{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# dataloader arguments\n",
    "batch_size = 128\n",
    "# data_path='~/justinData/mnist'\n",
    "subset=10\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "#  Initialize Network\n",
    "net = nn.Sequential(nn.Conv2d(1, 12, 5),\n",
    "                    nn.AvgPool2d(2, stride=2),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Conv2d(12, 64, 5),\n",
    "                    nn.AvgPool2d(2, stride=2),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(64*4*4, 10),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state_dict': OrderedDict([('conv_fc.0.weight', tensor([[[[ 0.0931,  0.0193, -0.0849],\n",
      "          [ 0.1109,  0.2121, -0.2605],\n",
      "          [ 0.0376, -0.0058, -0.0403]],\n",
      "\n",
      "         [[-0.0475,  0.1391, -0.1495],\n",
      "          [ 0.2059,  0.1943, -0.3784],\n",
      "          [ 0.0901,  0.0615, -0.2394]],\n",
      "\n",
      "         [[ 0.1880, -0.1464, -0.0732],\n",
      "          [ 0.0828,  0.1378, -0.3004],\n",
      "          [ 0.2835, -0.0221, -0.1532]]],\n",
      "\n",
      "\n",
      "        [[[-0.0157, -0.1529,  0.1716],\n",
      "          [ 0.0594, -0.1340, -0.0643],\n",
      "          [ 0.0184, -0.1188,  0.0965]],\n",
      "\n",
      "         [[ 0.1957, -0.0544, -0.0770],\n",
      "          [-0.0348, -0.0664,  0.0313],\n",
      "          [-0.0026, -0.0582,  0.1344]],\n",
      "\n",
      "         [[-0.0316,  0.0745, -0.0949],\n",
      "          [-0.1542, -0.1321,  0.1678],\n",
      "          [-0.2048, -0.0533,  0.2732]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1676, -0.2314, -0.2622],\n",
      "          [ 0.1440, -0.2259, -0.1999],\n",
      "          [ 0.2448,  0.0399,  0.2511]],\n",
      "\n",
      "         [[ 0.1769, -0.1979,  0.1028],\n",
      "          [-0.1555, -0.0954,  0.0448],\n",
      "          [ 0.1123,  0.0420,  0.0193]],\n",
      "\n",
      "         [[-0.0206,  0.2467,  0.1230],\n",
      "          [-0.0272,  0.0976,  0.0831],\n",
      "          [-0.1491, -0.1951, -0.0939]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1925, -0.1992, -0.2038],\n",
      "          [ 0.0797, -0.1166,  0.1411],\n",
      "          [ 0.2172, -0.0306,  0.1654]],\n",
      "\n",
      "         [[ 0.1148,  0.1937,  0.0995],\n",
      "          [-0.1533,  0.0430, -0.0398],\n",
      "          [-0.0518, -0.0466, -0.0914]],\n",
      "\n",
      "         [[ 0.0693,  0.1835,  0.1776],\n",
      "          [-0.2463, -0.1255,  0.0511],\n",
      "          [-0.1473,  0.0047,  0.0878]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2320, -0.0757,  0.1008],\n",
      "          [ 0.2092, -0.0428,  0.2085],\n",
      "          [-0.1010,  0.0930, -0.1918]],\n",
      "\n",
      "         [[-0.1942, -0.0892, -0.0634],\n",
      "          [-0.3233,  0.0187, -0.0628],\n",
      "          [-0.1994, -0.1583,  0.2589]],\n",
      "\n",
      "         [[-0.1242,  0.1162,  0.1930],\n",
      "          [-0.2163, -0.0805,  0.2568],\n",
      "          [-0.1685,  0.0877,  0.3058]]],\n",
      "\n",
      "\n",
      "        [[[-0.0369, -0.0990, -0.1931],\n",
      "          [ 0.2070, -0.0176,  0.1360],\n",
      "          [-0.2480,  0.1369,  0.1634]],\n",
      "\n",
      "         [[-0.0496, -0.2231, -0.1045],\n",
      "          [ 0.0533,  0.0663, -0.0344],\n",
      "          [ 0.1058,  0.1003, -0.0018]],\n",
      "\n",
      "         [[ 0.1329, -0.2748, -0.0287],\n",
      "          [ 0.0873, -0.1990,  0.1721],\n",
      "          [-0.0228, -0.0145,  0.0914]]]])), ('conv_fc.1.weight', tensor([1.2152, 0.9655, 1.0785, 1.2103, 1.1621, 1.0069, 0.8778, 1.2368, 1.0136,\n",
      "        1.0007, 1.2438, 1.0348, 1.0721, 1.0302, 1.1751, 1.0120, 0.9619, 1.0625,\n",
      "        1.0345, 1.1625, 0.8878, 0.9236, 0.8827, 0.7500, 1.1526, 0.9187, 1.2168,\n",
      "        1.1127, 1.0548, 0.9322, 1.1083, 1.0030, 1.2454, 0.9832, 0.8888, 0.9449,\n",
      "        1.0820, 0.9531, 0.9067, 0.9166, 0.9436, 0.9684, 1.2599, 0.9462, 1.0636,\n",
      "        1.0865, 1.1222, 0.9822, 1.0747, 1.1246, 1.0788, 1.1151, 1.1986, 0.9728,\n",
      "        1.1810, 0.9700, 1.0198, 1.1766, 1.1851, 0.9919, 1.1205, 1.0548, 1.0950,\n",
      "        1.1014, 1.1434, 0.9672, 1.1005, 0.9532, 1.0043, 1.1363, 0.9289, 1.0547,\n",
      "        1.0815, 1.0691, 1.1982, 0.9765, 1.0281, 1.0109, 1.1476, 1.0522, 1.0470,\n",
      "        1.1109, 1.0110, 1.0548, 1.1954, 1.0613, 1.0433, 0.8751, 1.2024, 1.0379,\n",
      "        1.2271, 1.0371, 0.9467, 1.0843, 1.0840, 1.2551, 0.9016, 1.0952, 1.1151,\n",
      "        0.8798, 1.0781, 0.9877, 0.9905, 0.9643, 1.0688, 1.2279, 0.8482, 1.1039,\n",
      "        1.0850, 0.8580, 1.0104, 1.1875, 1.1029, 1.1578, 1.1358, 1.1280, 1.0998,\n",
      "        1.0925, 1.1255, 1.0114, 1.1162, 1.1097, 0.7760, 1.0434, 1.0820, 1.1224,\n",
      "        1.1874, 1.0363, 1.0836, 1.0508, 1.1412, 0.8863, 1.1460, 1.1721, 0.9899,\n",
      "        1.1286, 0.9249, 1.0675, 1.1245, 1.0828, 0.9499, 1.1119, 0.8153, 1.0566,\n",
      "        0.9474, 0.9671, 0.9485, 1.0831, 0.9262, 1.1147, 1.0436, 1.0366, 1.0146,\n",
      "        0.9302, 1.0159, 1.0531, 1.1000, 1.1587, 0.8927, 1.2094, 1.1102, 0.9826,\n",
      "        0.9685, 1.1706, 1.0842, 1.1386, 1.1114, 1.0059, 0.9186, 1.0928, 1.0518,\n",
      "        0.9912, 0.8992, 0.9395, 0.9857, 1.2281, 0.9100, 0.8072, 1.1864, 1.1477,\n",
      "        1.1137, 0.9821, 1.0459, 1.0787, 0.9702, 0.9408, 0.9678, 1.0704, 1.1101,\n",
      "        0.9383, 1.0393, 1.0709, 1.0073, 0.9071, 0.9157, 0.9941, 1.0434, 0.7989,\n",
      "        0.9122, 1.1331, 1.0210, 1.1527, 0.9075, 1.1317, 1.0867, 0.9367, 0.9805,\n",
      "        1.1712, 1.0877, 1.1379, 0.9972, 1.0325, 1.0371, 0.9345, 0.9724, 1.0143,\n",
      "        1.1347, 0.9855, 1.1660, 0.9840, 1.0343, 0.9843, 1.0993, 0.8766, 0.9035,\n",
      "        0.9668, 0.9161, 0.9357, 1.0289, 1.1262, 1.1087, 1.1385, 1.0508, 0.8681,\n",
      "        1.2083, 1.1356, 0.9209, 0.9615, 0.9657, 1.1232, 1.0858, 1.1537, 1.1800,\n",
      "        1.0182, 1.1216, 0.9501, 1.1209, 0.9532, 0.9370, 0.9081, 1.0571, 1.0590,\n",
      "        1.1266, 0.9581, 1.1092, 1.0559])), ('conv_fc.1.bias', tensor([ 1.1023e-01, -4.5251e-02,  4.9363e-02,  1.4682e-01,  8.5550e-02,\n",
      "         7.0887e-03, -1.3675e-01,  2.1137e-01, -4.4421e-02, -3.9091e-02,\n",
      "         7.6882e-02,  5.6086e-02,  1.4049e-01, -1.0388e-01,  8.1731e-02,\n",
      "        -7.7344e-02, -9.4947e-02,  4.0936e-02, -4.6239e-02,  7.9547e-02,\n",
      "        -1.1760e-01, -7.4257e-02, -1.3308e-01, -1.7741e-01, -7.7125e-02,\n",
      "        -1.7083e-01, -3.0399e-02,  7.8272e-02,  1.1388e-01, -2.2050e-01,\n",
      "         5.3760e-02,  3.4037e-02,  1.0114e-01, -3.4221e-02, -1.2681e-01,\n",
      "        -7.4773e-02,  9.6881e-02, -4.3107e-02, -9.1831e-02, -1.0031e-01,\n",
      "        -6.0664e-02, -3.2818e-02,  2.5823e-01, -5.5911e-02, -1.2290e-01,\n",
      "         5.7150e-02, -1.4262e-01, -3.1988e-02,  4.5276e-02, -4.0198e-02,\n",
      "         1.1320e-01,  2.2930e-02,  5.7175e-02, -2.4198e-02,  1.8512e-01,\n",
      "        -3.4379e-02,  7.0897e-03,  1.5731e-01,  1.1325e-01, -2.0208e-02,\n",
      "         7.7056e-02,  5.9794e-02,  1.0488e-02,  7.7024e-02,  2.1230e-02,\n",
      "        -3.8678e-02,  4.7533e-02, -1.2097e-01,  7.0294e-04,  1.1730e-01,\n",
      "        -1.7047e-01,  3.6556e-02,  5.4751e-02, -1.0385e-01,  2.0449e-01,\n",
      "         8.2379e-03,  2.2764e-02, -1.2009e-02, -7.1493e-03,  1.2853e-01,\n",
      "         2.5903e-02,  8.9847e-02,  4.5548e-03,  3.1850e-02,  6.4168e-02,\n",
      "         2.2765e-02,  2.1996e-02, -9.8831e-02,  1.0379e-01,  1.3214e-02,\n",
      "         8.8971e-02,  1.1396e-02, -1.8344e-01,  7.0711e-02,  5.1784e-02,\n",
      "         1.3761e-01, -1.2529e-01,  2.7171e-02,  2.6812e-02, -9.8259e-02,\n",
      "         2.9317e-02, -7.2714e-03, -2.8159e-02,  2.8134e-03,  3.8499e-02,\n",
      "         2.6470e-01, -1.8527e-01,  1.0789e-01,  7.9981e-03, -2.4004e-01,\n",
      "         9.0064e-03,  9.6394e-02,  2.8374e-02,  1.5936e-01,  1.2212e-01,\n",
      "         6.2790e-02,  8.3693e-02,  1.0333e-01,  1.1517e-01,  3.0706e-02,\n",
      "         8.1215e-02,  6.9503e-02, -1.9019e-01, -5.4555e-03, -4.5983e-02,\n",
      "         3.0291e-02,  1.1473e-03,  1.9922e-02,  6.9910e-02,  4.6160e-02,\n",
      "         1.4502e-01, -8.3856e-02,  1.0680e-01,  1.4961e-01, -2.6346e-02,\n",
      "         8.6747e-02, -9.2432e-02, -7.1521e-02,  1.0710e-01,  8.1843e-02,\n",
      "        -3.2490e-02,  1.2565e-01, -1.6240e-01,  7.6927e-02, -5.4314e-02,\n",
      "        -1.6885e-02, -3.1071e-02,  7.9913e-02, -7.8926e-02,  6.7691e-02,\n",
      "         4.3794e-02,  2.5371e-02,  3.0984e-02, -5.8421e-02, -6.7810e-03,\n",
      "         5.8138e-02,  1.2912e-01,  1.2763e-01, -1.5345e-01,  9.4633e-02,\n",
      "         8.9151e-02, -2.8410e-02, -8.0707e-03,  1.5458e-01, -1.2324e-01,\n",
      "         1.1763e-01,  9.0171e-02, -8.6317e-02, -6.2326e-02,  5.0907e-02,\n",
      "         4.7707e-02, -9.3188e-02, -1.4026e-01, -4.2212e-02, -1.6123e-02,\n",
      "         6.3060e-02, -1.5456e-02, -1.9093e-01,  1.1969e-01,  1.1132e-01,\n",
      "         8.3990e-02, -6.7354e-02, -1.4106e-01, -6.0943e-02, -1.3306e-01,\n",
      "        -2.3754e-01, -5.0813e-02, -1.3398e-02,  9.1107e-02, -6.7145e-02,\n",
      "         6.4776e-05,  3.9041e-02, -3.7455e-02, -1.8366e-01, -9.6403e-02,\n",
      "        -5.7821e-03,  2.9251e-02, -1.6468e-01, -4.4778e-02,  4.6354e-02,\n",
      "        -2.6331e-02, -3.0695e-02, -1.0928e-01,  1.1952e-01,  1.7302e-02,\n",
      "        -7.9144e-02, -7.9224e-02,  9.1133e-02,  9.7276e-02,  2.9363e-02,\n",
      "        -3.0164e-02,  8.7903e-02,  9.3034e-03, -5.7868e-02,  1.8626e-04,\n",
      "         2.8620e-02,  1.1431e-02, -7.9960e-02,  1.0434e-01, -5.8651e-02,\n",
      "         1.4425e-02, -9.4371e-03,  7.1470e-02, -1.0354e-01, -3.5353e-02,\n",
      "        -1.5876e-02, -5.4876e-02, -3.1788e-02, -2.0819e-02,  1.7729e-01,\n",
      "         6.9332e-02,  8.0842e-02,  9.2435e-03, -1.2710e-01,  1.6048e-01,\n",
      "         1.1382e-01, -5.2706e-02, -7.7395e-02, -5.7168e-02,  2.4944e-02,\n",
      "        -2.9792e-02,  1.6077e-01,  1.3416e-02, -4.8284e-02,  1.2525e-01,\n",
      "        -6.6433e-02, -4.6658e-02, -5.4726e-02, -7.9273e-02, -6.2168e-02,\n",
      "         7.6304e-02,  2.0151e-02,  3.0979e-01, -4.2354e-02,  9.0917e-02,\n",
      "         5.5695e-02])), ('conv_fc.1.running_mean', tensor([ 1.7126e-03, -6.0090e-03,  1.1010e-03, -3.3229e-03,  5.5944e-03,\n",
      "         3.3637e-03, -1.1097e-04, -5.1592e-03,  2.5128e-04,  1.2067e-03,\n",
      "        -9.0316e-03,  5.7097e-03,  4.5550e-03,  9.3721e-03, -1.8982e-03,\n",
      "        -1.1095e-02, -9.8430e-03, -2.6759e-03, -1.5173e-02, -1.0281e-04,\n",
      "         5.0511e-03, -1.0364e-03, -5.4758e-03, -9.5301e-03, -3.3532e-03,\n",
      "        -1.2813e-02, -1.4309e-02, -9.4646e-03,  6.3252e-04, -6.7167e-03,\n",
      "        -1.1701e-02,  3.3001e-03, -4.6506e-03,  7.1813e-03, -1.3015e-03,\n",
      "        -3.8719e-03,  3.0967e-03,  1.0660e-02,  6.0823e-03,  1.1603e-03,\n",
      "         2.3862e-03,  2.9777e-03, -6.2490e-03, -1.6454e-03,  8.6538e-03,\n",
      "         4.7668e-03, -1.7846e-03,  4.1354e-03, -2.5686e-03, -1.0682e-02,\n",
      "        -2.7972e-03, -1.0218e-02, -7.3976e-03,  1.8379e-03,  3.3353e-03,\n",
      "         2.2809e-04,  1.0629e-03,  6.7834e-03, -2.4323e-03, -5.8583e-03,\n",
      "         4.3342e-03, -1.7359e-03, -9.2616e-04,  7.4277e-03,  8.8689e-03,\n",
      "         3.3196e-03, -4.0577e-03, -2.1231e-03,  3.7540e-03, -5.0742e-03,\n",
      "        -1.3427e-02, -2.2156e-03,  3.8067e-03,  1.7875e-02, -3.2257e-03,\n",
      "        -5.0295e-03, -1.4934e-03, -2.4917e-04, -1.4580e-02, -3.6249e-03,\n",
      "         3.6386e-04,  6.4531e-03, -4.3199e-03, -8.2250e-03, -1.3130e-03,\n",
      "        -4.9258e-03,  4.3678e-03, -6.0748e-03, -2.1503e-03, -8.6663e-03,\n",
      "         2.2994e-03, -7.9786e-03, -6.3296e-03,  5.3056e-03,  4.5568e-03,\n",
      "         7.5917e-04,  3.0133e-03, -2.0799e-03, -1.6379e-03, -2.4420e-03,\n",
      "         1.0355e-03,  7.7755e-04, -7.8987e-03, -1.1846e-03, -1.8496e-03,\n",
      "        -2.7875e-03, -4.1761e-03, -3.0980e-03,  2.9171e-03, -9.8089e-03,\n",
      "        -1.0093e-03, -1.8407e-03,  1.0311e-02,  2.1468e-03, -1.7639e-03,\n",
      "         4.4724e-03,  6.4621e-03, -4.6221e-03, -4.8885e-03,  3.1501e-03,\n",
      "        -1.4061e-03,  1.0354e-03, -4.0358e-03, -1.5111e-02, -1.0607e-02,\n",
      "        -8.6769e-03, -1.3181e-02, -5.4711e-03,  8.1617e-03,  3.7019e-04,\n",
      "         3.2822e-04,  1.4349e-02,  8.0569e-03, -2.4217e-03, -1.3264e-03,\n",
      "        -8.0326e-04,  1.4760e-03,  2.7269e-03,  1.1716e-03, -5.0961e-03,\n",
      "         5.9470e-04,  2.2755e-03, -6.2179e-03,  1.5673e-03,  6.0802e-03,\n",
      "         4.9001e-04,  1.1550e-02,  3.8266e-03, -3.7082e-04, -4.1744e-03,\n",
      "        -4.8287e-03, -1.2105e-03,  3.7548e-03,  1.0041e-02, -4.6704e-04,\n",
      "         1.5009e-03,  2.0924e-03, -1.0584e-02,  2.4298e-03, -5.0371e-03,\n",
      "         4.7598e-04, -4.1334e-03,  9.8731e-03, -6.1592e-03, -2.8070e-03,\n",
      "        -2.3033e-03, -8.5701e-03, -1.0378e-02,  1.5485e-02, -8.6068e-03,\n",
      "        -1.8923e-03, -1.4133e-02,  1.1730e-02,  1.3697e-03,  1.6694e-03,\n",
      "        -4.0848e-03, -1.7617e-03,  1.2295e-02,  4.9452e-04,  1.4029e-04,\n",
      "         2.0303e-03,  6.2675e-03, -1.8581e-03, -7.3818e-03,  1.5064e-03,\n",
      "        -2.0714e-04, -2.7566e-03,  9.8888e-03,  7.0643e-03, -5.7922e-03,\n",
      "         1.7546e-03,  1.4958e-03,  1.1357e-03,  8.3458e-04,  8.8584e-03,\n",
      "        -1.3794e-03, -3.6351e-03, -1.2407e-02, -2.5049e-04,  1.3527e-03,\n",
      "         1.0618e-02,  6.6887e-03,  1.2240e-02,  4.0972e-03, -2.6326e-03,\n",
      "         3.9560e-03, -4.4818e-03, -8.7731e-04,  7.1799e-03,  8.4592e-04,\n",
      "         9.2633e-03,  5.0370e-03, -8.4035e-04, -2.9549e-03, -1.2420e-03,\n",
      "        -3.5738e-03, -9.8577e-03, -1.0269e-02, -6.3694e-03, -6.9040e-03,\n",
      "         6.6011e-03,  4.3061e-03, -2.8918e-04, -2.4717e-03,  5.8279e-03,\n",
      "        -3.9535e-04,  9.0023e-04, -4.7716e-03,  1.8577e-03,  6.2134e-03,\n",
      "         5.9964e-03,  2.2830e-03, -5.1450e-03,  3.1269e-03, -3.1865e-03,\n",
      "        -1.1499e-02,  4.7241e-03, -2.0390e-03,  1.3099e-02, -3.6384e-03,\n",
      "        -1.1376e-02, -3.8883e-03, -9.0168e-03, -2.8535e-03, -8.4754e-03,\n",
      "         1.8904e-05, -1.5715e-02,  4.2320e-03,  6.3396e-03,  4.7504e-03,\n",
      "        -6.2734e-05,  1.7340e-03,  2.6874e-03,  4.9010e-04, -2.5626e-03,\n",
      "        -4.0346e-03])), ('conv_fc.1.running_var', tensor([0.8762, 0.2212, 0.1034, 0.8338, 0.5884, 0.2610, 0.3372, 0.3061, 0.1645,\n",
      "        0.9181, 0.7409, 0.3775, 1.0017, 0.3279, 0.4698, 0.1536, 0.5227, 0.1700,\n",
      "        0.8899, 0.8568, 0.5588, 0.1081, 0.6282, 1.2679, 0.5804, 0.5515, 0.7637,\n",
      "        0.5235, 0.9463, 1.9580, 0.6893, 0.1143, 0.8896, 0.6155, 0.5866, 0.3531,\n",
      "        0.1758, 0.3891, 0.2552, 0.5651, 0.4858, 0.6704, 0.4739, 0.4604, 0.4880,\n",
      "        0.6825, 0.5254, 0.0714, 0.4354, 0.5590, 0.2556, 0.4001, 0.5987, 0.5853,\n",
      "        0.1810, 0.3088, 0.2537, 0.2034, 0.6702, 0.1300, 0.2910, 0.2866, 0.5348,\n",
      "        0.5549, 0.4344, 0.4288, 0.1563, 0.1768, 0.6688, 0.4780, 0.6816, 0.3877,\n",
      "        0.2040, 0.4277, 0.2381, 0.3031, 0.1260, 0.1662, 0.4457, 0.2462, 0.1543,\n",
      "        0.1549, 0.1560, 0.3784, 0.6310, 0.2547, 0.0889, 0.4843, 0.7715, 0.3533,\n",
      "        0.8519, 0.1190, 1.1574, 0.1363, 0.1817, 1.2002, 0.1251, 0.3850, 0.5850,\n",
      "        0.6552, 0.2416, 0.2177, 0.2567, 0.3916, 0.1869, 0.1756, 0.4605, 0.4945,\n",
      "        0.6119, 0.6495, 0.0881, 0.8463, 0.6256, 0.4338, 0.6207, 0.1155, 0.8679,\n",
      "        0.2099, 0.1600, 0.1734, 0.2278, 0.1911, 0.5651, 0.8572, 0.2902, 1.0948,\n",
      "        0.6517, 0.2956, 0.2595, 0.1662, 0.3597, 1.7434, 1.0373, 0.6244, 0.0934,\n",
      "        0.1578, 0.0816, 0.2525, 0.1763, 0.2228, 0.6509, 0.1403, 0.4142, 0.4785,\n",
      "        0.7397, 0.1239, 0.8228, 0.5487, 0.5353, 0.4872, 0.3196, 0.1504, 0.2484,\n",
      "        0.4332, 0.3088, 0.1146, 0.3008, 0.5900, 0.3804, 0.8802, 0.1814, 0.7308,\n",
      "        0.4511, 0.1437, 0.3790, 0.3814, 0.2956, 0.1789, 1.3886, 0.2132, 0.2354,\n",
      "        0.8348, 0.5355, 0.2748, 0.2868, 0.3900, 0.8139, 0.8670, 0.2275, 0.3207,\n",
      "        0.6189, 0.0974, 0.4062, 0.2958, 0.1090, 0.2502, 0.3528, 0.2509, 1.0773,\n",
      "        0.2252, 0.1551, 0.2698, 0.1526, 0.1040, 0.2650, 0.3449, 0.6918, 1.7365,\n",
      "        0.4016, 0.4362, 0.1748, 0.4978, 0.3203, 0.4065, 0.2973, 0.3057, 0.3664,\n",
      "        0.7619, 0.4127, 0.1794, 0.3071, 1.0223, 0.2555, 0.2798, 0.3577, 0.3777,\n",
      "        0.4833, 0.4939, 0.7346, 0.8482, 0.1047, 0.1116, 0.3968, 0.1858, 0.4072,\n",
      "        0.4217, 0.0884, 0.1955, 0.0740, 0.1625, 0.8544, 0.3368, 0.3973, 0.4560,\n",
      "        0.5334, 0.6058, 0.1455, 0.1403, 0.4575, 0.2511, 0.3677, 0.3749, 0.5674,\n",
      "        0.2596, 0.2703, 0.0729, 0.4397, 0.1517, 0.2898, 0.4705, 0.1921, 0.0801,\n",
      "        1.0319, 0.1152, 0.4912, 0.2876])), ('conv_fc.1.num_batches_tracked', tensor(19525)), ('conv_fc.3.weight', tensor([[[[-5.2572e-03,  3.2616e-02, -8.2841e-03],\n",
      "          [ 7.8471e-03,  2.4649e-02,  8.0738e-03],\n",
      "          [-8.2360e-03, -2.1059e-03,  1.4590e-02]],\n",
      "\n",
      "         [[ 3.5824e-04, -1.4522e-02, -1.9614e-03],\n",
      "          [ 3.7269e-02,  1.0532e-03,  6.1239e-03],\n",
      "          [ 1.6592e-02,  9.2356e-03,  1.6452e-02]],\n",
      "\n",
      "         [[-6.3480e-03, -1.8100e-02,  1.2267e-02],\n",
      "          [ 8.8177e-03, -2.5788e-02, -6.2602e-03],\n",
      "          [-1.8800e-02, -1.4584e-02, -3.0283e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1145e-03,  1.0969e-03,  1.1569e-03],\n",
      "          [ 1.7405e-02, -2.7322e-03,  6.7599e-03],\n",
      "          [-2.3491e-03,  8.2330e-03,  6.7188e-03]],\n",
      "\n",
      "         [[-7.1523e-03, -3.8700e-02, -1.3030e-02],\n",
      "          [-1.8274e-03, -2.7459e-02, -1.3771e-02],\n",
      "          [-2.1416e-02,  1.0899e-02, -9.7399e-03]],\n",
      "\n",
      "         [[-7.3112e-03, -9.9539e-03, -6.4041e-03],\n",
      "          [-5.9486e-03, -6.9332e-03,  6.3005e-03],\n",
      "          [-3.2833e-02, -2.2796e-03, -1.1877e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7681e-02,  6.1776e-03,  4.0149e-03],\n",
      "          [ 1.4539e-02, -4.3088e-03,  7.0108e-03],\n",
      "          [ 2.7871e-02, -5.1187e-04, -4.2069e-03]],\n",
      "\n",
      "         [[ 2.7265e-03,  7.9790e-03, -2.0971e-02],\n",
      "          [ 1.0707e-02,  1.0012e-02,  1.8549e-04],\n",
      "          [ 1.6940e-02,  1.1002e-03,  8.9100e-03]],\n",
      "\n",
      "         [[ 8.5123e-03, -1.7926e-02, -1.0821e-02],\n",
      "          [-1.6707e-02,  7.6643e-03,  1.1914e-02],\n",
      "          [-6.6951e-03, -2.4315e-02,  8.4285e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4299e-02,  8.2399e-04, -1.0314e-03],\n",
      "          [-1.7465e-02,  4.4193e-04, -1.1102e-02],\n",
      "          [-2.2715e-02, -3.4679e-03, -2.2309e-02]],\n",
      "\n",
      "         [[-2.9706e-02, -3.4648e-03,  7.2149e-04],\n",
      "          [-3.7915e-02,  2.4936e-03, -1.4829e-02],\n",
      "          [-1.1237e-03,  1.1670e-02, -2.0102e-02]],\n",
      "\n",
      "         [[ 2.8825e-02, -1.5936e-02,  1.4707e-02],\n",
      "          [ 5.9566e-03,  1.5758e-02,  2.9775e-02],\n",
      "          [-1.6708e-02, -1.8146e-03,  3.7170e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7070e-02,  1.9855e-02, -2.3553e-02],\n",
      "          [-9.0145e-03,  1.1961e-02,  1.4536e-02],\n",
      "          [ 7.8974e-03, -6.1588e-03, -3.7507e-03]],\n",
      "\n",
      "         [[-5.0098e-03, -1.7203e-02,  2.6066e-03],\n",
      "          [-1.1772e-02, -1.9134e-04, -1.1608e-02],\n",
      "          [-7.4477e-03,  2.7321e-02,  5.4061e-03]],\n",
      "\n",
      "         [[-1.1175e-02, -1.0730e-02,  1.2699e-03],\n",
      "          [-1.6872e-02,  2.0054e-03,  7.2493e-04],\n",
      "          [-1.3268e-02, -2.1598e-03, -1.3570e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8695e-03,  1.0133e-02, -1.3313e-02],\n",
      "          [ 7.6952e-03,  3.7197e-03,  4.1818e-03],\n",
      "          [-1.7923e-02,  3.3241e-03,  1.0935e-02]],\n",
      "\n",
      "         [[-2.1074e-02,  2.2836e-02,  2.5699e-02],\n",
      "          [ 4.6255e-03,  1.4899e-02,  1.8616e-02],\n",
      "          [ 3.0085e-03, -8.6712e-03, -9.2275e-03]],\n",
      "\n",
      "         [[-1.8412e-02,  9.8894e-04,  8.7910e-03],\n",
      "          [ 1.3261e-02,  3.8348e-03, -2.3207e-02],\n",
      "          [ 1.4004e-03,  1.2195e-02,  4.1154e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-9.5783e-03,  6.6621e-03,  8.7044e-03],\n",
      "          [-2.7529e-03,  7.2459e-03, -8.4405e-03],\n",
      "          [ 2.0894e-02, -2.8909e-03,  1.0315e-02]],\n",
      "\n",
      "         [[ 1.3926e-02, -2.9377e-03, -1.0214e-02],\n",
      "          [ 1.0117e-02,  2.6146e-02,  1.4217e-02],\n",
      "          [ 8.6889e-03,  1.6451e-02,  2.1872e-02]],\n",
      "\n",
      "         [[-1.5923e-02, -2.4870e-02, -7.2827e-03],\n",
      "          [-1.1828e-02,  5.5866e-03, -8.8069e-03],\n",
      "          [-3.9690e-03,  1.6824e-02, -8.2187e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7752e-03,  3.3388e-03, -2.2220e-02],\n",
      "          [ 1.9105e-02,  1.5361e-02,  7.5732e-03],\n",
      "          [-3.6054e-03, -1.3422e-02, -5.1402e-04]],\n",
      "\n",
      "         [[-9.5889e-03,  2.5727e-02, -5.8959e-03],\n",
      "          [-1.3845e-02,  3.1468e-02,  3.3524e-02],\n",
      "          [-2.0787e-02,  1.5939e-02, -6.3526e-03]],\n",
      "\n",
      "         [[-1.9613e-02,  3.9331e-03, -9.5880e-03],\n",
      "          [-7.7633e-04, -2.2853e-02,  4.8094e-03],\n",
      "          [-9.4631e-03, -2.2617e-02,  8.1817e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0481e-02, -5.3062e-03,  2.8109e-02],\n",
      "          [ 1.4939e-02,  3.3245e-03,  1.8371e-02],\n",
      "          [-8.2739e-03, -1.2343e-02,  2.5255e-02]],\n",
      "\n",
      "         [[ 9.7722e-03, -2.4160e-02, -1.5685e-02],\n",
      "          [-1.1626e-02,  1.3461e-02, -1.9577e-02],\n",
      "          [-1.3496e-02, -1.1350e-02,  1.0656e-02]],\n",
      "\n",
      "         [[ 1.6377e-02, -2.0306e-02, -4.2922e-02],\n",
      "          [ 5.4084e-02,  4.3985e-02,  2.7422e-03],\n",
      "          [ 4.7664e-02,  5.3713e-02,  2.6834e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3268e-02, -1.6116e-02, -1.3408e-02],\n",
      "          [-7.2605e-03,  1.0412e-02, -1.9708e-02],\n",
      "          [ 2.1418e-02, -2.5004e-03,  1.3758e-02]],\n",
      "\n",
      "         [[-5.4720e-03, -1.9792e-02, -4.3552e-02],\n",
      "          [-5.9014e-03,  2.8878e-03, -2.8450e-02],\n",
      "          [-1.5325e-02, -1.3373e-02, -3.3858e-02]],\n",
      "\n",
      "         [[-2.6089e-02, -1.7058e-02, -5.6428e-03],\n",
      "          [-2.4390e-02, -6.8583e-04, -9.0907e-03],\n",
      "          [ 9.4146e-03, -5.5453e-03, -6.3996e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7228e-02, -1.4664e-02,  5.3251e-03],\n",
      "          [ 1.6001e-02,  3.0106e-05, -9.4193e-03],\n",
      "          [-3.2840e-03,  8.4434e-03,  2.0327e-02]],\n",
      "\n",
      "         [[-1.5551e-02, -3.5263e-02, -8.2969e-03],\n",
      "          [-8.3731e-03, -3.0521e-02, -2.3029e-02],\n",
      "          [-6.1488e-03,  8.1244e-03, -2.5712e-02]],\n",
      "\n",
      "         [[ 1.9916e-02,  2.0045e-02, -8.7214e-03],\n",
      "          [-2.0695e-02,  1.9370e-02, -2.5162e-02],\n",
      "          [-1.8647e-02, -2.1743e-02, -2.2343e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4181e-03,  3.3758e-03,  2.4620e-04],\n",
      "          [-1.2469e-03,  4.8480e-03,  2.1653e-03],\n",
      "          [-7.8839e-05, -1.3289e-02,  4.5087e-03]],\n",
      "\n",
      "         [[ 4.3261e-03,  5.6623e-03,  3.1994e-03],\n",
      "          [ 2.8613e-02,  2.7881e-02,  1.5178e-03],\n",
      "          [ 3.2518e-02,  2.2155e-02,  3.0102e-02]],\n",
      "\n",
      "         [[ 1.9090e-02, -1.1804e-02, -2.4266e-02],\n",
      "          [-1.0624e-02,  9.7236e-03,  1.1029e-02],\n",
      "          [-2.1626e-02, -4.5541e-03,  2.8154e-02]]]])), ('conv_fc.4.weight', tensor([0.9212, 1.0073, 0.9549, 0.9452, 0.9810, 0.8974, 0.9908, 1.0105, 0.9832,\n",
      "        1.0131, 1.0262, 1.1559, 0.9319, 0.9343, 1.0876, 1.0121, 1.0868, 0.9673,\n",
      "        0.9538, 0.9868, 1.0565, 1.1527, 0.9146, 1.0842, 0.9560, 0.9821, 0.9689,\n",
      "        1.0058, 0.9313, 1.0171, 1.0073, 0.9515, 0.9454, 0.9492, 0.8857, 0.9624,\n",
      "        0.9469, 0.9759, 0.8853, 1.0124, 0.8957, 0.9518, 0.8671, 1.0822, 0.9481,\n",
      "        0.9305, 0.9070, 1.0347, 1.0891, 0.8839, 0.9697, 0.9456, 1.0713, 0.9346,\n",
      "        0.9200, 1.0669, 0.8497, 0.9263, 0.9466, 1.1675, 1.0613, 1.0879, 0.9448,\n",
      "        0.8777, 1.0632, 0.9846, 0.9760, 0.9222, 0.9150, 0.9578, 1.0103, 0.9384,\n",
      "        0.9865, 0.9626, 0.9477, 1.0496, 0.9187, 0.9788, 0.9637, 0.9684, 1.0765,\n",
      "        0.9320, 0.9715, 0.9234, 1.2187, 1.0263, 0.9517, 0.9336, 0.9305, 0.9525,\n",
      "        1.1197, 1.0347, 1.0276, 0.9562, 0.9844, 0.9414, 0.9822, 0.9393, 0.9242,\n",
      "        0.9815, 0.9432, 0.9393, 1.0789, 1.0230, 0.9632, 0.9800, 0.9188, 0.9661,\n",
      "        0.9709, 0.9679, 0.9952, 0.9958, 1.0042, 0.8532, 0.9606, 1.0133, 0.9004,\n",
      "        0.9579, 0.9074, 0.9969, 0.9557, 0.9136, 1.1066, 0.9943, 1.0469, 0.9443,\n",
      "        0.9821, 0.9598, 1.0806, 1.1234, 0.9427, 1.0163, 0.8752, 0.9525, 0.9662,\n",
      "        0.9912, 0.9641, 1.0509, 0.9697, 0.9430, 0.8578, 1.0562, 0.9786, 1.0155,\n",
      "        0.9888, 0.9903, 0.9564, 0.8558, 0.9705, 0.9771, 1.0846, 0.9172, 0.9673,\n",
      "        0.9962, 1.0057, 0.9438, 0.9331, 0.9757, 0.9266, 0.9206, 1.0107, 0.9766,\n",
      "        0.9735, 1.0185, 0.9681, 0.8965, 1.0067, 1.0370, 1.1402, 0.9241, 0.9572,\n",
      "        1.0866, 0.9814, 1.1507, 0.9879, 0.9322, 0.9430, 0.9802, 1.0342, 0.9572,\n",
      "        1.0207, 1.0349, 1.0213, 0.9553, 0.9583, 0.8391, 0.9483, 1.0153, 0.9327,\n",
      "        0.9596, 1.0516, 0.9637, 0.9722, 1.0997, 1.0025, 0.9792, 0.9793, 0.9217,\n",
      "        0.9489, 1.1109, 1.0295, 1.0245, 0.9754, 0.9420, 0.9247, 0.9803, 0.9976,\n",
      "        0.9476, 0.8995, 0.9670, 0.9270, 1.1707, 0.9067, 1.0353, 0.9973, 1.0980,\n",
      "        1.2105, 0.9789, 1.0657, 1.0293, 0.9667, 0.8540, 0.9664, 1.0363, 0.8415,\n",
      "        0.9638, 0.9540, 1.1337, 1.1244, 0.8920, 0.9920, 0.9382, 1.0227, 0.9436,\n",
      "        0.9151, 0.9474, 0.9906, 1.0076, 1.0906, 0.9342, 0.8272, 1.0072, 0.9622,\n",
      "        1.0383, 0.9153, 1.0594, 0.9927, 0.9595, 0.8808, 0.9197, 1.1575, 1.0865,\n",
      "        0.9153, 0.9530, 0.9511, 0.9960])), ('conv_fc.4.bias', tensor([-0.1199, -0.0739, -0.1613, -0.0844, -0.0938, -0.1453, -0.0338, -0.0528,\n",
      "        -0.0813, -0.0233, -0.0398, -0.1721, -0.0941, -0.1028, -0.1097, -0.1270,\n",
      "        -0.1255, -0.1031, -0.1177, -0.0971, -0.2112, -0.1245, -0.1273, -0.0313,\n",
      "        -0.1149, -0.1670, -0.0651, -0.1035, -0.1170, -0.0203, -0.0841, -0.1315,\n",
      "        -0.1321, -0.1467, -0.2748, -0.1206, -0.0812, -0.1032, -0.2057, -0.1654,\n",
      "        -0.1686, -0.0993, -0.1555, -0.0285, -0.1016, -0.0856, -0.1616, -0.0492,\n",
      "         0.0648, -0.0968, -0.0900, -0.0220, -0.0590, -0.0651, -0.1237, -0.0671,\n",
      "        -0.2152, -0.1922, -0.1283, -0.1097, -0.1414, -0.0630, -0.1424, -0.1076,\n",
      "        -0.0671, -0.1006, -0.0627, -0.1508, -0.1174, -0.1121, -0.0863, -0.1136,\n",
      "        -0.0891, -0.1042, -0.1238, -0.0610, -0.1106, -0.1061, -0.1306, -0.0720,\n",
      "        -0.0253, -0.1421, -0.1097, -0.1249, -0.2733, -0.0477, -0.0706, -0.1541,\n",
      "        -0.1388, -0.1898, -0.0251, -0.0091, -0.0109, -0.1497, -0.1052, -0.1016,\n",
      "        -0.0974, -0.0942, -0.1652, -0.0490, -0.1482, -0.0891, -0.0508, -0.0669,\n",
      "        -0.1291, -0.1963, -0.1186, -0.0640, -0.1088, -0.0617, -0.1199, -0.0932,\n",
      "        -0.0720, -0.1877, -0.1383, -0.1177, -0.1513, -0.1179, -0.1638, -0.0886,\n",
      "        -0.0797, -0.1663, -0.0214, -0.1134, -0.0652, -0.1353, -0.0812, -0.0692,\n",
      "        -0.1017, -0.1145, -0.0857, -0.1072, -0.2248, -0.1305, -0.0925, -0.1394,\n",
      "        -0.0548, -0.0627, -0.1556, -0.1037, -0.2325, -0.0806, -0.0581, -0.0716,\n",
      "        -0.0895, -0.0985, -0.1038, -0.1576, -0.1220, -0.0496, -0.0179, -0.1452,\n",
      "        -0.1310, -0.0529, -0.0792, -0.1086, -0.0887, -0.0651, -0.1507, -0.0851,\n",
      "        -0.0724, -0.0996, -0.1206, -0.0821, -0.0514, -0.1213, -0.0467, -0.0351,\n",
      "         0.0767, -0.1023, -0.0766, -0.1819, -0.0877, -0.2872, -0.0611, -0.0778,\n",
      "        -0.1258, -0.0830, -0.0389, -0.0970, -0.0311, -0.0848, -0.0342, -0.0874,\n",
      "        -0.1621, -0.1976, -0.1935, -0.0737, -0.1274, -0.1376, -0.0682, -0.1208,\n",
      "        -0.0847, -0.0580, -0.1460, -0.1176, -0.0676, -0.1307, -0.1063, -0.0331,\n",
      "        -0.0789, -0.1079, -0.0545, -0.1642, -0.1609, -0.0696, -0.1016, -0.1520,\n",
      "        -0.1538, -0.0742, -0.1075, -0.3157, -0.2113, -0.1198, -0.0505, -0.0586,\n",
      "        -0.1223, -0.1650, -0.1617, -0.1735, -0.1036, -0.1668, -0.0940, -0.0498,\n",
      "        -0.1833, -0.1251, -0.1019, -0.2047, -0.0440, -0.1858, -0.0425, -0.1465,\n",
      "        -0.0732, -0.0858, -0.1856, -0.1495, -0.1414, -0.0466, -0.0238, -0.1253,\n",
      "        -0.2640, -0.0501, -0.1320, -0.0365, -0.1397, -0.0596, -0.2573, -0.1014,\n",
      "        -0.1872, -0.1522, -0.1510, -0.1877, -0.2081, -0.1026, -0.1093, -0.1109])), ('conv_fc.4.running_mean', tensor([-1.0662e+00, -2.3121e-01, -6.5923e-02, -1.3722e+00, -5.6653e-01,\n",
      "         8.3945e-01, -1.3087e+00, -9.7784e-01, -1.6613e-01, -1.8938e+00,\n",
      "        -2.8955e-01, -4.5174e-01, -1.4829e+00, -4.4214e-01, -4.8973e-01,\n",
      "        -3.7060e-01, -5.3370e-01,  7.8448e-01, -1.2353e+00, -5.8097e-01,\n",
      "        -9.5066e-01, -4.1995e-01, -5.5285e-01, -7.4778e-01,  2.9181e-01,\n",
      "         9.8967e-01, -1.1558e+00, -6.3665e-01, -1.8966e+00, -1.0394e+00,\n",
      "        -6.3467e-01, -3.2359e-01, -4.3062e-01, -1.1886e+00, -1.8555e+00,\n",
      "        -4.5252e-01, -3.7735e-01,  3.5111e-01, -2.1526e+00, -1.0906e-01,\n",
      "        -2.2560e+00, -1.7343e+00, -1.7820e+00, -8.3610e-01,  1.2566e+00,\n",
      "        -5.7013e-01, -5.4975e-01, -7.7448e-01, -7.3545e-01, -3.4387e+00,\n",
      "        -4.1556e-02, -9.3955e-01, -1.6320e-01, -1.7716e+00, -2.0782e+00,\n",
      "        -5.1673e-01, -1.6019e+00, -9.7575e-01, -1.6755e+00, -7.0618e-01,\n",
      "        -5.4508e-01, -5.7458e-01,  2.1177e-01, -2.5842e+00, -5.2263e-01,\n",
      "        -1.1211e+00, -1.1106e+00, -1.2855e+00, -2.5207e+00, -1.4829e+00,\n",
      "        -3.3204e-01,  2.4705e-01, -2.2399e+00, -1.5803e+00,  4.5187e-01,\n",
      "        -1.9049e-01, -4.0031e-01,  1.0424e+00,  5.5145e-01, -1.6635e+00,\n",
      "        -6.7733e-01,  4.9605e-01, -4.0835e-01, -6.3968e-01, -5.3867e-01,\n",
      "        -9.8799e-01, -6.8186e-01, -7.7259e-01, -9.4319e-01,  5.3993e-01,\n",
      "        -4.1847e-01, -8.0637e-01, -6.8634e-01, -2.1568e-01, -2.4611e-01,\n",
      "        -9.9437e-01, -1.5530e+00, -1.7577e+00, -1.1468e+00, -1.0824e+00,\n",
      "         1.7500e+00, -1.5513e+00, -3.7228e-01, -1.0102e-01,  7.7758e-01,\n",
      "        -2.9569e-01, -1.1345e+00, -9.9846e-01, -3.4736e-01, -3.2505e-01,\n",
      "        -5.3475e-01, -7.7788e-01, -7.5897e-01, -3.5084e+00, -1.6242e-03,\n",
      "        -5.0269e-01, -1.4179e+00,  7.0670e-01, -1.7422e+00,  7.5674e-02,\n",
      "        -7.2544e-01, -1.1251e+00, -8.1285e-01, -1.6108e-01, -1.8997e-01,\n",
      "        -4.4778e-01, -1.2187e-01, -6.3923e-01, -1.4906e-01, -4.0835e-01,\n",
      "        -1.1802e+00, -5.3095e-01, -6.9122e-01,  1.4194e+00, -1.4109e-01,\n",
      "         1.0758e-01, -6.7855e-01, -2.9745e-01, -4.2572e-01,  1.6181e+00,\n",
      "        -9.9212e-01, -3.0429e-01, -1.0668e+00, -4.3842e-01, -7.1697e-01,\n",
      "        -2.3131e-01, -2.5189e+00,  6.4876e-02,  8.8691e-01, -5.1137e-01,\n",
      "        -7.3922e-01, -2.8292e+00,  1.2299e+00, -5.8129e-01, -5.8117e-01,\n",
      "         5.4149e-01, -6.7859e-01, -1.0094e+00, -1.8164e+00, -1.2516e+00,\n",
      "        -2.8131e-01, -4.3701e-01,  1.1491e+00,  3.2300e-01, -8.5962e-01,\n",
      "        -5.8049e-01, -1.1186e+00, -1.3165e+00, -4.9460e-01, -1.2774e+00,\n",
      "        -2.2341e-01, -4.5681e-01, -6.2183e-01, -6.4659e-01, -7.4419e-01,\n",
      "        -1.4291e+00, -4.6067e-01,  1.3207e-01, -7.2050e-01,  1.2287e-02,\n",
      "        -3.6065e-01, -1.0258e+00, -4.4988e-01,  1.0766e+00,  1.0797e+00,\n",
      "        -6.8364e-01, -8.8228e-01, -4.8222e-01, -1.5087e+00, -1.7183e+00,\n",
      "        -1.0144e+00,  5.2645e-01,  8.7023e-01, -5.1259e-01, -3.7752e-01,\n",
      "         6.6079e-01, -3.8951e-01, -9.3174e-01, -5.0857e-01, -7.7580e-01,\n",
      "        -9.8280e-01, -4.8032e-01, -1.1054e+00, -9.0776e-01, -2.4974e+00,\n",
      "         2.8629e-02, -2.2033e+00,  4.6861e-01, -1.8060e+00, -7.1515e-01,\n",
      "        -6.0037e-01, -9.3059e-01, -2.3624e+00, -6.5592e-01, -5.4475e-01,\n",
      "        -3.7492e-01, -7.5337e-01,  2.7642e-01, -2.2781e-02,  6.1824e-01,\n",
      "         9.3046e-01, -1.2382e+00,  2.4082e-01, -1.0799e+00, -2.7882e+00,\n",
      "        -4.7130e-01, -1.8957e+00, -1.0532e+00, -3.9811e-01, -7.2706e-01,\n",
      "        -2.3714e-01, -1.2572e+00, -1.2657e+00, -1.2304e+00,  1.5570e-01,\n",
      "        -2.4022e+00,  3.0058e-01, -6.5657e-01, -5.7544e-01,  9.3819e-01,\n",
      "        -3.3622e+00, -5.6627e-01, -5.0339e-01, -4.4987e-01, -5.0757e-01,\n",
      "        -4.1805e-01,  1.8739e-01, -9.1440e-01, -3.2361e+00, -5.4898e-01,\n",
      "        -6.2486e-01, -4.5355e-01, -2.6463e+00,  1.3019e+00, -4.4999e-01,\n",
      "        -2.0813e-01])), ('conv_fc.4.running_var', tensor([1.6838, 1.9473, 2.4992, 1.8841, 2.9443, 1.0749, 1.6177, 1.7917, 1.2093,\n",
      "        3.2508, 1.6679, 4.2158, 1.8089, 1.7782, 2.6100, 2.1466, 3.0278, 1.3578,\n",
      "        1.5578, 2.7877, 3.4138, 3.5257, 1.5563, 2.7045, 0.9661, 2.5145, 1.8235,\n",
      "        1.5448, 3.3658, 2.0421, 1.5809, 1.6088, 2.0707, 3.1774, 4.1240, 2.1876,\n",
      "        1.3480, 0.6366, 4.3759, 2.7161, 3.7632, 2.4995, 3.2778, 2.5936, 0.7990,\n",
      "        2.5471, 2.1828, 1.4595, 2.6726, 4.5138, 0.7411, 2.7652, 2.3566, 3.2902,\n",
      "        2.8524, 1.8256, 3.3545, 3.0932, 3.1347, 3.7675, 2.3523, 2.7562, 1.0540,\n",
      "        3.7326, 2.0596, 1.7078, 1.3679, 1.4033, 3.8984, 2.3666, 1.9714, 1.2121,\n",
      "        3.7598, 2.7270, 1.5402, 2.2359, 1.2479, 1.1690, 2.1498, 2.2952, 2.1098,\n",
      "        1.5168, 2.1793, 1.6712, 6.3297, 2.2048, 1.4865, 2.7475, 1.7930, 1.2911,\n",
      "        3.4115, 1.3419, 3.9253, 1.4997, 1.2106, 2.1132, 2.7409, 2.7976, 2.2127,\n",
      "        1.8257, 2.1201, 2.7525, 1.7211, 1.9901, 1.7366, 1.7373, 2.4099, 1.3548,\n",
      "        1.2079, 0.7863, 2.2450, 1.4902, 1.5656, 5.5184, 1.5321, 1.8053, 1.9482,\n",
      "        0.8359, 2.1934, 2.9479, 1.3164, 1.5138, 2.5293, 1.5614, 2.1866, 1.6021,\n",
      "        1.0287, 1.7248, 3.8585, 2.5921, 2.5246, 1.8373, 2.7216, 1.1409, 1.3312,\n",
      "        1.5511, 1.9697, 3.4518, 0.7863, 1.1714, 3.9982, 1.5780, 1.5566, 2.5211,\n",
      "        1.3562, 1.5249, 5.1329, 1.5453, 1.0516, 1.1542, 2.2645, 4.4149, 1.1983,\n",
      "        2.7272, 1.5867, 2.3004, 1.0792, 2.2265, 2.5893, 1.4655, 1.0166, 1.1337,\n",
      "        1.4625, 1.2276, 1.1235, 2.7160, 1.7492, 4.0174, 3.3416, 1.7642, 1.4419,\n",
      "        3.7475, 1.8763, 5.2194, 2.5382, 1.3685, 1.4506, 0.8293, 2.6973, 1.0489,\n",
      "        1.8041, 2.4360, 1.7511, 1.1003, 0.8933, 1.7593, 1.5890, 1.8326, 2.6712,\n",
      "        2.9454, 2.0877, 1.7150, 1.2042, 2.5690, 1.6438, 1.8239, 1.1584, 1.5947,\n",
      "        1.3305, 2.9645, 1.9562, 3.0138, 1.4335, 3.0626, 4.3017, 1.2401, 4.4850,\n",
      "        0.8205, 2.6146, 1.8430, 2.1925, 6.1586, 3.5861, 2.2824, 1.6883, 2.3560,\n",
      "        3.9676, 1.8300, 3.5280, 2.3262, 1.7965, 3.4998, 0.5379, 1.8820, 4.2916,\n",
      "        0.9920, 2.4495, 4.8310, 2.6047, 1.6728, 0.7782, 2.4372, 2.7020, 2.5075,\n",
      "        1.1732, 4.4043, 1.5063, 2.4304, 2.0303, 1.8045, 4.3014, 1.3222, 1.9635,\n",
      "        1.6082, 1.1995, 2.1857, 2.0019, 1.4368, 4.5226, 1.6448, 2.9970, 4.2296,\n",
      "        3.7143, 1.6831, 1.0143, 1.7597])), ('conv_fc.4.num_batches_tracked', tensor(19525)), ('conv_fc.6.weight', tensor([[[[-2.0598e-02, -1.0831e-02,  1.3079e-03],\n",
      "          [-2.2494e-02,  2.3155e-02, -4.8225e-03],\n",
      "          [-1.5037e-02,  2.4314e-02,  9.9927e-03]],\n",
      "\n",
      "         [[-3.2971e-02,  9.9561e-03,  5.0018e-03],\n",
      "          [-1.9198e-02, -6.7332e-03,  6.2795e-03],\n",
      "          [ 4.3029e-04, -2.3507e-02, -8.6286e-04]],\n",
      "\n",
      "         [[-1.4147e-02,  2.5860e-04, -6.6922e-03],\n",
      "          [-1.7320e-03, -2.1340e-02, -1.0502e-02],\n",
      "          [-1.2883e-02, -1.1106e-02,  5.6168e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6220e-02, -8.5614e-03,  1.1853e-02],\n",
      "          [ 1.7951e-03, -8.5879e-03,  4.8874e-04],\n",
      "          [-2.1004e-02, -2.5907e-02,  8.3377e-04]],\n",
      "\n",
      "         [[-1.1991e-02, -5.3121e-03, -1.1441e-02],\n",
      "          [-1.4121e-02, -1.9564e-02, -1.6445e-02],\n",
      "          [ 1.1918e-03,  1.8554e-02,  5.2991e-03]],\n",
      "\n",
      "         [[-7.3208e-03,  8.0239e-03,  1.5529e-02],\n",
      "          [-2.1553e-02, -1.9562e-02, -1.3090e-03],\n",
      "          [-2.1310e-02,  2.0655e-03, -5.7981e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7245e-03,  2.4676e-02,  2.8847e-02],\n",
      "          [-1.5723e-03,  1.4778e-02, -1.2261e-02],\n",
      "          [-6.1918e-03, -9.2134e-03, -1.3243e-02]],\n",
      "\n",
      "         [[-9.4634e-04,  1.7092e-02, -1.1176e-03],\n",
      "          [-5.5187e-05,  1.2361e-02,  7.3771e-03],\n",
      "          [-2.2654e-03,  1.6534e-02,  7.2866e-03]],\n",
      "\n",
      "         [[-1.5591e-02, -3.2747e-03, -2.3516e-02],\n",
      "          [-2.8515e-02, -2.5788e-02, -6.1567e-03],\n",
      "          [-1.2944e-02, -2.6870e-02, -1.1766e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6063e-02, -3.2239e-02, -5.2924e-02],\n",
      "          [ 1.8034e-03, -2.1238e-02, -3.8486e-02],\n",
      "          [-1.3245e-02, -1.6621e-02, -1.6824e-02]],\n",
      "\n",
      "         [[-9.0570e-03,  5.9777e-03, -1.6487e-02],\n",
      "          [ 1.1834e-02, -1.4744e-02,  1.2549e-03],\n",
      "          [-1.5978e-02, -1.0230e-02, -1.4891e-02]],\n",
      "\n",
      "         [[ 1.9092e-02,  2.6306e-02,  1.8807e-02],\n",
      "          [ 9.4380e-03,  1.3756e-02,  4.2580e-02],\n",
      "          [ 1.3710e-02,  3.1365e-02,  3.9155e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3823e-03, -6.2222e-03,  8.8162e-03],\n",
      "          [ 1.0790e-02,  2.4676e-02, -1.1348e-03],\n",
      "          [ 8.8654e-03,  1.2834e-03,  3.0984e-03]],\n",
      "\n",
      "         [[-2.7174e-02,  4.0132e-03,  2.0407e-02],\n",
      "          [-7.0550e-03,  1.5352e-02,  9.0338e-03],\n",
      "          [-1.6099e-02,  9.7534e-03,  4.6980e-03]],\n",
      "\n",
      "         [[-9.6144e-03, -3.6165e-02, -3.8387e-02],\n",
      "          [ 3.3601e-02, -1.5980e-02, -1.6743e-02],\n",
      "          [ 2.0194e-02, -1.6857e-02, -8.7223e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1446e-02, -7.9653e-03, -2.7216e-03],\n",
      "          [-1.6675e-02, -1.3501e-02, -8.0623e-03],\n",
      "          [-3.2399e-02, -1.8515e-02, -1.5696e-02]],\n",
      "\n",
      "         [[-6.5072e-03, -1.7743e-02, -2.5871e-04],\n",
      "          [-2.3310e-04, -2.6993e-02, -6.7519e-03],\n",
      "          [ 1.1435e-02, -1.1948e-03, -3.0736e-02]],\n",
      "\n",
      "         [[ 9.8359e-03, -3.7046e-03,  8.9138e-03],\n",
      "          [ 1.1814e-02, -2.3603e-02, -1.6880e-02],\n",
      "          [-3.0696e-03, -2.7647e-02, -2.6927e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.3274e-03,  8.4475e-03, -2.1378e-02],\n",
      "          [-2.4539e-02, -2.3209e-02, -3.0842e-02],\n",
      "          [-3.0382e-03, -2.1148e-02,  8.7569e-04]],\n",
      "\n",
      "         [[-6.2193e-03,  1.0906e-02, -1.9042e-02],\n",
      "          [ 4.6286e-03, -1.2619e-02,  6.8502e-03],\n",
      "          [ 1.9081e-02, -9.7290e-03, -4.4475e-04]],\n",
      "\n",
      "         [[ 7.5588e-03, -3.9490e-03,  6.7236e-03],\n",
      "          [-5.4098e-03,  1.6697e-02, -5.9286e-03],\n",
      "          [-1.6690e-02, -9.8313e-03, -1.3769e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2473e-03, -2.8865e-03, -2.6985e-02],\n",
      "          [ 1.7022e-02,  1.0737e-02, -1.5340e-02],\n",
      "          [ 1.0081e-02, -1.8492e-02, -5.5916e-03]],\n",
      "\n",
      "         [[ 3.2465e-03, -1.4927e-02,  1.2801e-02],\n",
      "          [-1.2073e-02,  8.8696e-03,  4.8807e-03],\n",
      "          [ 4.6633e-03, -7.1818e-03, -1.0251e-02]],\n",
      "\n",
      "         [[-2.9047e-02, -1.2133e-02, -1.0134e-02],\n",
      "          [-1.8125e-02, -1.9154e-02, -8.4557e-03],\n",
      "          [ 1.7498e-02, -8.9503e-03,  1.6865e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6003e-02, -2.1221e-03, -8.7950e-03],\n",
      "          [ 3.0650e-02,  3.4946e-02, -1.5743e-02],\n",
      "          [ 2.5907e-02,  8.9330e-03, -9.0289e-03]],\n",
      "\n",
      "         [[-5.1967e-02, -2.9575e-02,  2.9569e-03],\n",
      "          [-3.1912e-02,  9.1124e-03,  1.2986e-02],\n",
      "          [-1.0705e-02,  1.2255e-02,  5.6985e-03]],\n",
      "\n",
      "         [[-3.9052e-02, -3.3527e-02, -2.9246e-02],\n",
      "          [ 1.1978e-02, -1.7398e-02, -1.8377e-02],\n",
      "          [-1.4227e-02, -1.1277e-02, -1.7449e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0050e-04,  5.1778e-03,  3.2241e-02],\n",
      "          [ 3.8629e-03,  5.6277e-03,  7.8718e-03],\n",
      "          [-1.7045e-02, -6.6026e-03, -3.8070e-02]],\n",
      "\n",
      "         [[-1.2758e-02,  6.7401e-03,  2.8171e-02],\n",
      "          [ 3.9364e-03, -1.0867e-02,  3.4126e-03],\n",
      "          [ 1.0829e-02,  1.1286e-03,  1.1950e-02]],\n",
      "\n",
      "         [[ 2.7371e-02, -5.6900e-03,  9.7991e-04],\n",
      "          [ 1.4160e-02, -1.4697e-02, -6.6451e-03],\n",
      "          [-1.1888e-02, -1.0766e-02, -2.5091e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3531e-03, -2.7325e-03,  1.5441e-02],\n",
      "          [ 3.4626e-02,  5.0105e-03,  4.0726e-02],\n",
      "          [ 3.9094e-05, -2.6296e-02,  4.0720e-03]],\n",
      "\n",
      "         [[-4.1502e-03, -1.4206e-02, -4.2386e-04],\n",
      "          [-3.8382e-02, -2.6260e-02, -1.0790e-02],\n",
      "          [-7.8913e-04, -3.9003e-04, -6.5437e-03]],\n",
      "\n",
      "         [[-4.0306e-02, -3.8566e-02, -2.4987e-02],\n",
      "          [-3.7116e-02, -2.8631e-02, -9.4943e-03],\n",
      "          [-2.0950e-02, -4.4870e-03, -2.4476e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4558e-03, -1.9234e-02, -2.4882e-02],\n",
      "          [-7.2855e-03, -1.2405e-02, -5.8555e-03],\n",
      "          [-2.7378e-02, -1.4643e-02,  1.6886e-03]],\n",
      "\n",
      "         [[ 3.5967e-03, -1.9323e-02, -1.4449e-02],\n",
      "          [ 7.1524e-03,  1.3946e-02, -1.3429e-02],\n",
      "          [-1.0531e-03, -1.8350e-02, -2.4411e-02]],\n",
      "\n",
      "         [[-2.0943e-02, -1.1849e-03,  1.1561e-02],\n",
      "          [-1.4982e-03, -1.9067e-02,  2.7055e-03],\n",
      "          [-1.5692e-02, -2.8036e-02, -1.7478e-02]]]])), ('conv_fc.7.weight', tensor([0.9447, 1.0230, 1.0731, 1.0259, 0.9721, 0.9887, 0.9521, 1.0070, 0.9721,\n",
      "        1.0538, 1.0146, 1.0611, 0.9410, 1.0311, 1.0278, 1.0288, 1.0264, 1.0113,\n",
      "        0.9627, 0.9807, 0.9810, 0.9882, 0.9421, 1.0133, 1.0261, 1.0374, 0.9765,\n",
      "        0.9616, 0.9598, 0.9510, 1.0452, 1.0273, 0.9847, 0.9652, 0.9868, 1.0028,\n",
      "        1.0325, 0.9824, 1.0011, 0.9765, 0.9497, 0.9954, 0.9839, 1.0409, 0.9905,\n",
      "        0.9501, 0.9914, 1.0317, 0.9868, 1.0374, 1.0078, 1.0624, 1.0085, 1.0265,\n",
      "        0.9719, 0.9758, 1.0205, 0.9911, 0.9033, 1.0114, 0.9908, 0.9888, 0.9927,\n",
      "        1.0300, 0.9887, 0.9670, 0.9689, 0.9908, 1.0168, 1.0224, 1.0324, 1.0780,\n",
      "        0.9878, 1.0101, 1.0104, 0.9049, 1.0056, 1.0057, 0.9885, 0.9932, 0.9615,\n",
      "        0.9940, 1.0367, 0.9999, 1.0174, 0.9674, 1.0060, 0.9264, 0.9592, 1.0011,\n",
      "        0.8842, 0.9719, 0.9741, 0.9876, 0.9975, 0.9739, 0.9535, 1.0036, 0.9013,\n",
      "        0.9471, 0.9836, 1.0347, 1.0243, 0.9612, 1.0384, 0.8878, 1.0114, 0.9510,\n",
      "        1.0032, 0.9408, 0.9154, 0.9324, 0.9895, 1.0726, 0.9762, 1.0391, 0.9719,\n",
      "        0.9521, 0.9461, 1.0259, 0.9765, 1.0063, 1.0389, 1.0443, 1.0267, 0.9975,\n",
      "        0.9879, 1.0032, 1.0251, 0.9724, 1.0241, 0.8887, 0.9841, 1.0048, 1.0136,\n",
      "        0.9872, 0.9570, 0.9773, 0.9514, 1.0025, 0.9883, 0.9355, 0.9678, 1.0179,\n",
      "        1.0019, 0.9711, 0.9621, 1.0250, 1.0091, 0.9549, 0.9572, 1.0215, 0.9661,\n",
      "        1.0430, 1.0006, 0.9953, 0.9141, 0.8812, 1.0341, 1.0783, 0.9866, 1.0087,\n",
      "        0.9746, 0.9740, 1.0395, 0.9674, 0.9506, 0.8991, 0.9999, 0.9488, 1.0600,\n",
      "        0.9894, 1.0815, 0.9704, 1.0321, 0.9681, 0.9713, 0.9592, 1.0091, 0.9719,\n",
      "        1.0017, 0.9930, 1.0772, 0.9509, 0.9573, 0.9734, 1.0196, 0.9485, 1.0026,\n",
      "        0.9595, 1.0010, 0.8990, 1.0506, 0.9618, 1.0024, 0.9368, 0.9724, 0.9147,\n",
      "        0.9287, 0.9458, 0.9911, 0.9866, 0.9685, 1.0401, 1.0030, 0.9699, 0.9297,\n",
      "        1.0113, 0.9456, 1.0079, 0.9614, 1.0864, 0.9952, 0.9921, 1.0082, 0.9697,\n",
      "        0.9938, 1.0249, 0.9063, 0.9943, 1.0513, 1.0166, 0.9856, 0.9264, 0.9969,\n",
      "        1.0807, 0.9477, 1.0122, 1.0817, 0.9710, 0.9386, 1.0139, 0.9603, 1.0701,\n",
      "        0.9184, 0.9675, 0.9522, 0.9947, 1.0007, 1.0022, 0.9917, 0.9583, 0.9595,\n",
      "        1.0121, 0.9942, 0.9693, 1.0232, 1.0189, 1.0737, 0.9612, 0.9644, 0.9750,\n",
      "        0.9655, 0.9759, 1.0360, 1.0089])), ('conv_fc.7.bias', tensor([-0.1209, -0.0558, -0.0087, -0.0744, -0.1380, -0.0386, -0.0612, -0.0555,\n",
      "        -0.0566,  0.0008, -0.1011, -0.0807, -0.1051,  0.0225, -0.0666, -0.0369,\n",
      "        -0.1063, -0.0996, -0.0577, -0.0573, -0.0461, -0.0350, -0.0359, -0.0449,\n",
      "        -0.0471, -0.0632, -0.0649, -0.0843, -0.0750, -0.0926, -0.0290, -0.1163,\n",
      "        -0.0241, -0.0496, -0.0309, -0.0325, -0.0312, -0.1075, -0.0947, -0.0802,\n",
      "         0.0124, -0.0327, -0.0939, -0.0582, -0.0318, -0.0807, -0.0248, -0.0040,\n",
      "        -0.1269, -0.0598, -0.0879,  0.0276, -0.0240, -0.0414, -0.0679, -0.0516,\n",
      "        -0.0220, -0.0493, -0.1259, -0.0419, -0.0806, -0.1217, -0.0447, -0.0540,\n",
      "        -0.0208, -0.1233, -0.0754, -0.0613, -0.0815, -0.0251, -0.0388, -0.0484,\n",
      "        -0.0303, -0.1046, -0.0998, -0.0809, -0.0421, -0.0057, -0.0584, -0.0545,\n",
      "        -0.0915, -0.0191, -0.1110, -0.0210, -0.0885, -0.1316, -0.0922, -0.0406,\n",
      "        -0.0930, -0.1609, -0.0785, -0.0702, -0.0494, -0.1189, -0.0242, -0.0857,\n",
      "        -0.1266, -0.0845, -0.1533, -0.1203, -0.0428, -0.0214, -0.0640, -0.1084,\n",
      "         0.0114, -0.0756, -0.0653, -0.1337, -0.0334, -0.1325, -0.1861, -0.1175,\n",
      "        -0.0418,  0.0215, -0.0764, -0.0429, -0.1234, -0.0745, -0.0538, -0.0807,\n",
      "        -0.0850, -0.0792, -0.1001, -0.0466, -0.0632, -0.0424, -0.1227, -0.1250,\n",
      "        -0.0606, -0.0792, -0.1052, -0.1301, -0.0897, -0.1004, -0.0367, -0.0921,\n",
      "        -0.0896, -0.0508, -0.1705, -0.0244, -0.0456, -0.0573, -0.0953, -0.0727,\n",
      "        -0.0877, -0.0360, -0.0760, -0.0578,  0.0156, -0.1030, -0.0678, -0.0109,\n",
      "        -0.0612, -0.0155, -0.0776, -0.0823, -0.0292, -0.0772, -0.0343,  0.0059,\n",
      "        -0.0665, -0.0443, -0.0210, -0.1345, -0.0814, -0.0672, -0.0686, -0.0610,\n",
      "        -0.0841, -0.0737, -0.0978, -0.0398, -0.0759, -0.1032, -0.0326, -0.0737,\n",
      "        -0.0981, -0.1064, -0.0289, -0.1050, -0.0304, -0.0854, -0.0144, -0.0143,\n",
      "        -0.1082, -0.0707, -0.0801, -0.0970, -0.0734, -0.0917, -0.0604, -0.0976,\n",
      "        -0.0385, -0.0482, -0.0550, -0.0289, -0.0874,  0.0403, -0.0594, -0.1479,\n",
      "        -0.0895, -0.0479, -0.0952, -0.0771, -0.0856, -0.1043, -0.1897, -0.0048,\n",
      "        -0.0435, -0.0651, -0.0709, -0.1161, -0.0574, -0.0532, -0.1214, -0.0675,\n",
      "        -0.0849, -0.0006, -0.1079, -0.1026, -0.0354, -0.0386, -0.0805, -0.1724,\n",
      "        -0.0397,  0.0403, -0.0893, -0.0834, -0.0210, -0.0836, -0.0751, -0.0853,\n",
      "        -0.0351,  0.0041, -0.0379, -0.0661, -0.1045, -0.0391, -0.0251, -0.0519,\n",
      "        -0.0793, -0.0675, -0.0812, -0.0398, -0.0496, -0.0631, -0.0539, -0.1020,\n",
      "         0.0701, -0.1003, -0.1048, -0.0838, -0.0368, -0.0567, -0.0680, -0.0112])), ('conv_fc.7.running_mean', tensor([ 7.3754e-01, -6.8572e-01, -8.0024e-01, -3.6067e-01,  3.1611e-01,\n",
      "        -4.4295e-01, -1.1136e+00,  2.3606e-01, -9.0504e-02, -8.8785e-01,\n",
      "        -8.4931e-01, -5.6835e-01, -2.7438e-01, -8.9698e-01,  4.1524e-02,\n",
      "        -3.7983e-01,  7.7466e-01,  4.2146e-02, -1.1576e+00, -1.0480e-01,\n",
      "        -1.8298e-01, -6.5624e-01, -6.4442e-01, -5.6361e-01, -1.3609e+00,\n",
      "        -6.6105e-02, -9.3752e-01,  9.4682e-01,  1.7716e-01,  1.4281e-01,\n",
      "        -4.7208e-01, -1.0405e+00, -5.1794e-01, -5.7431e-01, -1.2783e+00,\n",
      "        -8.1299e-01, -2.5782e-01,  6.0364e-01, -7.6185e-02, -1.1037e-01,\n",
      "        -1.7462e+00, -4.1941e-01, -1.0585e-01,  1.0011e-02, -1.0320e+00,\n",
      "        -1.5937e-01, -1.3603e+00, -2.7397e-01, -2.1824e-01, -7.4718e-01,\n",
      "        -5.2871e-01, -2.9930e-01, -3.2205e-01,  2.1834e-01,  7.6547e-01,\n",
      "        -6.8300e-03, -6.8147e-01, -1.0817e+00, -2.4815e-01, -6.3247e-01,\n",
      "        -1.0817e-01,  2.1652e-01, -7.3212e-01, -3.4510e-01, -1.1093e+00,\n",
      "         9.4621e-01,  2.3556e-01,  1.4216e-01, -9.1403e-02, -7.0392e-01,\n",
      "         7.4164e-02, -7.7204e-01, -1.7385e+00, -7.0548e-01,  5.5296e-01,\n",
      "        -1.1584e+00, -2.3919e-01, -6.0082e-01, -4.5249e-01, -6.7822e-01,\n",
      "         2.2100e-01, -1.4253e+00, -7.0226e-01, -8.3116e-01, -9.1857e-01,\n",
      "         8.4445e-01, -4.2085e-01, -1.0290e+00,  4.7250e-01, -6.7283e-01,\n",
      "        -2.0484e+00, -6.3664e-01, -8.3387e-02, -4.6393e-02, -1.5633e-01,\n",
      "        -3.0849e-01,  1.2384e+00, -1.3176e-01, -9.5450e-01,  4.7878e-02,\n",
      "        -1.7765e-01, -1.2548e+00,  1.3110e-01,  1.9858e-01, -6.2462e-01,\n",
      "        -4.8915e-01, -6.2530e-01,  7.9524e-01,  2.9096e-01, -2.3339e+00,\n",
      "         7.8828e-01, -5.3939e-01,  3.3986e-01, -4.3089e-01,  2.3416e-01,\n",
      "         6.2983e-01,  1.7611e-01, -9.5143e-01, -1.4152e+00, -1.6102e-01,\n",
      "        -1.9025e-01, -2.7834e-01, -3.9564e-01, -3.8694e-02, -9.9763e-01,\n",
      "        -6.6296e-01,  2.8642e-01,  4.9772e-01, -4.3005e-02, -2.6547e-01,\n",
      "        -1.7421e-01, -1.6083e+00, -8.2307e-01, -3.1927e-02, -5.4814e-02,\n",
      "         3.5098e-02, -1.0630e-01, -6.3750e-01,  1.5583e-01, -6.9166e-01,\n",
      "        -1.2248e+00, -5.4961e-01, -5.5134e-01, -4.1573e-01,  1.8287e-01,\n",
      "        -6.6739e-01, -1.6975e-02, -4.6609e-01, -5.6622e-01, -6.6795e-01,\n",
      "         4.0622e-01, -6.8454e-01, -7.9774e-01, -3.1732e-01, -1.5726e+00,\n",
      "        -6.4337e-03, -1.6596e+00, -1.5269e+00, -3.4044e-01, -1.2497e-03,\n",
      "        -9.9454e-01, -1.0202e-02, -1.2706e+00,  6.7225e-01, -4.5838e-01,\n",
      "        -1.0165e+00, -8.8935e-01, -1.5927e+00, -2.1436e-02, -1.8011e+00,\n",
      "        -2.3514e-01, -1.2955e+00, -8.4719e-02, -3.7956e-01, -3.3420e-01,\n",
      "         2.3495e-01,  6.4304e-02,  6.0871e-01, -5.9540e-01,  8.1585e-01,\n",
      "        -3.2696e-01,  5.5425e-01, -6.3745e-01, -6.5087e-01, -8.9119e-01,\n",
      "        -1.1252e-01, -7.5325e-01,  5.4581e-01, -1.6959e-01, -3.3810e-01,\n",
      "        -3.5435e-01, -1.2113e+00, -3.7917e-01, -1.4440e+00,  4.3587e-01,\n",
      "        -1.1245e+00,  4.4351e-01, -2.2397e+00, -9.7664e-01,  1.0383e+00,\n",
      "         4.2129e-01, -1.9338e-01,  8.9669e-01, -3.4724e-01,  2.1650e-02,\n",
      "         6.9200e-01,  1.4588e+00, -7.1679e-01, -1.3018e+00, -5.2482e-02,\n",
      "        -7.3909e-01, -3.6386e-02, -7.0328e-01, -7.3315e-01,  2.0092e-01,\n",
      "         5.3908e-01, -6.0134e-01, -1.3851e+00, -1.1679e+00,  7.8431e-02,\n",
      "        -1.4467e+00, -2.1406e-01,  1.0753e-01,  1.1638e+00,  2.7322e-02,\n",
      "        -3.0896e-01,  8.4004e-01,  8.0289e-01, -2.4674e-01, -6.4839e-01,\n",
      "        -1.0061e+00, -1.0741e+00, -1.2362e+00, -5.2522e-01, -1.3803e+00,\n",
      "         2.5135e-01,  9.6399e-01, -4.9238e-01, -6.0929e-01, -2.8270e-01,\n",
      "         1.8061e-01, -6.1435e-01,  3.6088e-01, -4.7005e-01, -5.0887e-01,\n",
      "         3.7102e-01,  2.5599e-01, -7.4123e-01, -4.0928e-01, -1.1599e-01,\n",
      "         6.6859e-01,  1.2830e-01, -1.2077e+00, -1.2839e+00, -7.8393e-01,\n",
      "        -4.9959e-01])), ('conv_fc.7.running_var', tensor([0.9629, 0.6782, 0.9177, 1.0225, 1.3239, 0.5382, 0.7874, 0.5065, 0.6547,\n",
      "        1.0951, 1.0250, 1.1273, 1.2201, 0.7191, 0.9656, 0.6893, 1.0155, 0.7721,\n",
      "        0.8311, 0.6385, 0.5722, 0.5745, 1.0859, 1.0934, 1.1473, 0.7855, 1.4520,\n",
      "        0.6799, 0.8070, 0.7880, 1.2095, 1.3537, 0.5913, 0.8376, 1.5535, 0.7893,\n",
      "        0.4765, 0.8163, 0.7579, 0.8603, 2.1120, 0.6460, 0.4692, 0.6879, 1.3711,\n",
      "        0.8638, 1.3176, 0.5205, 1.6074, 0.8306, 0.9556, 0.7584, 0.7272, 1.1941,\n",
      "        0.7333, 0.9628, 0.9162, 0.7045, 1.4540, 0.8390, 0.7771, 0.9852, 1.7858,\n",
      "        0.4750, 1.3047, 0.8657, 0.5256, 1.0215, 0.7077, 0.9453, 1.4589, 1.2414,\n",
      "        1.3815, 1.0073, 1.1859, 1.0869, 0.6342, 1.4869, 1.1001, 0.9356, 0.4773,\n",
      "        1.3481, 1.2899, 0.8987, 1.1979, 0.8478, 1.0526, 1.6886, 0.6871, 1.1009,\n",
      "        1.8798, 0.9557, 0.9610, 0.7882, 0.9295, 0.8508, 1.0118, 0.6268, 2.2020,\n",
      "        0.8863, 0.8625, 1.5863, 0.8741, 0.6230, 0.9162, 1.9660, 0.8016, 0.8175,\n",
      "        0.4983, 2.8287, 1.5056, 1.6344, 0.9298, 1.1775, 0.6885, 0.6149, 0.7312,\n",
      "        0.9507, 1.3331, 1.3480, 1.3051, 0.8067, 1.1104, 0.9482, 1.9171, 1.0224,\n",
      "        0.6877, 1.2189, 0.6063, 0.9018, 1.0211, 1.2370, 0.6463, 0.8941, 0.7543,\n",
      "        1.3545, 0.9176, 0.8583, 0.9844, 0.6982, 1.1423, 0.7467, 1.0336, 0.6465,\n",
      "        0.6345, 0.8600, 1.0020, 1.3054, 1.2239, 1.7158, 0.8366, 0.8577, 0.8920,\n",
      "        0.6710, 1.3385, 0.6116, 1.6152, 1.0064, 0.7810, 0.8641, 1.0496, 0.6546,\n",
      "        1.2457, 0.9372, 1.0597, 0.9095, 1.0287, 1.7962, 0.7781, 1.7019, 0.8992,\n",
      "        1.2897, 1.4935, 0.6098, 1.1111, 0.5884, 0.5735, 0.7873, 1.5490, 0.7515,\n",
      "        1.7173, 0.6096, 1.7891, 1.1878, 0.8133, 0.9066, 0.9767, 0.9125, 0.9358,\n",
      "        1.5013, 1.3325, 1.7522, 1.0697, 1.1883, 0.7154, 1.4619, 0.5425, 2.5109,\n",
      "        0.9744, 0.8107, 0.7276, 0.8354, 0.8490, 1.0915, 0.7739, 0.3950, 1.2913,\n",
      "        1.1487, 1.1828, 0.6381, 1.0809, 0.9378, 0.9909, 0.8333, 0.6852, 0.5948,\n",
      "        1.2286, 1.2922, 1.6359, 0.6839, 1.9555, 0.9604, 0.8084, 0.9011, 0.4583,\n",
      "        1.1793, 0.6946, 0.6748, 0.9747, 0.8899, 0.8962, 1.0780, 1.0085, 1.0210,\n",
      "        1.7082, 0.3787, 0.7608, 0.7464, 0.6753, 0.7726, 0.9866, 1.6355, 1.2175,\n",
      "        0.6919, 1.0242, 1.1607, 0.7007, 1.1755, 1.2777, 0.9526, 1.4322, 0.7726,\n",
      "        0.9451, 1.3370, 0.9018, 0.6806])), ('conv_fc.7.num_batches_tracked', tensor(19525)), ('conv_fc.10.weight', tensor([[[[ 9.1372e-03,  5.3300e-03,  1.1134e-02],\n",
      "          [-1.2575e-02,  7.3924e-03, -1.3668e-02],\n",
      "          [-2.3547e-02,  1.7734e-02, -9.4999e-05]],\n",
      "\n",
      "         [[ 2.0492e-02, -3.0067e-03, -1.0137e-02],\n",
      "          [-3.1882e-02, -1.3833e-02, -3.5352e-02],\n",
      "          [-2.1486e-02,  1.1736e-02, -4.2891e-03]],\n",
      "\n",
      "         [[-4.5909e-02,  7.7973e-03,  6.9592e-03],\n",
      "          [-1.7523e-02,  1.1649e-02,  3.2748e-02],\n",
      "          [ 6.6656e-03,  4.3743e-02,  2.7461e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2737e-02, -3.2426e-03,  1.7619e-02],\n",
      "          [-1.3861e-02,  6.5323e-03, -2.3946e-02],\n",
      "          [-2.2839e-02, -1.9778e-02, -1.6651e-02]],\n",
      "\n",
      "         [[-4.3823e-02,  5.2484e-03, -1.7640e-02],\n",
      "          [-2.3829e-02, -7.6896e-04,  3.4651e-03],\n",
      "          [ 5.3546e-04,  2.4113e-02,  2.1055e-02]],\n",
      "\n",
      "         [[-5.6384e-03, -1.3787e-02, -5.0507e-02],\n",
      "          [ 4.3456e-03, -1.2046e-02, -3.5370e-02],\n",
      "          [ 1.8815e-03, -1.4281e-02, -1.6321e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1862e-03, -7.0756e-03, -4.5732e-03],\n",
      "          [ 7.6696e-03, -2.8195e-03, -7.6400e-03],\n",
      "          [-1.4511e-02, -3.0126e-02, -3.8092e-02]],\n",
      "\n",
      "         [[-7.1138e-03, -6.2437e-03, -2.1960e-02],\n",
      "          [-2.7204e-02, -1.4921e-02, -3.3255e-03],\n",
      "          [-3.1139e-03, -4.3365e-03,  1.5717e-03]],\n",
      "\n",
      "         [[-1.5904e-02, -1.7185e-02, -3.6101e-02],\n",
      "          [-3.6925e-02, -3.4215e-02, -3.4863e-02],\n",
      "          [-3.5878e-02, -4.2281e-02, -3.3219e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4521e-03,  2.2874e-02, -6.5335e-04],\n",
      "          [ 1.1384e-02,  1.6730e-02,  2.9719e-02],\n",
      "          [-5.6540e-03,  7.0903e-03,  1.1539e-02]],\n",
      "\n",
      "         [[-3.9665e-02, -2.4931e-02, -6.4859e-02],\n",
      "          [-1.8473e-02, -3.4834e-02, -5.7551e-02],\n",
      "          [-9.2898e-03, -3.6318e-02, -4.0169e-02]],\n",
      "\n",
      "         [[-1.4172e-02, -4.2486e-02, -1.5691e-02],\n",
      "          [-2.7290e-02, -2.3826e-02, -2.2408e-02],\n",
      "          [-3.6940e-02,  6.2266e-03, -1.1574e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4765e-02,  2.5487e-02,  1.1433e-02],\n",
      "          [ 2.8611e-02,  1.7480e-02,  9.8606e-03],\n",
      "          [-1.1185e-02,  1.3109e-02, -6.3769e-03]],\n",
      "\n",
      "         [[-1.3834e-02, -2.0821e-02,  1.5557e-03],\n",
      "          [ 1.3330e-02, -1.5363e-02,  2.5092e-02],\n",
      "          [ 7.8373e-03,  1.9017e-02,  3.7289e-02]],\n",
      "\n",
      "         [[-4.4434e-03,  2.8892e-02, -2.2185e-02],\n",
      "          [ 1.7524e-02,  3.9729e-02,  3.7968e-04],\n",
      "          [ 1.1153e-02,  2.1900e-02, -3.3677e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7379e-03,  2.1124e-02,  2.7707e-02],\n",
      "          [-1.9259e-03, -1.1697e-02,  1.8061e-02],\n",
      "          [ 3.2126e-03, -1.0363e-02,  2.3667e-02]],\n",
      "\n",
      "         [[ 1.6938e-02,  2.7119e-02, -1.0098e-02],\n",
      "          [-2.8587e-03,  5.0991e-02, -1.3880e-02],\n",
      "          [-1.8050e-02,  2.5569e-02,  5.5607e-03]],\n",
      "\n",
      "         [[ 5.2875e-03,  7.9247e-03, -1.5223e-02],\n",
      "          [ 2.4248e-02,  4.0827e-03, -1.7068e-02],\n",
      "          [ 1.0785e-02, -9.1828e-03,  5.1463e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1978e-02, -1.3424e-02, -1.6628e-02],\n",
      "          [-1.2598e-02, -2.9752e-03, -1.1249e-04],\n",
      "          [ 9.9809e-04,  1.1535e-02, -2.8917e-02]],\n",
      "\n",
      "         [[-7.3892e-03,  7.5921e-03, -1.8871e-02],\n",
      "          [-3.4421e-03,  6.5649e-03, -1.2414e-02],\n",
      "          [-1.1723e-02, -4.8332e-03, -3.1680e-02]],\n",
      "\n",
      "         [[-5.4522e-03, -2.1727e-02,  9.4192e-03],\n",
      "          [-2.7905e-02, -3.0357e-02,  5.0985e-03],\n",
      "          [ 1.1548e-02,  1.4845e-02, -2.5147e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6814e-02, -2.2787e-02, -2.5381e-03],\n",
      "          [ 1.0561e-03,  4.8918e-03, -2.4878e-02],\n",
      "          [ 8.3245e-03, -2.5109e-02,  6.6615e-04]],\n",
      "\n",
      "         [[-7.9455e-03,  2.7306e-02,  2.5304e-02],\n",
      "          [ 1.7346e-02,  1.1395e-02, -6.0269e-03],\n",
      "          [-8.2728e-03,  6.3886e-03, -3.4263e-03]],\n",
      "\n",
      "         [[ 9.9970e-03, -1.0191e-03,  2.4185e-02],\n",
      "          [-1.0795e-02,  1.4162e-02, -8.7597e-04],\n",
      "          [-1.4726e-03, -3.1796e-04,  1.2592e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4525e-02, -4.6315e-02, -3.6289e-02],\n",
      "          [-1.8323e-02, -1.6107e-02, -3.5522e-02],\n",
      "          [-1.1681e-02, -2.4905e-02,  3.0870e-03]],\n",
      "\n",
      "         [[-2.8623e-03,  2.0935e-02,  1.8879e-02],\n",
      "          [-2.5094e-02, -6.0287e-03, -2.3209e-02],\n",
      "          [-1.2427e-02, -3.2038e-02, -3.1424e-02]],\n",
      "\n",
      "         [[ 5.5131e-03, -2.0696e-02,  1.4726e-03],\n",
      "          [ 1.6458e-02, -1.0663e-02,  6.5492e-03],\n",
      "          [ 1.6640e-02,  1.3119e-02,  2.1914e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1926e-03,  1.0751e-02,  1.3598e-02],\n",
      "          [ 5.4775e-03,  3.3292e-02,  1.6656e-02],\n",
      "          [-1.0175e-02,  1.3554e-02,  7.9755e-05]],\n",
      "\n",
      "         [[ 1.2229e-02,  2.9442e-03,  2.2145e-02],\n",
      "          [ 1.1008e-02,  2.0643e-02, -2.2024e-02],\n",
      "          [ 4.0025e-02,  2.8220e-02,  1.6884e-02]],\n",
      "\n",
      "         [[ 2.3168e-02,  1.1438e-02,  1.6299e-02],\n",
      "          [-6.7184e-03,  2.9050e-03,  1.4633e-02],\n",
      "          [ 6.7844e-03,  1.3260e-02,  8.5423e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4520e-02,  2.1866e-02, -3.8276e-03],\n",
      "          [ 3.5655e-02,  1.5094e-02,  3.7895e-03],\n",
      "          [ 2.3344e-02, -7.9817e-03, -1.4183e-02]],\n",
      "\n",
      "         [[ 8.3483e-03,  3.9197e-03,  3.6367e-02],\n",
      "          [ 2.5147e-02, -3.2616e-03,  6.7045e-03],\n",
      "          [ 5.7768e-03, -1.2458e-02,  4.6632e-02]],\n",
      "\n",
      "         [[ 3.0113e-02, -2.4426e-03, -8.6150e-03],\n",
      "          [ 4.7721e-02,  1.2252e-02,  7.3724e-03],\n",
      "          [ 2.1922e-02,  4.1524e-03,  8.0000e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.7740e-03,  1.8588e-02,  1.7563e-02],\n",
      "          [-1.5394e-02, -1.2967e-02,  1.6956e-02],\n",
      "          [-8.4691e-03,  4.9545e-04, -4.4121e-03]],\n",
      "\n",
      "         [[ 1.0189e-02,  1.9197e-02, -5.8570e-04],\n",
      "          [ 4.3114e-02,  4.4729e-02, -1.5139e-02],\n",
      "          [ 1.5420e-02,  3.9595e-02, -1.7305e-03]],\n",
      "\n",
      "         [[ 7.6429e-03, -2.0511e-02, -1.0566e-02],\n",
      "          [ 4.2766e-02,  2.1078e-02, -1.9036e-02],\n",
      "          [ 3.0598e-02,  1.2943e-03,  8.0025e-03]]]])), ('conv_fc.11.weight', tensor([0.9733, 1.0188, 0.9690, 0.9532, 0.9773, 1.0392, 0.9338, 0.9705, 1.0281,\n",
      "        1.0120, 0.9615, 0.9966, 0.9972, 0.9212, 0.9281, 0.9490, 0.9679, 0.9788,\n",
      "        0.9260, 0.9196, 1.0013, 0.9605, 0.9082, 0.9812, 0.9653, 0.9951, 0.9694,\n",
      "        1.0288, 0.9540, 0.9502, 0.9726, 0.9798, 1.0260, 0.9569, 0.9640, 0.9275,\n",
      "        0.9894, 0.9813, 0.9719, 0.9562, 0.9064, 1.0515, 0.9194, 0.9437, 0.9170,\n",
      "        0.9072, 1.0229, 0.9817, 0.9870, 1.0061, 1.0225, 0.9583, 1.0233, 0.9889,\n",
      "        1.0455, 0.9805, 0.9535, 1.0030, 1.0097, 0.9791, 0.9455, 1.0181, 0.9954,\n",
      "        0.9232, 0.9944, 0.9765, 1.0112, 0.9057, 0.9569, 0.9988, 0.9242, 0.9555,\n",
      "        1.0093, 0.9105, 0.9588, 0.9373, 1.0251, 0.9554, 0.9199, 1.0073, 0.9622,\n",
      "        0.9981, 1.0443, 1.0075, 0.9500, 0.9634, 1.0252, 0.9842, 0.9265, 1.0111,\n",
      "        0.9887, 1.0055, 0.9825, 0.9807, 1.0324, 0.9907, 0.9132, 1.0076, 0.9614,\n",
      "        1.0099, 0.9445, 1.0745, 0.9471, 0.9780, 1.0502, 0.8944, 0.9742, 0.9725,\n",
      "        0.9458, 0.9626, 0.9022, 0.9975, 0.9178, 0.9393, 0.9565, 0.9350, 0.9472,\n",
      "        0.9674, 1.0063, 0.9685, 0.9691, 0.9815, 0.9676, 1.0722, 0.9908, 0.9779,\n",
      "        0.9932, 1.0366, 1.0070, 0.9970, 0.9544, 1.0074, 0.9775, 0.9789, 1.0588,\n",
      "        1.0197, 0.9981, 0.9484, 0.9808, 0.9876, 0.9450, 0.9779, 0.9882, 0.9590,\n",
      "        0.9643, 0.9718, 0.9956, 0.9110, 0.9587, 0.9492, 0.8918, 0.9489, 0.9783,\n",
      "        1.0174, 0.9675, 1.0094, 0.9470, 0.9336, 1.0002, 0.9603, 1.0374, 1.0236,\n",
      "        0.9188, 1.0149, 1.0026, 0.9586, 0.9388, 0.9890, 0.9893, 0.9468, 0.9948,\n",
      "        0.9761, 0.9172, 0.9260, 0.9565, 0.9866, 0.9918, 0.9969, 0.9638, 0.9973,\n",
      "        1.0255, 0.9726, 0.9250, 1.0018, 1.0012, 0.9031, 0.9307, 1.0108, 1.0803,\n",
      "        1.0102, 0.9123, 0.9408, 0.9649, 0.9524, 0.9287, 1.0072, 0.9323, 1.0120,\n",
      "        0.9180, 0.9526, 0.9458, 0.9836, 0.9763, 0.9404, 0.9099, 0.9863, 0.9026,\n",
      "        0.9244, 0.9533, 0.9903, 0.9728, 0.9752, 0.9519, 0.9439, 0.9651, 0.9467,\n",
      "        1.0413, 1.0201, 0.9372, 0.9965, 0.9839, 0.9480, 1.0354, 0.9875, 1.0454,\n",
      "        0.9459, 0.9726, 0.9609, 0.9436, 0.9812, 0.9597, 0.9533, 0.9960, 0.9161,\n",
      "        0.9936, 0.9544, 0.9827, 0.9960, 0.9530, 1.0116, 0.9432, 0.9772, 0.9990,\n",
      "        0.9546, 0.9618, 0.9901, 0.9813, 0.9646, 0.9400, 0.9592, 1.0439, 0.9511,\n",
      "        0.9747, 0.9659, 0.9647, 0.9500])), ('conv_fc.11.bias', tensor([-0.1480, -0.0588, -0.1125, -0.0288, -0.0600, -0.0349, -0.0632, -0.0827,\n",
      "        -0.1096, -0.0335, -0.0651, -0.1243, -0.0753, -0.1027, -0.1037, -0.1107,\n",
      "        -0.1549, -0.0437, -0.1476, -0.0506, -0.0579, -0.0830, -0.0777, -0.0527,\n",
      "        -0.1189, -0.0521, -0.1768, -0.0525, -0.2611, -0.0649, -0.0331, -0.0403,\n",
      "        -0.0853, -0.0934, -0.0756, -0.1174, -0.1052, -0.0786, -0.1392, -0.1206,\n",
      "        -0.0939, -0.1111, -0.0896, -0.0888, -0.0302, -0.0739, -0.1277, -0.1885,\n",
      "        -0.1196, -0.0803, -0.0313, -0.0478, -0.0440, -0.0877, -0.0774, -0.0319,\n",
      "        -0.1080, -0.0703, -0.0599, -0.0675, -0.1275, -0.0247, -0.0537, -0.1042,\n",
      "        -0.0156, -0.0893, -0.2149, -0.1122, -0.0890, -0.0515, -0.0678, -0.0793,\n",
      "        -0.1171, -0.1870, -0.0747, -0.1257, -0.0709, -0.0811, -0.1568, -0.0605,\n",
      "        -0.0727, -0.0105, -0.0415, -0.0360, -0.0727, -0.1019, -0.0640, -0.0615,\n",
      "        -0.0684, -0.0638, -0.0650, -0.0708, -0.0659, -0.0608, -0.0624, -0.0485,\n",
      "        -0.1760, -0.0639, -0.0824, -0.0684, -0.0859, -0.0549, -0.0606, -0.0991,\n",
      "        -0.0410, -0.1674, -0.0888, -0.1008, -0.0398, -0.0428, -0.1071, -0.0551,\n",
      "        -0.1080, -0.0818, -0.1170, -0.0677, -0.0831, -0.0833, -0.0466, -0.1133,\n",
      "        -0.0371, -0.0266, -0.1060, -0.0031, -0.0581, -0.1239, -0.1359, -0.0520,\n",
      "        -0.1101, -0.0407, -0.0824, -0.1164, -0.0972, -0.0520, -0.0789, -0.0594,\n",
      "        -0.1012, -0.1008, -0.0860, -0.1460, -0.1068, -0.1507, -0.0677, -0.0249,\n",
      "        -0.0591, -0.1042, -0.0572, -0.0855, -0.0790, -0.0545, -0.0920, -0.0469,\n",
      "        -0.0738, -0.0404, -0.1022, -0.0805, -0.0868, -0.0840, -0.0354, -0.1840,\n",
      "        -0.0645, -0.1045, -0.0897, -0.0542, -0.1010, -0.0542, -0.0959, -0.0443,\n",
      "        -0.2084, -0.0688, -0.1700, -0.0931, -0.0820, -0.1095, -0.0797, -0.0776,\n",
      "        -0.0846, -0.1561, -0.0949, -0.1260, -0.0386, -0.1082, -0.1016, -0.0702,\n",
      "        -0.0202, -0.0662, -0.1346, -0.0648, -0.0811, -0.0886, -0.0922, -0.0200,\n",
      "        -0.0599, -0.1173, -0.0879, -0.0665, -0.1137, -0.1320, -0.2222, -0.0631,\n",
      "        -0.1202, -0.0591, -0.1022, -0.0136, -0.0795, -0.0650, -0.0819, -0.1062,\n",
      "        -0.1655, -0.1168, -0.0991, -0.1265, -0.0783, -0.0800, -0.0945, -0.0224,\n",
      "        -0.0858, -0.0558, -0.0999, -0.1885, -0.0521, -0.0369, -0.0391, -0.1129,\n",
      "        -0.0632, -0.1289, -0.0769, -0.1047, -0.2244, -0.1136, -0.0431, -0.0786,\n",
      "        -0.0575, -0.1085, -0.2525, -0.0717, -0.1754, -0.0986, -0.0704, -0.0496,\n",
      "        -0.0598, -0.1364, -0.1148, -0.0853, -0.1022, -0.1162, -0.1073, -0.0536,\n",
      "        -0.1052, -0.0720, -0.0655, -0.1168, -0.1019, -0.0837, -0.0825, -0.0260])), ('conv_fc.11.running_mean', tensor([-0.5756, -1.6984,  1.0814, -0.9942, -0.7419, -0.3351, -0.6250, -1.5266,\n",
      "        -0.6437, -1.1698, -0.3471, -0.7279, -1.6035, -0.6880, -0.4636, -1.2751,\n",
      "        -0.3594, -1.0140,  0.0385, -1.4300, -1.0416, -0.3275, -1.8824, -1.1548,\n",
      "        -0.2910, -1.3815, -0.5722, -0.5898,  0.6953, -0.7107, -0.5984, -0.3547,\n",
      "        -0.6379,  0.4237, -1.2670, -0.3802, -0.0207, -0.0870, -0.2815, -0.2350,\n",
      "        -1.4232, -0.8649, -0.3834, -0.3592, -1.4625, -0.9988,  0.2552,  0.5136,\n",
      "        -1.0492,  0.0854, -0.1941, -0.8582, -1.2421, -1.4090, -1.9282, -0.2764,\n",
      "        -0.0152, -0.9568, -0.8302,  0.7521, -0.3777, -0.6302, -1.1976, -1.4272,\n",
      "        -0.1310,  0.0137, -0.6356, -2.5522, -1.1164,  0.0230, -0.1191, -1.1307,\n",
      "        -0.9839, -0.6139,  0.1275, -2.0979, -0.6390, -0.1520, -0.3984, -1.1193,\n",
      "        -0.3002, -1.6036, -0.9386, -1.7941, -2.0998, -0.3282, -0.5670, -0.0653,\n",
      "        -1.1739, -1.0287, -0.3465,  0.1000, -0.6575, -0.1599, -0.8764, -1.4928,\n",
      "        -1.0232, -0.1864,  0.1373, -1.1772,  0.1001, -0.9802, -0.3334, -0.2924,\n",
      "        -2.2219, -1.2511, -0.4649,  0.4982, -1.7545, -0.0892, -2.1287, -1.4381,\n",
      "        -0.7761,  0.8048, -0.5576, -1.6028,  0.4970, -0.3892, -0.3631, -0.8814,\n",
      "        -1.3302, -0.3086, -0.8663, -0.8146, -1.1002, -0.5622, -0.2559, -0.9350,\n",
      "        -0.6771,  0.0482, -0.9701,  0.0543, -0.6978, -0.7314,  0.0198, -1.9996,\n",
      "        -0.7958, -0.6250, -0.7295, -0.0933,  0.1891,  0.1288, -0.5893, -0.4256,\n",
      "        -0.7903, -0.0116, -0.7440,  0.3305,  0.2025, -0.4853, -1.6654, -0.2617,\n",
      "        -0.8337,  0.0111, -0.2245,  0.4396, -0.5426, -1.3319, -1.9816, -0.7491,\n",
      "        -0.3249, -0.9011, -0.3466, -0.4758, -0.1364, -0.7372, -1.4028,  0.1870,\n",
      "         0.3413, -0.4713, -1.3166,  1.2666, -0.1153,  0.2317, -0.7770, -1.2703,\n",
      "        -0.4656, -0.6352, -0.7813, -0.5213, -0.3075, -0.6045, -1.5930, -0.4934,\n",
      "        -0.2363, -1.3362, -0.2250,  0.0414, -0.8886, -0.0706, -0.7439, -1.2763,\n",
      "        -0.0487,  0.7276, -1.2337, -0.2724, -1.2050, -0.3292,  1.2556, -2.7889,\n",
      "        -0.8707, -1.6102, -0.1494, -1.3054, -0.2340, -0.9335, -0.0137, -1.6707,\n",
      "        -0.5731, -0.9563,  0.1385,  0.2953,  0.1547, -0.3199, -0.3650, -1.4872,\n",
      "        -0.0938, -0.6954,  0.8135, -0.9238, -0.0536, -0.9147, -1.3830, -0.1784,\n",
      "        -0.2008, -0.4602, -0.6715, -1.3257, -1.5061, -0.3469, -0.8004, -0.5444,\n",
      "        -1.3629, -1.3398,  0.9877, -0.2250, -1.4069, -0.5176, -0.5457, -0.8551,\n",
      "        -0.5118, -0.1497, -0.9711, -0.1250, -0.7951, -0.7964, -0.4988, -0.1350,\n",
      "        -0.5910, -0.2417, -1.6147, -1.3970,  0.2854,  0.6797, -1.0235, -1.1424])), ('conv_fc.11.running_var', tensor([0.9741, 1.7527, 0.6747, 0.7939, 0.7201, 0.8201, 0.8724, 1.4175, 0.6447,\n",
      "        1.2713, 0.6281, 0.6368, 2.0715, 0.8032, 0.8747, 0.8359, 0.9349, 0.8444,\n",
      "        1.1434, 1.4173, 0.8764, 0.5083, 1.8958, 1.1769, 0.6810, 1.2415, 1.0353,\n",
      "        0.8039, 1.5747, 0.9161, 0.6875, 0.6012, 0.8504, 0.4527, 1.1240, 0.9925,\n",
      "        0.7019, 0.6893, 1.0978, 0.7844, 0.6701, 1.4136, 1.1997, 0.5615, 1.3997,\n",
      "        1.2850, 1.0742, 1.0544, 0.7761, 0.5049, 0.6215, 0.6617, 1.2082, 1.2691,\n",
      "        1.5346, 1.0351, 1.0951, 1.0697, 0.9358, 0.7124, 0.9458, 0.8624, 0.6400,\n",
      "        1.1559, 0.6230, 0.8139, 1.2686, 2.3028, 0.6348, 0.7559, 1.0118, 0.8095,\n",
      "        0.9742, 1.0239, 0.4853, 1.7079, 0.7525, 0.9248, 0.8842, 1.0237, 0.6885,\n",
      "        1.3288, 0.9079, 1.0390, 2.1439, 0.8663, 0.9626, 0.6139, 1.1208, 0.9199,\n",
      "        0.9317, 0.9233, 0.5357, 0.5847, 0.8139, 0.7188, 1.1255, 0.5533, 0.4514,\n",
      "        0.8708, 0.7204, 1.0554, 0.9201, 0.8204, 1.1318, 1.1935, 0.8117, 0.6356,\n",
      "        1.4649, 0.7764, 2.1694, 0.8254, 1.1396, 0.9300, 1.1031, 1.0181, 0.8019,\n",
      "        0.5112, 0.8066, 1.5136, 0.7156, 0.5628, 0.7692, 0.9763, 0.8239, 0.7356,\n",
      "        0.7802, 0.9444, 1.0669, 0.8866, 0.8125, 0.7775, 0.8143, 0.5014, 1.3197,\n",
      "        1.0447, 0.6974, 1.4712, 0.8713, 0.8288, 0.7333, 0.8998, 0.9605, 0.6571,\n",
      "        0.6339, 0.5780, 0.8631, 0.7603, 0.6348, 0.8197, 0.9993, 1.4425, 0.6831,\n",
      "        0.6484, 0.9608, 0.7113, 0.5721, 1.2455, 1.0998, 1.3490, 0.8758, 0.6401,\n",
      "        1.1021, 0.8125, 0.7956, 0.9420, 0.9244, 0.8131, 1.4849, 1.4709, 1.2263,\n",
      "        0.9009, 1.3678, 0.5632, 0.8793, 1.1984, 0.9406, 0.9422, 0.5994, 0.9630,\n",
      "        0.5078, 0.6796, 0.7580, 1.1911, 0.7134, 1.4415, 1.2276, 0.8048, 0.9109,\n",
      "        0.8369, 0.5378, 1.3232, 0.8037, 0.6715, 0.9164, 0.7168, 1.1147, 1.4319,\n",
      "        1.1260, 2.0039, 0.9303, 0.8755, 0.8246, 1.0907, 1.8207, 0.6799, 1.1106,\n",
      "        1.4054, 0.8017, 1.0117, 0.6904, 1.0923, 0.6954, 1.0846, 0.7291, 1.7907,\n",
      "        0.9595, 0.6742, 0.8862, 1.6819, 0.6093, 1.4358, 1.2733, 0.7719, 0.7743,\n",
      "        0.7182, 0.4700, 0.9726, 1.6812, 0.6665, 0.9285, 1.1382, 0.9844, 1.3420,\n",
      "        1.7214, 1.3501, 1.6075, 0.5050, 0.7679, 0.9581, 0.7686, 0.6219, 1.2939,\n",
      "        0.5036, 1.4204, 0.9675, 1.0873, 0.5459, 0.9817, 0.9389, 0.9842, 0.7652,\n",
      "        1.1480, 0.4464, 1.6050, 1.4126])), ('conv_fc.11.num_batches_tracked', tensor(19525)), ('conv_fc.13.weight', tensor([[[[-1.4221e-02, -3.9435e-02,  2.4158e-04],\n",
      "          [-2.2572e-02,  2.5745e-03,  8.4531e-03],\n",
      "          [-1.4516e-02, -1.1286e-03,  2.1555e-02]],\n",
      "\n",
      "         [[ 1.2599e-02, -8.1664e-03,  2.4214e-02],\n",
      "          [ 2.3035e-02,  4.9078e-02,  4.6653e-02],\n",
      "          [ 2.1202e-02,  4.0421e-02,  4.1866e-02]],\n",
      "\n",
      "         [[ 3.0030e-03,  2.6281e-02,  1.1385e-02],\n",
      "          [-1.0556e-02,  4.3879e-04, -4.6262e-03],\n",
      "          [-1.8801e-02,  4.9645e-03,  9.0987e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3314e-02, -2.6740e-02,  2.0773e-03],\n",
      "          [ 9.4355e-03,  7.8244e-03, -1.5613e-02],\n",
      "          [-2.2926e-02,  3.3346e-03, -9.6289e-04]],\n",
      "\n",
      "         [[-7.9646e-03,  7.9793e-03,  8.9170e-03],\n",
      "          [ 2.0011e-02,  3.2816e-02,  1.9285e-02],\n",
      "          [ 3.5981e-02,  1.4964e-02,  6.4281e-03]],\n",
      "\n",
      "         [[-2.2273e-02, -1.8473e-02, -1.5319e-02],\n",
      "          [-1.5886e-02, -3.7762e-03, -2.4006e-02],\n",
      "          [-1.4068e-02, -1.4314e-02, -3.4874e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7065e-02,  1.0170e-02, -9.0622e-03],\n",
      "          [ 4.7094e-04,  2.1596e-03,  9.6027e-03],\n",
      "          [ 1.7607e-02, -3.5147e-03,  9.5131e-03]],\n",
      "\n",
      "         [[ 1.1186e-02, -3.4554e-03,  6.8284e-03],\n",
      "          [ 7.4155e-03,  1.4749e-02,  1.6579e-02],\n",
      "          [ 6.5595e-03,  3.6331e-02,  1.9649e-02]],\n",
      "\n",
      "         [[-2.0443e-02, -1.4910e-02, -8.3466e-03],\n",
      "          [-2.6779e-02,  6.4421e-03, -2.2564e-03],\n",
      "          [ 1.2916e-02, -2.5245e-02, -1.4272e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4729e-02,  2.0966e-02, -1.0759e-02],\n",
      "          [-1.1815e-02, -2.2478e-02,  1.1051e-02],\n",
      "          [ 1.0634e-02,  7.8628e-03, -3.8224e-03]],\n",
      "\n",
      "         [[-1.8282e-03,  3.4997e-03, -1.2267e-02],\n",
      "          [-5.3749e-03,  2.2372e-03,  1.7235e-02],\n",
      "          [-7.8546e-04,  8.6104e-03,  4.9251e-04]],\n",
      "\n",
      "         [[ 1.1063e-02, -1.7691e-02, -2.5011e-02],\n",
      "          [-5.4146e-03,  1.4787e-02, -3.6488e-03],\n",
      "          [-6.1017e-03, -1.2324e-02, -6.8150e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2467e-02, -2.1555e-03, -2.2235e-03],\n",
      "          [ 5.4335e-03,  1.5030e-02, -3.4624e-04],\n",
      "          [ 1.0680e-02,  2.2028e-02,  2.3091e-02]],\n",
      "\n",
      "         [[-1.2925e-02,  3.2944e-02, -4.4600e-03],\n",
      "          [ 6.8460e-03,  1.8035e-02,  3.3371e-02],\n",
      "          [ 3.5971e-02,  4.8043e-02, -2.4686e-05]],\n",
      "\n",
      "         [[-1.2038e-02, -1.5074e-02, -2.6723e-02],\n",
      "          [ 4.6067e-03, -1.7411e-02, -1.7353e-02],\n",
      "          [-3.2004e-02, -7.7108e-03,  4.7005e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6171e-02, -1.3771e-02, -2.3826e-03],\n",
      "          [-2.0342e-02, -3.4054e-03, -9.5472e-03],\n",
      "          [ 5.9895e-03, -7.7173e-03,  2.3730e-02]],\n",
      "\n",
      "         [[ 1.0943e-02,  2.4138e-02, -1.5283e-02],\n",
      "          [ 9.9259e-03,  1.1827e-03,  1.3396e-02],\n",
      "          [ 4.7668e-03, -3.1938e-03, -1.1327e-04]],\n",
      "\n",
      "         [[ 1.7353e-02, -1.5688e-02, -2.1793e-02],\n",
      "          [-1.2195e-02, -1.6903e-02,  1.0844e-02],\n",
      "          [-3.5607e-03,  6.8019e-03, -1.2717e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2331e-02, -2.4616e-03,  1.8891e-03],\n",
      "          [-1.0086e-02, -1.6420e-02,  1.3544e-02],\n",
      "          [ 1.3046e-02, -9.1903e-03,  7.8295e-04]],\n",
      "\n",
      "         [[ 7.5999e-04,  1.7298e-02,  1.6347e-02],\n",
      "          [ 2.3043e-02, -1.7872e-03,  2.7805e-02],\n",
      "          [ 2.9964e-02,  1.4326e-02,  5.2105e-03]],\n",
      "\n",
      "         [[-4.8951e-03, -1.3917e-03, -1.8582e-03],\n",
      "          [-6.1786e-03, -5.8381e-03, -1.7327e-02],\n",
      "          [ 1.4194e-02,  1.3653e-02, -3.1705e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4747e-03,  4.7151e-03,  9.9541e-03],\n",
      "          [ 1.8357e-02, -1.9910e-02, -1.0838e-02],\n",
      "          [-2.8796e-02, -1.5999e-02, -1.6658e-02]],\n",
      "\n",
      "         [[ 1.3878e-02,  1.5847e-03, -1.3616e-02],\n",
      "          [ 2.1789e-03,  1.6782e-02, -2.2941e-02],\n",
      "          [-1.8662e-02, -3.3179e-03,  8.2180e-03]],\n",
      "\n",
      "         [[-1.0217e-02, -3.7987e-02, -4.1790e-02],\n",
      "          [-2.0988e-02, -1.7694e-02, -1.2450e-02],\n",
      "          [-1.0624e-02, -1.0492e-02,  7.2021e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.9608e-02, -2.9026e-02, -1.3423e-02],\n",
      "          [-2.3527e-02, -1.7727e-02, -8.6528e-03],\n",
      "          [-1.8341e-02, -2.3121e-02,  2.2457e-03]],\n",
      "\n",
      "         [[-2.5795e-02, -3.4382e-02, -1.1081e-02],\n",
      "          [-3.1064e-02, -1.5343e-02, -3.5229e-03],\n",
      "          [-6.3053e-03,  2.4247e-03,  6.4951e-03]],\n",
      "\n",
      "         [[ 1.3458e-02,  1.5378e-02, -2.2076e-03],\n",
      "          [-5.4536e-03,  3.3906e-03, -1.3745e-02],\n",
      "          [-3.3060e-02, -1.0513e-02, -2.4697e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6043e-04, -8.2393e-03, -3.8005e-02],\n",
      "          [ 3.7971e-03, -1.6159e-02, -2.6629e-04],\n",
      "          [ 1.1002e-02,  2.4428e-03, -6.3043e-03]],\n",
      "\n",
      "         [[-1.7837e-02,  4.4956e-04,  1.1153e-02],\n",
      "          [-8.8198e-03, -3.0878e-02, -3.2252e-02],\n",
      "          [ 3.3007e-03, -1.8298e-02, -2.0292e-03]],\n",
      "\n",
      "         [[-1.9750e-03, -1.4650e-02, -6.6580e-03],\n",
      "          [-7.6722e-03, -2.9427e-02, -1.3687e-02],\n",
      "          [-3.5045e-03, -1.9162e-02, -2.9512e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0686e-02, -2.2360e-02, -3.6653e-05],\n",
      "          [-1.8973e-02, -3.7284e-02, -2.3504e-02],\n",
      "          [-2.8445e-02, -6.1801e-03, -2.0799e-02]],\n",
      "\n",
      "         [[ 5.1792e-03,  4.0163e-03,  3.8922e-03],\n",
      "          [-1.8778e-02, -4.3009e-02, -2.3704e-02],\n",
      "          [ 1.5477e-02, -1.4942e-02, -1.1963e-02]],\n",
      "\n",
      "         [[ 1.2179e-02, -6.3311e-03,  2.7488e-03],\n",
      "          [ 1.1286e-03, -9.7351e-04, -8.9363e-03],\n",
      "          [ 1.0644e-02, -2.8105e-02, -1.3060e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9860e-03,  9.3844e-04,  1.1401e-02],\n",
      "          [-1.7311e-02,  6.1966e-03, -3.2158e-02],\n",
      "          [-1.2959e-03, -1.4065e-02, -2.1822e-02]],\n",
      "\n",
      "         [[ 2.2449e-02, -1.2111e-02,  2.3114e-02],\n",
      "          [ 5.4281e-03,  8.4434e-03, -1.1930e-02],\n",
      "          [ 2.5522e-02,  1.5844e-02,  2.4485e-02]],\n",
      "\n",
      "         [[ 3.7931e-02,  4.0502e-02,  1.0341e-02],\n",
      "          [ 1.3417e-02,  2.5793e-02,  2.6268e-02],\n",
      "          [ 2.5691e-02, -9.4281e-03, -3.0796e-03]]]])), ('conv_fc.14.weight', tensor([1.0013, 0.9836, 0.9526, 1.0343, 0.9835, 0.9596, 0.9874, 0.9903, 1.0259,\n",
      "        0.9681, 0.9907, 0.9914, 0.9767, 0.9984, 1.0106, 1.0105, 1.0399, 1.0633,\n",
      "        0.9948, 1.0326, 1.0402, 1.0442, 1.0118, 1.0032, 1.0017, 0.9734, 0.9815,\n",
      "        0.9415, 0.9843, 0.9899, 0.9934, 0.9443, 1.0357, 1.0480, 1.0652, 0.9840,\n",
      "        1.0066, 1.0098, 0.9978, 1.0261, 0.9979, 0.9544, 1.0368, 1.0186, 1.0062,\n",
      "        0.9521, 1.0418, 0.9490, 1.0266, 1.0312, 0.9890, 1.0261, 1.0116, 1.0311,\n",
      "        1.0302, 1.0170, 1.0383, 0.9908, 0.9665, 0.9297, 1.0077, 0.9462, 0.9727,\n",
      "        0.9784, 0.9436, 0.9863, 1.0212, 1.0096, 1.0152, 1.0434, 1.0446, 1.0273,\n",
      "        0.9551, 0.9811, 1.0160, 1.0113, 0.9772, 1.0409, 0.9992, 1.0866, 1.0105,\n",
      "        0.9810, 0.9418, 1.0351, 1.0314, 0.9808, 1.0211, 0.9855, 0.9970, 1.0113,\n",
      "        0.9876, 0.9702, 1.0108, 1.0035, 1.0831, 0.9658, 1.0052, 1.0860, 0.9639,\n",
      "        1.0279, 0.9750, 1.0177, 0.9920, 1.0544, 0.9977, 0.9506, 1.0058, 1.0081,\n",
      "        0.9867, 0.9982, 0.9926, 0.9613, 0.9963, 1.0045, 1.0251, 1.0329, 1.0373,\n",
      "        0.9380, 0.9799, 0.9988, 1.0059, 0.9997, 1.0029, 1.0417, 1.0488, 1.0618,\n",
      "        1.0464, 0.9987, 0.9907, 0.9886, 0.9971, 0.9665, 0.9836, 0.9788, 0.9828,\n",
      "        0.9905, 1.0482, 1.0230, 0.9626, 1.0113, 1.0042, 1.0325, 0.9835, 0.9523,\n",
      "        0.9562, 1.0484, 1.0082, 1.0103, 0.9489, 1.0275, 1.0168, 1.0399, 1.0004,\n",
      "        1.0063, 1.0403, 0.9359, 1.0046, 0.9732, 1.0057, 1.0108, 0.9596, 1.0037,\n",
      "        0.9506, 0.9923, 1.0354, 1.0230, 1.0015, 1.0305, 0.9734, 1.0416, 0.9997,\n",
      "        0.9482, 1.0325, 1.0059, 1.0085, 0.9930, 0.9188, 1.0185, 0.9925, 0.9646,\n",
      "        0.9988, 1.0078, 1.0831, 0.9917, 1.0203, 1.0758, 1.0052, 0.9431, 0.9953,\n",
      "        0.9694, 1.0759, 0.9889, 0.9450, 0.9217, 1.0300, 0.9607, 0.9526, 1.0334,\n",
      "        1.1092, 1.0042, 1.0204, 1.0230, 1.0217, 0.9811, 1.0567, 1.0927, 1.0237,\n",
      "        0.9645, 1.0018, 0.9810, 1.0082, 0.9759, 1.0531, 0.9483, 0.9718, 1.0528,\n",
      "        0.9807, 1.0344, 0.9667, 1.0215, 1.0186, 1.0121, 0.9854, 1.0456, 1.0029,\n",
      "        1.0016, 1.0050, 1.0147, 0.9878, 0.9638, 0.9844, 0.9404, 0.9987, 1.0366,\n",
      "        0.9795, 0.9852, 1.0534, 0.9398, 0.9963, 1.0359, 0.9887, 0.9624, 1.0016,\n",
      "        1.0354, 1.0726, 0.9624, 0.9898, 0.9764, 1.0236, 1.0036, 0.9779, 1.0212,\n",
      "        0.9175, 0.9712, 1.0242, 1.0339])), ('conv_fc.14.bias', tensor([-0.0946, -0.0682, -0.0906, -0.0583, -0.0264, -0.2222, -0.1314, -0.0371,\n",
      "        -0.0722, -0.0642, -0.0855, -0.0419, -0.0470, -0.0154, -0.0807, -0.0279,\n",
      "        -0.0970, -0.0703, -0.1714, -0.1407, -0.0733, -0.0668, -0.0484, -0.1169,\n",
      "        -0.0714, -0.0940, -0.0717, -0.1773, -0.1094, -0.1125, -0.1082, -0.0996,\n",
      "        -0.0480, -0.1210, -0.0467, -0.0787, -0.0885, -0.1030, -0.1007, -0.1025,\n",
      "        -0.0474, -0.1142, -0.1927, -0.1134, -0.0422, -0.0727, -0.0773, -0.1108,\n",
      "        -0.1440, -0.0933, -0.1162, -0.1957, -0.1119, -0.1310, -0.0918, -0.0496,\n",
      "        -0.0878, -0.0783, -0.0490, -0.0555, -0.1570, -0.0914, -0.0886, -0.0766,\n",
      "        -0.1095, -0.1016, -0.0687, -0.1617, -0.1021, -0.0846, -0.0698, -0.0680,\n",
      "        -0.0598, -0.0636, -0.0579, -0.0788, -0.0487, -0.0697, -0.0763, -0.0606,\n",
      "        -0.1769, -0.0855, -0.1163, -0.0908, -0.0015, -0.0532, -0.0758, -0.0613,\n",
      "        -0.0242, -0.0892, -0.1049, -0.0475, -0.0295, -0.0766, -0.1008, -0.0600,\n",
      "        -0.1226, -0.0454, -0.0674, -0.0611, -0.1363, -0.0499, -0.0949, -0.1047,\n",
      "        -0.0452, -0.1094, -0.0391, -0.0773, -0.0626, -0.1454, -0.1269, -0.0451,\n",
      "        -0.1015, -0.1041, -0.1182, -0.0818, -0.0470, -0.1172, -0.0912, -0.0990,\n",
      "        -0.0580, -0.0642, -0.0800, -0.1063, -0.0778, -0.1342, -0.0845, -0.0791,\n",
      "        -0.0941, -0.1115, -0.0987, -0.0845, -0.0551, -0.1084, -0.0626, -0.0790,\n",
      "        -0.0524, -0.0881, -0.1302, -0.0672, -0.1860, -0.1230, -0.0254, -0.0867,\n",
      "        -0.0574, -0.0590, -0.0891, -0.0701, -0.0056, -0.0975, -0.1194, -0.1518,\n",
      "        -0.0765, -0.1095, -0.1248, -0.0611, -0.1387, -0.1452, -0.0594, -0.0687,\n",
      "        -0.1810, -0.1279, -0.1911, -0.0943, -0.0618, -0.1336, -0.0061, -0.0948,\n",
      "        -0.0795, -0.0345, -0.0683, -0.0835, -0.0645, -0.1484, -0.0554, -0.0803,\n",
      "        -0.0888, -0.0947, -0.0981, -0.0397, -0.0773, -0.1450, -0.1535, -0.0487,\n",
      "        -0.1287, -0.0127, -0.0706, -0.1139, -0.0423, -0.0690, -0.0778, -0.0409,\n",
      "        -0.1397, -0.0569, -0.0046, -0.0738, -0.1006, -0.0493, -0.0608, -0.0556,\n",
      "        -0.0190, -0.0949, -0.0824, -0.0388, -0.0411, -0.1207, -0.0512, -0.1228,\n",
      "        -0.0623, -0.1061, -0.1396, -0.0629, -0.0902, -0.0456, -0.0611, -0.1404,\n",
      "        -0.0698, -0.1612, -0.0685, -0.1157, -0.1351, -0.1087, -0.0937, -0.0966,\n",
      "        -0.1617, -0.1178, -0.0995, -0.0845, -0.1429, -0.0695, -0.0921, -0.0560,\n",
      "        -0.1341, -0.0798, -0.0566, -0.0465, -0.1311, -0.0853, -0.0741, -0.1170,\n",
      "        -0.1140, -0.0674, -0.0747, -0.0264, -0.0037, -0.1097, -0.1047, -0.0590,\n",
      "        -0.0235, -0.0707, -0.1069, -0.0299, -0.1335, -0.0588, -0.1264, -0.0374])), ('conv_fc.14.running_mean', tensor([ 0.3776, -0.4904,  0.2669,  0.1105, -0.7231, -1.8749, -0.0144, -1.3356,\n",
      "        -0.9115, -0.7745,  0.0749, -0.1432,  0.1490, -0.6603,  0.3145, -0.4986,\n",
      "        -1.9485, -1.6938, -0.0926, -1.5614, -1.7722, -2.2957,  0.1098, -0.9913,\n",
      "        -0.0554, -0.4163, -0.5284, -1.4043, -0.3765,  0.3282, -0.4415, -1.3030,\n",
      "        -0.9557, -1.9901, -1.6696, -0.3569, -1.0941, -1.5432,  0.8005, -0.1180,\n",
      "        -0.8291, -0.5849, -2.4157,  0.6151,  0.2964,  0.4960, -1.4126, -0.5841,\n",
      "        -1.5302, -2.2505, -1.8021, -1.0265, -1.2372, -1.7226, -0.6517, -1.6978,\n",
      "        -1.9628,  0.0115, -0.1387,  0.7881, -1.3317,  0.0668,  0.6703, -0.4503,\n",
      "        -0.0107, -0.9372, -1.0348, -2.4931, -0.0903, -1.3841, -2.3905, -1.7062,\n",
      "        -0.9164, -1.7251, -1.1066, -1.5911, -0.9501, -1.5141, -0.9587, -1.4573,\n",
      "        -1.4324,  0.0852, -1.0527, -1.3695, -0.2420, -1.3207, -1.2430,  0.4891,\n",
      "        -1.2150, -1.5478,  1.1201, -0.9083, -0.5585, -1.2026, -0.8977, -0.4778,\n",
      "        -2.5805, -1.6121, -0.0279, -2.1075, -2.1095, -0.8206, -1.4791, -1.6695,\n",
      "         0.1535, -1.7938,  0.1364, -0.7070, -0.6011, -1.4107, -0.2907, -0.0726,\n",
      "        -0.6142, -1.8720, -1.2480,  0.0647, -0.5425,  0.5674, -0.5280, -0.2514,\n",
      "        -0.9625,  0.5668, -1.9205, -1.5959, -1.3283, -2.0812, -0.3467, -1.3641,\n",
      "        -1.5815, -0.5761, -0.6565, -0.6168, -0.1398, -2.0586, -0.7872,  0.2278,\n",
      "        -0.1999, -2.0500, -0.6204, -0.1321, -1.5302,  0.1359, -0.4761, -0.6540,\n",
      "        -0.8434, -1.1904, -1.0432, -1.9016, -1.0153, -0.9067, -1.3873, -1.4979,\n",
      "        -0.5624, -0.1565, -1.5350, -0.5482, -0.5412, -0.0362, -0.8064, -0.2412,\n",
      "         0.1444, -0.0321, -0.4879, -0.1188, -0.6938,  0.1311,  0.1497, -0.3236,\n",
      "        -0.1285, -0.9005, -1.0349,  1.0989, -0.2402, -1.2462, -0.6711, -0.0673,\n",
      "        -1.2675, -0.1568, -0.8204, -0.5172, -0.5793, -0.1449, -3.1171,  0.0886,\n",
      "        -0.8298, -1.4977, -0.0454,  0.9610, -0.0816, -1.1170, -2.3028, -0.6047,\n",
      "        -1.9405, -0.8813, -0.8145,  0.8239, -0.6199, -1.5904, -1.3283, -0.6477,\n",
      "        -0.6941, -0.3101, -1.0131, -0.4942, -0.7810, -2.2875, -1.4669, -0.1564,\n",
      "        -0.0999, -0.6101, -0.0756, -1.2757, -2.0639,  0.2976, -0.5932, -2.1882,\n",
      "        -1.1074, -2.4991, -0.6707, -0.0779, -0.5904, -2.1602, -0.9242, -0.9311,\n",
      "        -1.4051, -0.2750, -0.8690, -0.5951, -1.8012, -0.5006,  0.8316, -0.2394,\n",
      "        -0.0718, -1.3696,  0.4128, -0.7815, -1.2361, -0.6574, -1.5071, -1.1957,\n",
      "        -1.2379, -0.2534, -0.2745,  0.2170, -0.9407, -0.1509, -0.2130, -1.2049,\n",
      "        -1.0985,  0.0557, -0.7022, -0.8160, -1.9934, -0.7149, -1.5603, -1.0828])), ('conv_fc.14.running_var', tensor([0.9575, 1.0059, 1.1819, 0.8888, 1.5322, 1.3143, 0.6088, 1.4827, 0.8607,\n",
      "        0.6620, 0.7880, 0.5638, 1.2942, 1.2386, 1.0439, 0.9736, 1.6748, 1.4006,\n",
      "        1.1456, 1.4276, 1.0510, 1.5615, 0.8309, 0.6867, 0.8607, 1.1211, 0.5439,\n",
      "        1.3170, 1.0566, 0.8602, 0.7201, 1.1624, 1.0805, 1.5829, 1.0571, 0.6548,\n",
      "        0.8598, 1.1112, 1.3253, 0.7996, 0.5555, 1.1264, 1.0401, 1.0990, 0.6026,\n",
      "        1.1869, 1.0538, 0.6944, 0.9679, 1.4080, 0.8969, 1.4650, 1.5214, 0.8457,\n",
      "        0.9285, 1.4035, 1.2140, 0.5004, 0.6720, 0.7186, 0.9541, 0.6120, 0.6716,\n",
      "        1.0045, 1.5738, 0.8959, 1.0514, 1.2562, 1.1130, 1.3406, 1.9065, 1.1680,\n",
      "        0.6631, 1.4024, 0.5717, 0.8217, 1.0265, 0.9756, 0.7076, 1.5630, 1.0934,\n",
      "        0.7308, 1.1025, 1.3207, 1.1187, 0.9596, 1.0702, 1.3120, 1.0245, 1.0721,\n",
      "        0.7130, 0.7984, 1.2868, 0.8004, 1.1628, 1.2832, 1.1354, 0.7489, 0.4924,\n",
      "        1.5686, 1.1836, 1.4288, 1.8501, 0.9815, 0.6202, 1.3520, 0.9803, 0.7437,\n",
      "        1.0057, 1.1693, 0.9502, 0.9720, 0.9598, 1.5398, 1.0194, 0.8829, 1.4010,\n",
      "        1.3651, 0.5830, 1.0740, 1.0797, 1.1923, 0.7733, 1.1967, 1.0018, 1.1354,\n",
      "        1.1978, 1.1520, 1.0287, 0.9492, 0.8566, 1.4345, 1.0348, 1.0343, 0.6511,\n",
      "        0.6622, 1.1329, 0.9385, 0.7787, 0.5950, 0.9452, 1.0190, 0.7519, 0.9892,\n",
      "        1.2067, 0.9698, 1.0508, 1.3770, 0.9449, 1.5377, 0.7482, 1.1984, 0.4872,\n",
      "        0.9478, 1.1753, 1.2805, 0.8270, 1.0783, 0.6603, 0.8319, 0.9515, 1.2574,\n",
      "        1.3223, 0.9295, 0.7518, 1.6276, 0.8960, 0.8122, 0.7515, 0.8693, 0.9778,\n",
      "        1.2831, 0.7814, 1.1535, 0.8037, 1.2802, 0.9125, 1.0516, 0.8652, 1.0436,\n",
      "        0.7110, 1.1293, 1.6596, 1.1952, 1.2028, 0.7488, 0.7894, 0.7617, 0.5127,\n",
      "        0.9249, 1.1658, 0.8249, 1.5456, 1.3942, 1.0516, 1.1393, 1.0355, 1.1384,\n",
      "        1.6240, 0.7139, 1.0827, 1.0252, 0.8542, 0.8084, 0.7647, 1.8860, 0.9395,\n",
      "        1.0658, 0.8126, 0.7294, 1.2673, 0.8847, 1.2150, 1.0087, 0.9094, 1.6008,\n",
      "        1.5150, 1.3806, 1.1520, 1.3140, 0.8529, 1.2531, 0.9774, 0.8165, 1.0274,\n",
      "        0.8148, 0.9527, 0.7971, 0.9189, 0.8619, 0.5797, 0.7379, 1.2038, 1.2250,\n",
      "        1.0274, 1.0781, 1.7407, 1.2613, 0.7281, 1.1360, 1.2341, 0.8182, 0.7789,\n",
      "        1.1070, 0.9042, 0.7822, 1.0559, 0.6904, 1.1709, 0.9518, 1.0297, 0.9291,\n",
      "        1.3257, 1.7216, 1.1131, 0.7395])), ('conv_fc.14.num_batches_tracked', tensor(19525)), ('conv_fc.16.weight', tensor([[[[-0.0165,  0.0141, -0.0111],\n",
      "          [-0.0119,  0.0185,  0.0059],\n",
      "          [-0.0097, -0.0056, -0.0099]],\n",
      "\n",
      "         [[ 0.0211,  0.0284,  0.0125],\n",
      "          [ 0.0201,  0.0015, -0.0126],\n",
      "          [-0.0104,  0.0169,  0.0060]],\n",
      "\n",
      "         [[ 0.0045, -0.0197, -0.0200],\n",
      "          [-0.0231,  0.0031,  0.0131],\n",
      "          [ 0.0027, -0.0174, -0.0048]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0206,  0.0029,  0.0296],\n",
      "          [-0.0061, -0.0014,  0.0222],\n",
      "          [ 0.0060, -0.0098,  0.0199]],\n",
      "\n",
      "         [[-0.0280, -0.0006, -0.0149],\n",
      "          [-0.0081, -0.0262,  0.0123],\n",
      "          [-0.0063, -0.0133, -0.0083]],\n",
      "\n",
      "         [[-0.0299, -0.0063, -0.0111],\n",
      "          [-0.0299, -0.0232, -0.0241],\n",
      "          [-0.0109,  0.0142, -0.0149]]],\n",
      "\n",
      "\n",
      "        [[[-0.0223, -0.0092,  0.0150],\n",
      "          [-0.0151,  0.0134,  0.0062],\n",
      "          [ 0.0026, -0.0074, -0.0169]],\n",
      "\n",
      "         [[ 0.0319,  0.0019,  0.0342],\n",
      "          [ 0.0009,  0.0424,  0.0227],\n",
      "          [ 0.0161,  0.0224,  0.0325]],\n",
      "\n",
      "         [[ 0.0244,  0.0382,  0.0101],\n",
      "          [-0.0082,  0.0197, -0.0114],\n",
      "          [ 0.0021,  0.0048, -0.0091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0095,  0.0142,  0.0028],\n",
      "          [-0.0158, -0.0126, -0.0246],\n",
      "          [-0.0126, -0.0057,  0.0028]],\n",
      "\n",
      "         [[-0.0138,  0.0048,  0.0131],\n",
      "          [-0.0042,  0.0171, -0.0135],\n",
      "          [ 0.0289, -0.0019,  0.0211]],\n",
      "\n",
      "         [[-0.0120, -0.0217, -0.0163],\n",
      "          [-0.0128, -0.0001,  0.0220],\n",
      "          [ 0.0091,  0.0274,  0.0187]]],\n",
      "\n",
      "\n",
      "        [[[-0.0225,  0.0041, -0.0247],\n",
      "          [-0.0092, -0.0178, -0.0275],\n",
      "          [-0.0177, -0.0294, -0.0249]],\n",
      "\n",
      "         [[ 0.0146,  0.0168,  0.0026],\n",
      "          [ 0.0234, -0.0014,  0.0239],\n",
      "          [-0.0019,  0.0132, -0.0055]],\n",
      "\n",
      "         [[ 0.0224,  0.0361,  0.0133],\n",
      "          [ 0.0139,  0.0132,  0.0170],\n",
      "          [ 0.0112, -0.0027, -0.0004]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078, -0.0091,  0.0044],\n",
      "          [ 0.0136, -0.0068, -0.0137],\n",
      "          [-0.0176,  0.0053, -0.0059]],\n",
      "\n",
      "         [[ 0.0166,  0.0010,  0.0006],\n",
      "          [ 0.0334,  0.0177,  0.0182],\n",
      "          [ 0.0149,  0.0570,  0.0378]],\n",
      "\n",
      "         [[ 0.0167,  0.0237,  0.0276],\n",
      "          [ 0.0251,  0.0019,  0.0127],\n",
      "          [ 0.0267, -0.0054, -0.0046]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0057,  0.0250, -0.0076],\n",
      "          [ 0.0129,  0.0097,  0.0042],\n",
      "          [ 0.0182,  0.0021,  0.0175]],\n",
      "\n",
      "         [[-0.0042, -0.0217,  0.0056],\n",
      "          [ 0.0154,  0.0026, -0.0206],\n",
      "          [ 0.0190,  0.0262,  0.0235]],\n",
      "\n",
      "         [[-0.0103, -0.0005,  0.0001],\n",
      "          [-0.0124,  0.0035,  0.0065],\n",
      "          [-0.0109, -0.0142,  0.0014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0058,  0.0102,  0.0096],\n",
      "          [-0.0060,  0.0118, -0.0021],\n",
      "          [ 0.0046, -0.0041, -0.0007]],\n",
      "\n",
      "         [[ 0.0179, -0.0150,  0.0102],\n",
      "          [-0.0201, -0.0169, -0.0394],\n",
      "          [-0.0406, -0.0427, -0.0275]],\n",
      "\n",
      "         [[-0.0141, -0.0066,  0.0207],\n",
      "          [-0.0022, -0.0039,  0.0051],\n",
      "          [-0.0035, -0.0036, -0.0016]]],\n",
      "\n",
      "\n",
      "        [[[-0.0039, -0.0174, -0.0073],\n",
      "          [-0.0333, -0.0065, -0.0058],\n",
      "          [-0.0171, -0.0370, -0.0330]],\n",
      "\n",
      "         [[-0.0218, -0.0016, -0.0229],\n",
      "          [-0.0205, -0.0036, -0.0016],\n",
      "          [-0.0182, -0.0168, -0.0083]],\n",
      "\n",
      "         [[-0.0106, -0.0051,  0.0060],\n",
      "          [ 0.0263, -0.0126, -0.0204],\n",
      "          [ 0.0010, -0.0161, -0.0179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0125, -0.0179, -0.0163],\n",
      "          [-0.0066,  0.0097, -0.0069],\n",
      "          [ 0.0274,  0.0055, -0.0073]],\n",
      "\n",
      "         [[-0.0078, -0.0084, -0.0274],\n",
      "          [-0.0261, -0.0179,  0.0002],\n",
      "          [ 0.0015, -0.0007,  0.0246]],\n",
      "\n",
      "         [[ 0.0128,  0.0105, -0.0042],\n",
      "          [ 0.0246,  0.0003, -0.0004],\n",
      "          [ 0.0274,  0.0128,  0.0138]]],\n",
      "\n",
      "\n",
      "        [[[-0.0056, -0.0075, -0.0010],\n",
      "          [ 0.0131,  0.0204,  0.0042],\n",
      "          [-0.0048,  0.0153,  0.0143]],\n",
      "\n",
      "         [[ 0.0081, -0.0134,  0.0178],\n",
      "          [-0.0081,  0.0145,  0.0099],\n",
      "          [ 0.0036,  0.0030, -0.0035]],\n",
      "\n",
      "         [[-0.0111,  0.0065,  0.0098],\n",
      "          [-0.0133, -0.0104, -0.0060],\n",
      "          [-0.0003, -0.0131, -0.0167]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0095, -0.0043, -0.0018],\n",
      "          [-0.0005,  0.0081, -0.0070],\n",
      "          [ 0.0066,  0.0104,  0.0104]],\n",
      "\n",
      "         [[-0.0383, -0.0033, -0.0138],\n",
      "          [-0.0313,  0.0062, -0.0013],\n",
      "          [ 0.0122, -0.0194, -0.0035]],\n",
      "\n",
      "         [[-0.0291, -0.0241, -0.0276],\n",
      "          [ 0.0009, -0.0171, -0.0182],\n",
      "          [ 0.0197, -0.0129, -0.0115]]]])), ('conv_fc.17.weight', tensor([1.0531, 0.9666, 1.0094, 0.9819, 0.9841, 1.0404, 0.9866, 0.9715, 1.0348,\n",
      "        1.0319, 1.0805, 1.1304, 1.0683, 1.0180, 0.9774, 1.0846, 1.0216, 0.9151,\n",
      "        1.1490, 1.0055, 1.0347, 1.0409, 0.9550, 1.0420, 1.0798, 1.0676, 0.9539,\n",
      "        0.9526, 1.0176, 1.0836, 0.9728, 0.9833, 0.9371, 1.0978, 1.0726, 1.0301,\n",
      "        1.0821, 1.0542, 1.0018, 1.0604, 1.0342, 1.0712, 0.9546, 0.9403, 1.0026,\n",
      "        1.0190, 0.9973, 0.9869, 1.0828, 1.0950, 1.0266, 1.0598, 0.9797, 1.1221,\n",
      "        0.9187, 0.9587, 1.0015, 1.0560, 1.1232, 0.9498, 1.0800, 1.0406, 1.0421,\n",
      "        0.9986, 0.9816, 0.9851, 1.0412, 1.1125, 1.0298, 1.0049, 1.0177, 1.0067,\n",
      "        0.9559, 1.0519, 1.0664, 1.0469, 1.0869, 1.0348, 0.9968, 1.0542, 1.0665,\n",
      "        0.9729, 0.9179, 0.9567, 0.9160, 1.0620, 1.0616, 0.9452, 1.0296, 0.9939,\n",
      "        1.0409, 1.0741, 1.0393, 0.9560, 1.0429, 1.0468, 0.9817, 1.0566, 1.0698,\n",
      "        1.0870, 1.0214, 1.0701, 1.0186, 1.1261, 1.0555, 1.0688, 1.0415, 1.0631,\n",
      "        1.0566, 0.9322, 1.0727, 1.0363, 0.9897, 1.0767, 1.0663, 0.9684, 1.1374,\n",
      "        1.0156, 0.9282, 0.9461, 1.0474, 1.0622, 1.0001, 1.0050, 1.1540, 0.9476,\n",
      "        1.0412, 1.0177, 1.0248, 1.1042, 1.1138, 1.0758, 1.0112, 1.0017, 0.9811,\n",
      "        0.9688, 0.9540, 1.0644, 1.0576, 1.0489, 0.9491, 1.0440, 1.0733, 1.0480,\n",
      "        1.0764, 1.0723, 1.0773, 1.0772, 1.0359, 1.0497, 1.0457, 1.0435, 1.0827,\n",
      "        1.0985, 0.9931, 1.1174, 0.9501, 0.9445, 1.0525, 0.9301, 1.0736, 1.0685,\n",
      "        0.9729, 1.0840, 1.0543, 1.0242, 0.9888, 1.0796, 1.1066, 1.1954, 0.9824,\n",
      "        1.0230, 0.9385, 1.0920, 1.0045, 1.0749, 0.9638, 0.9724, 1.0691, 1.0566,\n",
      "        1.0236, 1.0521, 1.0475, 1.0700, 1.0641, 1.0308, 1.0862, 1.1125, 1.0792,\n",
      "        1.0699, 1.0443, 1.0110, 1.0800, 1.0772, 1.0176, 1.0416, 1.0442, 1.0636,\n",
      "        1.1302, 1.0413, 1.1373, 0.9874, 0.9772, 1.0969, 1.0370, 1.0075, 1.0381,\n",
      "        0.9377, 1.0651, 0.9177, 1.1305, 1.0450, 0.9643, 1.0404, 1.0246, 0.9411,\n",
      "        0.9967, 1.0298, 1.0725, 1.0555, 1.0517, 1.1194, 1.0661, 1.0164, 0.9393,\n",
      "        1.0365, 1.0488, 1.0224, 1.0456, 1.0790, 1.0278, 0.9392, 1.0306, 1.0061,\n",
      "        0.9575, 0.9494, 1.0003, 1.0863, 0.9664, 1.0499, 1.0031, 1.0380, 1.0996,\n",
      "        1.0548, 1.0671, 1.0520, 0.9824, 0.9662, 0.9714, 1.0515, 0.9313, 1.0355,\n",
      "        1.1066, 1.0603, 1.0209, 1.0739])), ('conv_fc.17.bias', tensor([-0.2815, -0.2767, -0.2630, -0.2649, -0.1312, -0.2489, -0.2554, -0.2735,\n",
      "        -0.2199, -0.2279, -0.2189, -0.2339, -0.2225, -0.2325, -0.2937, -0.3082,\n",
      "        -0.2295, -0.3463, -0.2374, -0.2319, -0.2384, -0.3140, -0.2857, -0.2402,\n",
      "        -0.2476, -0.2622, -0.2989, -0.2425, -0.2529, -0.2775, -0.2552, -0.2138,\n",
      "        -0.2740, -0.2610, -0.2419, -0.2714, -0.2382, -0.2275, -0.2025, -0.2391,\n",
      "        -0.2654, -0.2911, -0.2849, -0.2935, -0.2713, -0.1988, -0.2292, -0.2036,\n",
      "        -0.2592, -0.2913, -0.2791, -0.2217, -0.2540, -0.1764, -0.3228, -0.2687,\n",
      "        -0.2432, -0.2483, -0.2420, -0.2532, -0.2357, -0.2619, -0.2440, -0.2035,\n",
      "        -0.3065, -0.3408, -0.2570, -0.2463, -0.2608, -0.2521, -0.2511, -0.2682,\n",
      "        -0.3376, -0.2301, -0.2727, -0.3083, -0.2375, -0.2837, -0.2618, -0.2747,\n",
      "        -0.3055, -0.2307, -0.2837, -0.2452, -0.3421, -0.2551, -0.2190, -0.2278,\n",
      "        -0.2129, -0.2268, -0.2568, -0.3001, -0.2670, -0.3006, -0.2317, -0.2103,\n",
      "        -0.2550, -0.2742, -0.2592, -0.2811, -0.2449, -0.3250, -0.2477, -0.2346,\n",
      "        -0.2359, -0.2507, -0.2512, -0.2859, -0.2773, -0.2765, -0.2448, -0.2803,\n",
      "        -0.2266, -0.2547, -0.2807, -0.2846, -0.2431, -0.2291, -0.2744, -0.2692,\n",
      "        -0.2806, -0.2096, -0.2755, -0.2937, -0.2535, -0.2742, -0.2156, -0.2671,\n",
      "        -0.2924, -0.2112, -0.2016, -0.2305, -0.2798, -0.2541, -0.2583, -0.2337,\n",
      "        -0.2135, -0.2101, -0.2369, -0.2981, -0.2509, -0.1899, -0.2033, -0.2659,\n",
      "        -0.2654, -0.2403, -0.2054, -0.2816, -0.2899, -0.2624, -0.2459, -0.2759,\n",
      "        -0.2387, -0.2881, -0.2860, -0.2141, -0.2823, -0.2938, -0.2831, -0.2956,\n",
      "        -0.2600, -0.3200, -0.2625, -0.2377, -0.2908, -0.2063, -0.2587, -0.2566,\n",
      "        -0.2239, -0.1544, -0.2109, -0.2846, -0.2839, -0.3041, -0.2286, -0.2725,\n",
      "        -0.2868, -0.2618, -0.2285, -0.2148, -0.2612, -0.2382, -0.2227, -0.2062,\n",
      "        -0.2846, -0.3366, -0.2166, -0.2420, -0.2984, -0.2886, -0.2797, -0.2329,\n",
      "        -0.2611, -0.2502, -0.2269, -0.2409, -0.1536, -0.2867, -0.2097, -0.2381,\n",
      "        -0.1946, -0.2668, -0.2833, -0.2485, -0.2635, -0.2946, -0.2936, -0.3158,\n",
      "        -0.2758, -0.2896, -0.2251, -0.3306, -0.2476, -0.2459, -0.2709, -0.2668,\n",
      "        -0.2936, -0.2494, -0.3260, -0.2894, -0.2206, -0.2306, -0.2438, -0.1936,\n",
      "        -0.2969, -0.2706, -0.2715, -0.2562, -0.2589, -0.1971, -0.2113, -0.2877,\n",
      "        -0.2246, -0.2486, -0.3263, -0.2665, -0.2244, -0.2101, -0.2346, -0.2970,\n",
      "        -0.2750, -0.2272, -0.2476, -0.2553, -0.2672, -0.2474, -0.2391, -0.2183,\n",
      "        -0.3013, -0.2735, -0.2620, -0.2262, -0.2573, -0.1858, -0.2731, -0.2084])), ('conv_fc.17.running_mean', tensor([-0.3670,  0.4793, -0.2411, -0.4052, -0.8055,  0.4225, -0.6033, -0.2030,\n",
      "        -0.2430, -1.2397,  0.2172,  0.2516, -1.3330, -0.7315, -0.0742, -0.5347,\n",
      "        -0.3023, -0.0691, -0.2416, -0.4577, -0.1969, -0.4711, -0.2413, -0.3957,\n",
      "        -1.1152, -0.0418, -0.6192, -0.2249,  0.2845, -0.4780, -0.6660, -0.8607,\n",
      "        -0.5650, -0.9410, -0.3526, -0.6322, -0.1404,  0.2903, -0.4678, -0.1258,\n",
      "         0.1950, -1.1091,  0.1123, -0.1300, -0.7300, -0.2177,  0.4823, -0.1769,\n",
      "        -0.4135, -0.6087, -0.1092, -0.0654, -0.2756, -0.0983,  0.2574, -0.8679,\n",
      "        -0.9828, -0.8045, -0.3646, -0.0709, -0.4356,  0.3133,  0.0395, -1.1330,\n",
      "        -0.5087, -0.2474,  0.0184, -0.1781, -0.2284, -0.3751, -0.0495,  0.6578,\n",
      "         0.1991, -0.0608, -0.9763, -1.1715, -0.2024,  0.3046, -0.4083, -0.5848,\n",
      "         0.2445, -0.9603, -0.2875, -0.3528,  0.8171, -0.3820, -0.1135,  0.2379,\n",
      "         0.0317,  0.1574, -0.9268, -1.2975, -0.3784, -0.0780, -0.3463, -1.0029,\n",
      "        -0.6628, -0.4600, -0.2726,  0.0718, -0.3826, -0.6404, -0.5418, -0.1319,\n",
      "         0.1346,  0.0756, -0.2766, -0.5090, -0.7545,  0.4491, -0.5104,  0.2705,\n",
      "        -0.7562, -0.3487, -1.0366, -0.3944, -0.8042,  0.4425, -0.4069, -0.4717,\n",
      "         0.2220,  0.1927,  0.7657,  0.4203, -0.4046, -0.8184,  0.2296, -0.0369,\n",
      "        -0.6331, -0.3390, -0.5296,  0.3145, -0.2740, -0.1027,  0.2870,  0.0175,\n",
      "        -0.9218, -0.1701, -0.1249, -0.0282, -0.4108, -0.5192, -0.3871,  0.3134,\n",
      "         0.7148, -0.3053, -0.4806, -0.0427,  0.4563, -0.3062, -0.2507, -0.2114,\n",
      "        -0.3055, -0.5244, -0.2173, -0.6422,  0.1908,  0.5539, -0.3066,  0.0241,\n",
      "        -0.5236, -0.8763, -0.0217,  0.0834, -0.8091,  0.2615,  0.0625, -0.4655,\n",
      "         0.1372,  0.2101, -0.8458,  0.0029,  0.0744, -0.4649,  0.4517,  0.0727,\n",
      "        -0.0217, -0.6492,  0.2388,  0.2860, -0.6753, -0.0964,  0.0978, -0.8243,\n",
      "        -0.6978,  0.4220,  0.2789, -0.1200, -0.3389, -0.3023, -0.8489, -1.2133,\n",
      "         0.5867, -0.0140, -0.3071, -0.2354, -0.0168, -0.2802, -0.5830, -0.3580,\n",
      "        -0.1437,  0.2805, -0.5610, -0.8056, -0.2587,  0.1976,  0.1262, -0.0812,\n",
      "        -0.1336,  0.6631, -0.4217, -0.4390, -0.3715,  0.1322, -0.3549,  0.6350,\n",
      "        -0.8775, -0.6040, -0.1305, -0.2180, -0.4232, -0.7144, -0.5368, -0.4279,\n",
      "        -0.4453, -0.0088, -0.6052,  0.4128, -0.3203, -0.6646,  0.4600, -1.0606,\n",
      "         0.5522, -0.3710, -1.2319, -0.2494, -0.8755, -0.2247, -0.2515, -0.6553,\n",
      "         0.1491, -0.0794, -0.5315, -0.2855, -0.1019, -0.2444, -0.6565, -0.6099,\n",
      "        -0.7926, -0.0486, -0.1900, -0.1016,  0.1395, -0.3445, -0.8577,  0.0391])), ('conv_fc.17.running_var', tensor([0.7980, 0.6395, 0.7488, 1.0865, 1.0371, 0.7118, 1.2330, 0.9869, 0.9251,\n",
      "        1.6918, 1.0123, 1.1988, 1.3454, 1.4982, 0.6509, 1.4131, 0.9401, 1.8609,\n",
      "        2.0711, 1.3213, 0.7527, 1.4912, 1.4468, 0.9030, 1.3368, 0.8344, 1.3625,\n",
      "        0.8830, 0.7381, 0.7726, 2.3331, 0.6456, 1.8172, 1.2893, 1.2388, 1.5131,\n",
      "        1.3299, 0.8574, 1.2414, 0.7530, 0.9812, 1.3245, 1.6583, 0.7787, 0.8235,\n",
      "        1.0778, 0.5947, 0.7934, 0.6988, 1.0511, 0.9628, 0.6180, 0.9849, 1.5982,\n",
      "        1.6511, 0.8452, 1.0011, 1.2136, 1.2902, 1.2601, 0.7372, 0.6652, 1.1779,\n",
      "        1.2049, 1.4659, 1.5559, 0.7984, 1.0495, 0.8974, 1.0059, 1.0297, 0.7093,\n",
      "        1.9207, 0.6684, 1.1523, 1.8402, 1.3068, 0.7893, 0.6188, 1.9419, 1.0430,\n",
      "        1.3009, 0.8286, 0.9363, 1.6409, 1.4353, 0.8514, 0.8072, 0.6153, 0.7705,\n",
      "        1.5600, 1.7353, 0.7894, 1.1608, 1.4077, 1.1640, 1.4569, 0.9175, 1.2953,\n",
      "        0.9527, 1.5234, 1.3219, 0.9577, 1.4712, 0.7854, 0.6394, 0.9375, 1.3769,\n",
      "        0.9349, 0.8529, 1.8407, 0.7280, 0.7194, 0.7429, 0.8987, 1.2525, 1.3798,\n",
      "        0.9845, 0.8744, 1.1465, 1.1511, 0.8535, 0.6719, 0.8515, 1.1132, 1.5304,\n",
      "        0.6380, 0.9367, 0.8661, 0.8294, 1.0965, 1.2665, 1.1257, 0.7907, 0.6910,\n",
      "        0.9047, 1.1987, 1.1330, 1.1573, 1.1624, 1.2865, 0.9693, 0.6505, 0.8906,\n",
      "        0.8263, 1.1362, 1.3968, 0.6988, 0.8252, 1.5258, 0.8060, 0.8483, 1.0151,\n",
      "        1.3038, 0.7871, 1.5353, 1.1503, 1.0510, 1.1246, 1.0611, 1.0277, 1.3726,\n",
      "        1.0468, 1.1157, 1.1883, 0.5451, 0.8646, 1.1902, 1.0149, 1.3749, 1.0969,\n",
      "        2.0224, 0.9889, 0.9847, 0.7068, 1.4376, 0.7806, 1.7715, 1.0471, 0.7908,\n",
      "        1.4642, 0.7085, 0.7418, 1.9106, 1.6481, 1.2197, 0.8037, 0.8819, 1.2321,\n",
      "        1.1234, 0.9704, 1.2321, 0.9907, 0.9578, 1.3304, 1.0107, 0.9358, 1.0238,\n",
      "        1.2831, 0.7375, 1.6882, 0.8537, 1.3511, 1.0363, 0.7401, 0.6898, 1.0915,\n",
      "        1.7479, 1.0748, 0.8748, 1.5044, 0.8005, 1.1644, 0.7149, 0.9506, 0.9156,\n",
      "        1.5937, 1.4615, 1.2298, 0.9924, 0.9543, 1.5532, 1.2568, 1.0712, 0.9894,\n",
      "        0.7901, 0.9033, 0.8026, 1.5983, 1.2407, 0.6470, 2.0018, 0.5920, 0.6575,\n",
      "        1.3055, 1.2491, 0.9897, 0.7657, 0.6720, 1.5260, 1.0932, 0.7953, 1.3599,\n",
      "        0.6763, 0.7205, 0.7550, 1.2639, 1.2519, 1.2559, 0.5951, 0.7058, 0.8297,\n",
      "        2.3098, 1.2574, 1.5701, 0.7900])), ('conv_fc.17.num_batches_tracked', tensor(19525)), ('conv_fc.21.weight', tensor([[-0.0051,  0.0042,  0.0032,  ...,  0.0080, -0.0010, -0.0024],\n",
      "        [-0.0056, -0.0030, -0.0016,  ..., -0.0074,  0.0043,  0.0014],\n",
      "        [-0.0057,  0.0066, -0.0054,  ..., -0.0045, -0.0006,  0.0066],\n",
      "        ...,\n",
      "        [ 0.0071,  0.0020, -0.0069,  ..., -0.0059,  0.0029,  0.0031],\n",
      "        [-0.0035,  0.0012, -0.0052,  ...,  0.0050,  0.0031, -0.0066],\n",
      "        [ 0.0043,  0.0044, -0.0009,  ..., -0.0060, -0.0059, -0.0069]])), ('conv_fc.23.weight', tensor([[ 0.0215,  0.0070, -0.0025,  ...,  0.0242,  0.0026,  0.0727],\n",
      "        [-0.0178,  0.0257,  0.0252,  ...,  0.0100,  0.0210,  0.0005],\n",
      "        [ 0.0173,  0.0274, -0.0268,  ..., -0.0135, -0.0096,  0.0298],\n",
      "        ...,\n",
      "        [-0.0055, -0.0063, -0.0348,  ..., -0.0243,  0.0031, -0.0003],\n",
      "        [-0.0087,  0.0133,  0.0099,  ..., -0.0213, -0.0073, -0.0459],\n",
      "        [ 0.0059, -0.0059, -0.0256,  ..., -0.0070, -0.0436,  0.0215]])), ('conv_fc.25.weight', tensor([[-0.2486, -0.2625, -0.1758,  0.7826,  0.0586, -0.4351,  1.1459,  0.0060,\n",
      "         -0.1133, -0.7531, -0.5090, -0.1500,  0.2738, -0.5177, -0.3643, -0.1219,\n",
      "         -0.1361,  0.6188, -0.5325, -0.5664,  0.9648, -0.9025,  0.2769, -0.9406,\n",
      "          0.7479, -0.6592, -0.0688, -0.1130, -0.8625,  0.0914, -0.4693, -0.9118,\n",
      "          0.0381, -0.3281, -0.8442, -0.3067, -0.4310, -0.7607,  0.4291,  1.2908,\n",
      "          0.7982, -0.4244,  0.0338,  0.2670, -0.8054, -0.4630,  0.9543, -0.5455,\n",
      "         -1.2514, -0.9206,  0.0485, -0.0911,  0.8460, -0.1019,  1.0403, -0.2673,\n",
      "          0.1958, -0.8768,  0.2174, -0.2532, -0.2979, -0.3861,  0.3934, -0.8475,\n",
      "          0.0389, -0.1160, -0.1026,  0.3075, -1.0719,  0.6902,  0.2908, -0.7648,\n",
      "          0.5737, -0.2060, -0.6422, -0.0425, -1.1084, -0.9703, -0.1282, -0.3464,\n",
      "          0.6906,  0.0846, -0.1078,  0.3679,  0.0121, -0.5723, -0.3051,  0.8523,\n",
      "         -0.0140,  0.4033,  0.5162,  0.1868,  0.4538, -0.3751, -0.5110, -1.2485,\n",
      "          0.2486, -0.4500, -0.5932, -0.0870],\n",
      "        [-0.0397,  0.2859, -0.3539,  0.5072, -0.2778, -0.3268, -0.6069,  0.4299,\n",
      "         -1.0593, -0.2468, -0.5465,  0.5401,  0.0284, -0.0857,  1.0966, -0.2264,\n",
      "         -0.1651, -0.9514,  0.8586, -1.1840, -0.4307, -1.1275,  0.0977,  0.3796,\n",
      "         -0.7901,  0.6157, -0.6872, -0.5009, -0.8000, -0.2371,  0.6648,  0.4115,\n",
      "          0.0276, -0.6010, -0.3971, -0.4198, -0.1766,  0.4309, -0.2900, -1.1452,\n",
      "          0.6548,  0.1326, -0.1520, -1.0342,  0.1562, -0.8199, -0.3495, -0.3907,\n",
      "         -0.4290,  0.4759, -0.2261, -0.0847,  0.2707,  0.5141, -0.3910, -1.3275,\n",
      "         -1.1283, -0.5425,  0.5121,  0.4091,  0.9881, -0.4816,  0.7240, -0.3886,\n",
      "         -0.3862,  0.3769, -0.0143,  0.5480,  0.6589, -0.3557, -0.5424,  0.7231,\n",
      "          0.0906, -0.0738, -1.0081, -0.6822,  0.0909, -0.4114, -0.3497, -0.4740,\n",
      "          0.8709,  0.0265, -0.1319,  0.6535, -0.7326,  0.5667, -0.0904,  0.8154,\n",
      "         -0.0062, -0.1146, -0.3905, -0.0852, -0.7322,  0.3801, -0.5202, -0.7958,\n",
      "         -0.6844,  0.4818,  0.0375, -0.6575],\n",
      "        [ 0.8809, -0.5425,  0.0448, -0.5686, -0.3852, -0.8050, -0.6361, -0.6974,\n",
      "         -0.4034,  0.0687,  0.5064,  0.0503,  0.8818, -0.4509,  0.0667, -0.6072,\n",
      "          1.8792, -1.1684, -0.0734,  0.6804,  0.2208,  0.2904,  0.2645, -0.3997,\n",
      "          0.1571, -0.6334,  0.2757, -0.2816, -0.2019, -0.1358, -0.2663, -0.3457,\n",
      "         -0.8977,  0.1023, -0.9445,  0.0530, -0.0390, -0.5727, -0.3473, -0.1708,\n",
      "         -0.8831,  0.6521, -0.2657,  1.0105, -0.9037, -0.9598, -0.7215, -0.1919,\n",
      "         -0.1906, -0.0136, -0.3202, -0.8401, -0.2735,  0.1392,  0.5454, -0.1906,\n",
      "         -0.2824, -0.3906, -0.8339, -0.1594, -0.2646, -0.8269,  0.4719,  0.3708,\n",
      "         -0.4337,  0.0656,  0.4189,  0.0192,  0.3138,  0.1094,  0.6458, -0.3471,\n",
      "          0.4383,  0.9870,  0.6909, -0.0126, -1.4511, -0.1213, -0.4675, -0.4882,\n",
      "         -0.1231, -0.4753,  0.2499,  0.1936, -1.0852,  0.1884, -0.4636, -0.3377,\n",
      "          0.8231, -0.3529, -1.0169,  0.3030, -0.5642,  0.0826, -0.2217,  0.5034,\n",
      "          0.1630, -0.0999, -1.1161,  0.4107],\n",
      "        [-0.4513, -0.1964,  0.2139,  0.6848, -0.4510,  0.3669,  0.5108, -0.0213,\n",
      "         -0.5886,  0.9113,  0.3230, -0.9086, -0.4100, -0.4591, -0.1201, -0.1541,\n",
      "         -0.0929, -0.5184, -0.3962, -0.0747, -0.5121,  0.6012,  0.4320, -0.4994,\n",
      "         -0.3442, -0.4735,  0.0084, -0.2919, -1.2580, -0.5149, -0.6211,  0.1214,\n",
      "         -0.8725,  0.0057, -0.0479, -0.7799,  0.1939,  0.7479, -0.9202,  0.0135,\n",
      "          0.0794,  0.4148,  0.1662,  0.0074, -0.1642, -0.5385,  0.8720, -0.1105,\n",
      "          0.3465, -0.0234,  0.6425, -0.7632, -0.3609, -1.5193, -0.4890,  0.3112,\n",
      "         -0.2270,  0.3191,  0.2488, -0.4968, -0.7734,  0.4915, -0.3666, -0.2898,\n",
      "         -0.2792, -0.2399, -0.8192, -0.6355, -0.9832, -1.0005,  0.2112,  0.2690,\n",
      "          0.2833,  0.9182,  0.3898,  0.8922, -0.4358, -0.0474, -0.1006, -0.7083,\n",
      "         -0.5813,  0.3336, -1.3408,  0.2676, -0.7563, -1.5324, -0.5193, -0.1111,\n",
      "          0.3793, -0.0663,  0.0778,  0.3736,  0.1773,  0.2828, -0.2653,  0.5425,\n",
      "         -0.3968, -0.2852,  0.2233, -0.4566],\n",
      "        [-0.2778, -0.2018, -0.3912,  1.0226,  0.3236, -0.7343, -0.7817, -0.3248,\n",
      "          0.6337,  0.7489,  0.2752, -0.0151, -0.6364, -0.4926, -0.4570, -0.2691,\n",
      "         -0.0575,  0.0339, -0.2556,  0.5070, -0.9723, -0.0697, -1.1461, -0.7221,\n",
      "          0.2494, -0.9656,  0.7888, -0.9157, -0.0921,  0.1272,  0.7869, -0.4069,\n",
      "         -0.8984,  0.7149, -0.9562, -0.0367,  0.2142, -0.2984,  0.2406, -0.5426,\n",
      "          0.5264, -0.5725, -0.3726, -0.9317, -0.9301,  0.0577,  0.8762, -0.0739,\n",
      "         -0.0079, -1.0243,  1.0785, -0.1067, -0.7210, -0.0850,  0.3713,  0.2229,\n",
      "         -0.1466,  1.4954, -0.5730, -0.1866, -0.6037, -1.0597, -0.0293,  0.3661,\n",
      "         -0.6186,  1.3229,  0.3058, -0.7337,  0.2332, -0.5346, -0.1761, -0.4089,\n",
      "         -0.5351,  0.0854,  0.1076, -0.3200, -0.4099,  0.3408,  0.1658, -0.2611,\n",
      "         -0.4231, -0.2320, -0.3141, -0.1204,  0.2095,  0.1282, -0.3010, -0.2441,\n",
      "         -0.5372,  1.0000, -1.2783, -0.5298, -0.4460, -1.0821, -0.3015, -0.0201,\n",
      "         -0.2648,  0.0213,  0.0229, -0.7625],\n",
      "        [-0.7910, -0.2138,  0.1306, -0.8237,  0.0652,  0.0676,  0.3541, -0.6105,\n",
      "         -0.4530,  0.7395, -1.8945, -0.3575, -0.4409, -0.0071, -0.7637, -0.5764,\n",
      "         -0.3767, -0.5829, -0.3770,  0.2667,  0.4301,  0.0321, -0.4935, -0.4285,\n",
      "         -0.6377,  0.4872,  0.1595, -0.5327, -0.0210, -0.0255,  0.4466,  0.6356,\n",
      "         -0.6563,  0.1118,  0.0694, -0.5532, -0.0549,  0.2957,  0.2374, -0.7175,\n",
      "         -0.4470, -0.1231, -0.0862, -0.8228, -0.0135,  0.0405, -0.2935, -0.2459,\n",
      "          0.1339, -0.3025, -0.3417, -0.5607, -0.3313, -0.3495, -0.5929,  0.0717,\n",
      "         -0.1255, -0.0154,  0.2057, -0.3482, -0.4375,  0.4363, -0.7906,  0.7346,\n",
      "          0.8955, -0.2570, -0.4929, -0.7613, -0.2058, -0.4714, -0.1257,  0.5134,\n",
      "          0.1424,  1.0035,  0.1175,  0.7277,  0.1980,  0.4332, -0.1387, -0.6465,\n",
      "         -0.5294, -0.5539, -0.9597,  0.0532, -0.7668, -0.1126, -0.2993, -0.2846,\n",
      "          1.3418,  0.2688,  0.2272,  0.6738, -0.7159,  0.1171, -0.2937,  0.3478,\n",
      "         -1.1668, -1.2113,  0.1096, -0.9957],\n",
      "        [ 0.6765, -0.5900, -0.1744,  0.6399, -0.1225,  0.0581, -0.0576, -0.5597,\n",
      "         -0.2811,  0.5141,  0.0109,  0.0939, -0.1105, -0.3075,  0.7585, -0.1466,\n",
      "         -0.2633,  0.2285, -0.4617,  0.0908,  0.2609, -0.1857, -0.8492,  0.3051,\n",
      "         -0.2006, -0.7354, -1.1361,  0.5663,  0.3321, -1.2383,  0.4969,  0.3388,\n",
      "          0.2548, -0.1374, -0.1150, -0.7341, -0.2872,  0.3189,  0.3069, -0.4506,\n",
      "         -0.4508,  0.8641,  0.0881,  0.1617,  0.1726,  0.1559, -0.6164,  0.5617,\n",
      "          0.1129,  0.3711,  1.1198, -1.2224,  0.5656,  0.1528, -0.0663, -0.6191,\n",
      "         -1.7248,  0.4252, -0.8686, -0.4267, -0.6259, -0.5484, -0.3876, -0.5869,\n",
      "         -0.6941, -0.3850,  0.3679, -0.4252, -0.5313,  0.6212,  0.3996, -0.7256,\n",
      "         -1.1840, -0.2032,  0.2016,  0.7418, -0.0033,  0.1144,  0.5800,  0.0859,\n",
      "          0.4771, -0.7424, -1.0714, -1.0736, -0.5059, -0.0913, -0.5322, -0.3802,\n",
      "         -0.3113, -0.6603, -0.9340, -0.9180,  0.5775,  0.2957,  0.0933, -0.0473,\n",
      "          0.2816,  0.2767, -0.1612,  0.4931],\n",
      "        [-0.5750, -0.5990, -1.1130, -0.5603, -1.1560, -0.4649, -0.4711, -0.4841,\n",
      "         -0.8493, -0.4002, -0.1757, -0.3533, -0.5211,  0.2921, -0.3397, -0.7400,\n",
      "         -0.0459,  0.4377, -0.5266,  0.7577, -0.3055,  0.7013, -0.5891, -0.3875,\n",
      "         -0.1554,  0.5193,  0.7168,  0.6063,  0.1068,  0.1874, -0.6761, -1.0116,\n",
      "         -0.7739, -0.3142, -0.8877,  0.3986,  0.3024, -0.5525, -0.7992,  0.3763,\n",
      "         -0.1660, -0.4840, -1.5207,  0.3915,  0.4057,  0.0529, -0.5838, -0.1911,\n",
      "         -0.8767, -0.7885,  0.0477,  0.4947, -0.2226, -0.0420, -0.6388,  0.3688,\n",
      "          0.3639, -0.4407,  0.7413, -0.6119,  0.7465,  0.5814, -0.5424, -0.7351,\n",
      "         -0.4538,  0.6473, -0.7899,  0.4571,  0.4098, -0.6556, -0.8246, -0.5659,\n",
      "         -0.3553,  0.0838,  0.8729, -0.0979, -0.0050, -0.6822, -0.7730,  0.0637,\n",
      "         -0.1291, -0.4907,  0.1254, -0.4618,  0.3701,  0.2620, -0.6542, -0.4151,\n",
      "          0.3464, -0.7073,  0.0355, -0.3468, -0.0560, -0.9410, -0.1741,  0.9411,\n",
      "         -0.6218, -0.7981,  0.4739, -0.3765],\n",
      "        [-0.5118,  1.2190,  0.6098, -0.4449,  0.2981, -0.6018, -0.5689,  0.3406,\n",
      "          0.4904, -0.2697,  0.9083, -1.2123, -0.0726,  1.4115,  0.3804,  0.2622,\n",
      "         -0.4064, -0.8425, -0.3077, -0.2945, -0.7978, -0.4108,  0.1944, -0.5570,\n",
      "          1.0801, -0.3982, -0.4792, -0.2557,  0.2672,  0.0713, -0.5837, -0.3596,\n",
      "          0.4422, -0.7683,  0.6672,  0.9651, -1.8831, -0.2848, -0.7119, -0.2157,\n",
      "         -0.1605, -0.4521,  0.4587, -0.4651, -0.1134, -0.4033, -0.4671,  0.3952,\n",
      "          0.4443,  0.5918, -0.1112,  0.2013, -0.0651, -0.4859,  0.0971,  0.0725,\n",
      "          0.0497, -0.1313, -1.0103, -0.3617, -0.2341,  0.0878,  0.3580, -0.5718,\n",
      "          0.1326, -0.4261, -0.5032, -0.7487, -0.9037,  0.0713, -0.7680,  0.1321,\n",
      "          0.0850, -0.1331, -0.4746, -0.4088, -0.3365, -0.5240, -0.1440, -0.3220,\n",
      "         -0.4045,  1.1103, -0.1024,  0.5440,  0.4194, -1.0277,  0.2527, -0.6265,\n",
      "         -0.0252, -0.6508, -0.1382, -0.9864, -0.3873,  0.1232,  0.2100, -0.8475,\n",
      "          0.1222, -0.4938, -1.1852,  0.2201],\n",
      "        [-0.2545,  0.4166, -1.0155, -0.2646, -1.2996,  0.5666, -0.7158,  0.6519,\n",
      "          0.3695, -0.1744,  0.3605,  0.3602, -0.9792, -0.5066, -0.5554,  0.4800,\n",
      "          0.0171,  0.5338,  0.7149, -0.0279, -0.2951, -0.0309,  0.3486,  0.2205,\n",
      "          0.8497, -0.5309,  0.3160, -0.0244, -0.7765, -1.4553, -0.6771, -0.2228,\n",
      "          0.0117, -0.5040, -0.0139, -0.6821,  0.0441,  0.4608,  0.4372,  0.5274,\n",
      "         -0.8443,  0.1233, -1.1661,  0.2686,  0.1577,  0.3605,  0.7534, -0.3634,\n",
      "          0.3816,  0.1005, -0.1004,  0.0906, -0.7030, -0.8908, -0.3739, -1.6109,\n",
      "         -0.6625, -0.1333, -0.2797,  0.5559, -0.5321,  0.0265, -0.7259, -0.2470,\n",
      "          0.0113, -0.6019, -0.4765,  0.7036,  0.3218, -0.3913, -0.4391, -0.2152,\n",
      "          0.5293, -0.2078, -0.7951,  0.4312, -0.4629, -0.7338, -0.4119,  0.1340,\n",
      "          0.8646,  0.3205,  0.1806, -0.5373,  0.0953, -0.4665,  0.5018,  0.0439,\n",
      "         -0.0952, -0.9727,  0.1565, -0.3117,  0.2419, -1.2299,  0.1458, -0.7488,\n",
      "         -0.6498,  0.5402,  0.0893, -0.5838]]))])}\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'model_cifar_39_s.pth.tar'\n",
    "checkpoint = torch.load(best_model_path, map_location=torch.device('cpu'))\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.057706498\n",
      "0.05773118\n"
     ]
    }
   ],
   "source": [
    "layers = [net.state_dict()['0.weight'].detach().cpu().numpy(),net.state_dict()['3.weight'].detach().cpu().numpy(),net.state_dict()['7.weight'].detach().cpu().numpy()]\n",
    "biases = [net.state_dict()['0.bias'].detach().cpu().numpy(),net.state_dict()['3.bias'].detach().cpu().numpy(),net.state_dict()['7.bias'].detach().cpu().numpy()]\n",
    "\n",
    "import numpy as np\n",
    "print(np.min(layers[1]))\n",
    "print(np.max(layers[1]))\n",
    "\n",
    "def conv2dOutputSize(layer,inputSize):\n",
    "    H_out = (inputSize[0] + layer.padding[0]-layer.dilation[0]*(layer.kernel_size[0]-1)-1)/layer.stride[0] +1\n",
    "    W_out = (inputSize[1] + layer.padding[0]-layer.dilation[1]*(layer.kernel_size[1]-1)-1)/layer.stride[1] +1\n",
    "    return [layer.out_channels,int(H_out),int(W_out)]\n",
    "\n",
    "def maxPoolOutputSize(layer,inputSize):\n",
    "    H_out = (inputSize[1] + layer.padding - layer.dilation*(layer.kernel_size-1)-1)/layer.stride +1\n",
    "    W_out = (inputSize[2] + layer.padding - layer.dilation*(layer.kernel_size-1)-1)/layer.stride +1\n",
    "    return [inputSize[0],int(H_out),int(W_out)]\n",
    "\n",
    "def AvgPoolOutputSize(layer,inputSize):\n",
    "    H_out = (inputSize[1] + layer.padding*2 - (layer.kernel_size-1))/layer.stride +1\n",
    "    W_out = (inputSize[2] + layer.padding*2 - (layer.kernel_size-1))/layer.stride +1\n",
    "    return [inputSize[0],int(H_out),int(W_out)]\n",
    "\n",
    "\n",
    "def optimized_conv2dToCRI(inputs, output, layer, layerIdx, axonsDict=None, neuronsDict=None):\n",
    "    Hk, Wk = layer.kernel_size\n",
    "    filters = layer.weight.detach().cpu().numpy()\n",
    "    pad_top, pad_left = Hk // 2, Wk // 2\n",
    "\n",
    "    # Define a helper function to reduce code redundancy\n",
    "    def process_patch(input_slice, output_slice, filters, axonsDict, neuronsDict, layerIdx, channel=None):\n",
    "        \"\"\"\n",
    "        This function processes a given patch of input neurons or axons and \n",
    "        updates the axonsDict or neuronsDict accordingly.\n",
    "        \"\"\"\n",
    "        for filIdx, fil in enumerate(filters):\n",
    "            postSynapticID = str(output_slice[filIdx])\n",
    "            fil = fil[channel] if channel is not None else fil[0]\n",
    "            for i, row in enumerate(input_slice):\n",
    "                for j, elem in enumerate(row):\n",
    "                    key = str(elem) if layerIdx != 0 else elem\n",
    "                    synapse_info = (postSynapticID, int(fil[i, j]))\n",
    "                    (neuronsDict if layerIdx != 0 else axonsDict)[key].append(synapse_info)\n",
    "\n",
    "    if layerIdx == 0:\n",
    "        Hi, Wi = inputs.shape\n",
    "        for row in range(pad_top, Hi - pad_top):\n",
    "            for col in range(pad_left, Wi - pad_left):\n",
    "                patch = inputs[row - pad_top:row + pad_top + 1, col - pad_left:col + pad_left + 1]\n",
    "                output_slice = output[:, row - pad_top, col - pad_left]\n",
    "                process_patch(patch, output_slice, filters, axonsDict, neuronsDict, layerIdx)\n",
    "    else:\n",
    "        C, Hi, Wi = inputs.shape\n",
    "        for channel in range(C):\n",
    "            for row in range(pad_top, Hi - pad_top):\n",
    "                for col in range(pad_left, Wi - pad_left):\n",
    "                    patch = inputs[channel, row - pad_top:row + pad_top + 1, col - pad_left:col + pad_left + 1]\n",
    "                    output_slice = output[:, row - pad_top, col - pad_left]\n",
    "                    process_patch(patch, output_slice, filters, axonsDict, neuronsDict, layerIdx, channel)\n",
    "\n",
    "def poolingToCRI(inputs, output, layer, neuronsDict, scaler=1e6, pool_type='max'):\n",
    "    C, Hi, Wi = inputs.shape\n",
    "    kernel_size = layer.kernel_size\n",
    "    pad_size = kernel_size // 2\n",
    "    stride = 2\n",
    "\n",
    "    for channel in range(C):\n",
    "        for row in range(0, Hi, stride):\n",
    "            for col in range(0, Wi, stride):\n",
    "                patch = inputs[channel, row:row+kernel_size, col:col+kernel_size]\n",
    "                postSynapticID = str(output[channel, row//stride, col//stride])\n",
    "\n",
    "                # Determine the pooling value\n",
    "                if pool_type == 'max':\n",
    "                    pooling_value = patch.max() * scaler\n",
    "                elif pool_type == 'avg':\n",
    "                    pooling_value = patch.mean() * scaler\n",
    "\n",
    "                # Update neuronsDict with postSynapticID and pooling_value\n",
    "                for preSynNeuron in patch.flatten():\n",
    "                    neuronsDict[str(preSynNeuron)].append((postSynapticID, pooling_value))\n",
    "\n",
    "# Wrapper functions for max pooling and average pooling\n",
    "def maxPoolToCRI(inputs, output, layer, neuronsDict, scaler=1e6):\n",
    "    return poolingToCRI(inputs, output, layer, neuronsDict, scaler, pool_type='max')\n",
    "\n",
    "def avgPoolToCRI(inputs, output, layer, neuronsDict, scaler=1e6):\n",
    "    return poolingToCRI(inputs, output, layer, neuronsDict, scaler, pool_type='avg')\n",
    "\n",
    "  \n",
    "def linearToCRI(inputs,output,layer,layerIdx,neuronsDict,outputNeurons=None):\n",
    "    inputs = inputs.flatten()\n",
    "    weight = layer.weight.detach().cpu().numpy()\n",
    "    currLayerNeuronIdxOffset,nextLayerNeuronIdxOffset = inputs[0],inputs[-1]+1\n",
    "    for baseNeuronIdx, neuron in enumerate(weight.T):\n",
    "        neuronID = str(baseNeuronIdx+currLayerNeuronIdxOffset)\n",
    "        neuronEntry = [(str(basePostSynapticID+nextLayerNeuronIdxOffset), int(synapseWeight)) for basePostSynapticID, synapseWeight in enumerate(neuron) if synapseWeight != 0]\n",
    "        neuronsDict[neuronID] = neuronEntry\n",
    "    print('instantiate output neurons')\n",
    "    for baseNeuronIdx in range(layer.out_features):\n",
    "        neuronID = str(baseNeuronIdx+nextLayerNeuronIdxOffset)\n",
    "        neuronsDict[neuronID] = []\n",
    "        outputNeurons.append(neuronID)\n",
    "        \n",
    "def convBiasAxons(layer,axonsDict,axonOffset,outputs):\n",
    "    biases = layer.bias.detach().cpu().numpy()\n",
    "    for biasIdx, bias in enumerate(biases):\n",
    "        biasID = 'a'+str(biasIdx+axonOffset)\n",
    "        axonsDict[biasID] = [(str(neuronIdx),int(bias)) for neuronIdx in outputs[biasIdx].flatten()]\n",
    "        \n",
    "def linearBiasAXons(layer,axonsDict,axonOffset,outputs):\n",
    "    biases = layer.bias.detach().cpu().numpy()\n",
    "    for biasIdx, bias in enumerate(biases):\n",
    "        biasID = 'a'+str(biasIdx+axonOffset)\n",
    "        axonsDict[biasID] = [(str(outputs[biasIdx]),int(bias))]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRIConverter:\n",
    "    def __init__(self, scalar=1e6):\n",
    "        self.axonsDict = {}\n",
    "        self.neuronsDict = {}\n",
    "        self.scalar = scalar\n",
    "        \n",
    "    @staticmethod \n",
    "    def _conv2dOutputSize(layer, inputSize):\n",
    "        H_out = (inputSize[0] + 2 * layer.padding[0] - layer.dilation[0] * (layer.kernel_size[0] - 1) - 1) // layer.stride[0] + 1\n",
    "        W_out = (inputSize[1] + 2 * layer.padding[1] - layer.dilation[1] * (layer.kernel_size[1] - 1) - 1) // layer.stride[1] + 1\n",
    "        return [layer.out_channels, int(H_out), int(W_out)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _maxPoolOutputSize(layer, inputSize):\n",
    "        H_out = (inputSize[1] + 2 * layer.padding - layer.dilation * (layer.kernel_size - 1) - 1) // layer.stride + 1\n",
    "        W_out = (inputSize[2] + 2 * layer.padding - layer.dilation * (layer.kernel_size - 1) - 1) // layer.stride + 1\n",
    "        return [inputSize[0], int(H_out), int(W_out)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _avgPoolOutputSize(layer, inputSize):\n",
    "        H_out = (inputSize[1] + layer.padding*2 - (layer.kernel_size-1))/layer.stride +1\n",
    "        W_out = (inputSize[2] + layer.padding*2 - (layer.kernel_size-1))/layer.stride +1\n",
    "        return [inputSize[0],int(H_out),int(W_out)]   \n",
    "    \n",
    "    def conv2dToCRI(self, inputs, output, layer, layerIdx, axonsDict=None, neuronsDict=None):\n",
    "        \"\"\"\n",
    "        Convert a convolutional layer to a CRI representation.\n",
    "        \n",
    "        Parameters:\n",
    "            inputs (torch.Tensor): The input tensor to the convolutional layer.\n",
    "            output (torch.Tensor): The output tensor of the convolutional layer.\n",
    "            layer (torch.nn.Conv2d): The convolutional layer to convert.\n",
    "            layerIdx (int): The index of the current convolutional layer within the model.\n",
    "            axonsDict (dict, optional): A dictionary that maps axon IDs to their synapse information. Defaults to None.\n",
    "            neuronsDict (dict, optional): A dictionary that maps neuron IDs to their synapse information. Defaults to None.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "            \n",
    "        Hk, Wk = layer.kernel_size\n",
    "        filters = layer.weight.detach().cpu().numpy()\n",
    "        pad_top, pad_left = Hk // 2, Wk // 2\n",
    "\n",
    "        # Define a helper function to reduce code redundancy\n",
    "        def process_patch(input_slice, output_slice, filters, axonsDict, neuronsDict, layerIdx, channel=None):\n",
    "            \"\"\"\n",
    "            Process a given patch of input neurons or axons and update axonsDict or neuronsDict.\n",
    "            \"\"\"\n",
    "            for filIdx, fil in enumerate(filters):\n",
    "                postSynapticID = str(output_slice[filIdx])\n",
    "                fil = fil[channel] if channel is not None else fil[0]\n",
    "                for i, row in enumerate(input_slice):\n",
    "                    for j, elem in enumerate(row):\n",
    "                        key = str(elem) if layerIdx != 0 else elem\n",
    "                        synapse_info = (postSynapticID, int(fil[i, j]))\n",
    "                        (neuronsDict if layerIdx != 0 else axonsDict)[key].append(synapse_info)\n",
    "        \n",
    "        if layerIdx == 0:\n",
    "            Hi, Wi = inputs.shape\n",
    "            for row in range(pad_top, Hi - pad_top):\n",
    "                for col in range(pad_left, Wi - pad_left):\n",
    "                    patch = inputs[row - pad_top:row + pad_top + 1, col - pad_left:col + pad_left + 1]\n",
    "                    output_slice = output[:, row - pad_top, col - pad_left]\n",
    "                    process_patch(patch, output_slice, filters, axonsDict, neuronsDict, layerIdx)\n",
    "        else:\n",
    "            C, Hi, Wi = inputs.shape\n",
    "            for channel in range(C):\n",
    "                for row in range(pad_top, Hi - pad_top):\n",
    "                    for col in range(pad_left, Wi - pad_left):\n",
    "                        patch = inputs[channel, row - pad_top:row + pad_top + 1, col - pad_left:col + pad_left + 1]\n",
    "                        output_slice = output[:, row - pad_top, col - pad_left]\n",
    "                        process_patch(patch, output_slice, filters, axonsDict, neuronsDict, layerIdx, channel)\n",
    "\n",
    "\n",
    "    def poolingToCRI(self, inputs, output, neuronsDict, layer, pool_type='max'):\n",
    "        \"\"\"\n",
    "        Convert a pooling layer to a CRI representation.\n",
    "        \n",
    "        Parameters:\n",
    "            inputs (torch.Tensor): The input tensor to the pooling layer.\n",
    "            output (torch.Tensor): The output tensor of the pooling layer.\n",
    "            neuronsDict (dict): A dictionary that maps neuron IDs to their synapse information.\n",
    "            layer (torch.nn.MaxPool2d or torch.nn.AvgPool2d): The pooling layer to convert.\n",
    "            pool_type (str, optional): The type of pooling operation, either 'max' or 'avg'. Defaults to 'max'.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        C, Hi, Wi = inputs.shape\n",
    "        kernel_size = layer.kernel_size\n",
    "        pad_size = kernel_size // 2\n",
    "        stride = 2\n",
    "\n",
    "        for channel in range(C):\n",
    "            for row in range(0, Hi, stride):\n",
    "                for col in range(0, Wi, stride):\n",
    "                    patch = inputs[channel, row:row+kernel_size, col:col+kernel_size]\n",
    "                    postSynapticID = str(output[channel, row//stride, col//stride])\n",
    "\n",
    "                    # Determine the pooling value\n",
    "                    if pool_type == 'max':\n",
    "                        pooling_value = patch.max() * self.scalar\n",
    "                    elif pool_type == 'avg':\n",
    "                        pooling_value = patch.mean() * self.scalar\n",
    "\n",
    "                    # Update neuronsDict with postSynapticID and pooling_value\n",
    "                    for preSynNeuron in patch.flatten():\n",
    "                        neuronsDict[str(preSynNeuron)].append((postSynapticID, pooling_value))\n",
    "    \n",
    "    # Wrapper functions\n",
    "    def maxPoolToCRI(self, inputs, output, neuronsDict, layer):\n",
    "        return self.poolingToCRI(inputs, output, neuronsDict, layer, pool_type='max')\n",
    "\n",
    "    def avgPoolToCRI(self, inputs, output,neuronsDict, layer):\n",
    "        return self.poolingToCRI(inputs, output, neuronsDict, layer, pool_type='avg')\n",
    "    \n",
    "    def linearToCRI(self, inputs, layer, neuronsDict, outputNeurons=None):\n",
    "        \"\"\"\n",
    "        Convert a linear layer to a CRI representation.\n",
    "        \n",
    "        Parameters:\n",
    "            inputs (torch.Tensor): The input tensor to the linear layer.\n",
    "            output (torch.Tensor): The output tensor of the linear layer.\n",
    "            layer (torch.nn.Linear): The linear layer to convert.\n",
    "            layerIdx (int): The index of the current linear layer within the model.\n",
    "            neuronsDict (dict): A dictionary that maps neuron IDs to their synapse information.\n",
    "            outputNeurons (list, optional): A list to store the neuron IDs of the output neurons.\n",
    "                                        Defaults to None, in which case a new list is created.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if outputNeurons is None:\n",
    "            outputNeurons = []\n",
    "\n",
    "        # Flatten the input tensor\n",
    "        inputs = inputs.flatten()\n",
    "\n",
    "        # Detach the weight matrix from the computational graph and convert to NumPy array\n",
    "        weight = layer.weight.detach().cpu().numpy()\n",
    "\n",
    "        # Determine neuron index offsets for the current and next layers\n",
    "        currLayerNeuronIdxOffset, nextLayerNeuronIdxOffset = inputs[0], inputs[-1] + 1\n",
    "\n",
    "        # Iterate over neurons and weights in the transposed weight matrix\n",
    "        for baseNeuronIdx, neuron in enumerate(weight.T):\n",
    "            neuronID = str(baseNeuronIdx + currLayerNeuronIdxOffset)\n",
    "            # Create a list of synapses with non-zero weights\n",
    "            neuronEntry = [(str(basePostSynapticID + nextLayerNeuronIdxOffset), int(synapseWeight))\n",
    "                        for basePostSynapticID, synapseWeight in enumerate(neuron) if synapseWeight != 0]\n",
    "            neuronsDict[neuronID] = neuronEntry\n",
    "\n",
    "        # Instantiate output neurons\n",
    "        for baseNeuronIdx in range(layer.out_features):\n",
    "            neuronID = str(baseNeuronIdx + nextLayerNeuronIdxOffset)\n",
    "            neuronsDict[neuronID] = []\n",
    "            outputNeurons.append(neuronID)\n",
    "    \n",
    "    def convBiasAxons(self, layer, axonsDict, axonOffset, outputs):\n",
    "        \"\"\"\n",
    "        Convert biases of a convolutional layer to axon entries in the CRI representation.\n",
    "        \n",
    "        Parameters:\n",
    "            layer (torch.nn.Conv2d): The convolutional layer to convert.\n",
    "            axonsDict (dict): A dictionary that maps axon IDs to their synapse information.\n",
    "            axonOffset (int): An offset value for axon IDs.\n",
    "            outputs (torch.Tensor): The output tensor of the convolutional layer.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Detach the biases from the computational graph and convert to NumPy array\n",
    "        biases = layer.bias.detach().cpu().numpy()\n",
    "\n",
    "        # Iterate over biases and create axon entries\n",
    "        for biasIdx, bias in enumerate(biases):\n",
    "            biasID = f'a{biasIdx + axonOffset}'\n",
    "            axonsDict[biasID] = [(str(neuronIdx), int(bias)) for neuronIdx in outputs[biasIdx].flatten()]\n",
    "\n",
    "    def linearBiasAxons(self, layer, axonsDict, axonOffset, outputs):\n",
    "        \"\"\"\n",
    "        Convert biases of a linear layer to axon entries in the CRI representation.\n",
    "        \n",
    "        Parameters:\n",
    "            layer (torch.nn.Linear): The linear layer to convert.\n",
    "            axonsDict (dict): A dictionary that maps axon IDs to their synapse information.\n",
    "            axonOffset (int): An offset value for axon IDs.\n",
    "            outputs (torch.Tensor): The output tensor of the linear layer.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Detach the biases from the computational graph and convert to NumPy array\n",
    "        biases = layer.bias.detach().cpu().numpy()\n",
    "\n",
    "        # Iterate over biases and create axon entries\n",
    "        for biasIdx, bias in enumerate(biases):\n",
    "            biasID = f'a{biasIdx + axonOffset}'\n",
    "            axonsDict[biasID] = [(str(outputs[biasIdx]), int(bias))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing Axons\n",
      "Input layer shape(infeature, outfeature):  (28, 28) , [12, 24, 24]\n",
      "constructing bias axons for input layer: 12 axons\n",
      "constructing hidden avgpool layer\n",
      "Hidden layer shape(infeature, outfeature):  (12, 24, 24) , [12, 12, 12]\n",
      "Numer of neurons: 6912\n",
      "constructing hidden conv2d layer\n",
      "Hidden layer shape(infeature, outfeature):  (12, 12, 12) , [64, 8, 8]\n",
      "constructing bias axons for hidden conv2d layer: 64 axons\n",
      "Numer of neurons: 8640\n",
      "constructing hidden avgpool layer\n",
      "Hidden layer shape(infeature, outfeature):  (64, 8, 8) , [64, 4, 4]\n",
      "Numer of neurons: 12736\n",
      "constructing output layer\n",
      "output layer shape(infeature, outfeature):  1024 , 10\n",
      "constructing bias axons for output linearlayer: 10 axons\n",
      "Numer of neurons: 13770\n",
      "time taken: 2.1457672119140625e-06s\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "# import cProfile\n",
    "\n",
    "# profiler = cProfile.Profile()\n",
    "\n",
    "# Start profiling\n",
    "# profiler.enable()\n",
    "axonsDict = defaultdict(list)\n",
    "neuronsDict = defaultdict(list)\n",
    "\n",
    "# axonsDict1 = defaultdict(list)\n",
    "# neuronsDict1 = defaultdict(list)\n",
    "# axonsDict2 = defaultdict(list)\n",
    "# neuronsDict2 = defaultdict(list)\n",
    "\n",
    "outputNeurons = []\n",
    "H_in, W_in = 28, 28\n",
    "inputSize = (H_in, W_in)\n",
    "axonOffset = 0\n",
    "neuronOffset = 0\n",
    "currInput = None\n",
    "converter = CRIConverter()\n",
    "    \n",
    "    \n",
    "for layerIdx, layer in enumerate(net):\n",
    "    start_time = time.time()\n",
    "        \n",
    "    if layerIdx == 0 and isinstance(layer, torch.nn.Conv2d): #input layer\n",
    "        print('constructing Axons')\n",
    "        outputSize = converter._conv2dOutputSize(layer,inputSize)\n",
    "        print(\"Input layer shape(infeature, outfeature): \", inputSize,',',outputSize)\n",
    "        input = np.arange(0,inputSize[0]*inputSize[1],dtype=int).reshape(inputSize)\n",
    "        inputAxons = np.array([['a'+str(i) for i in row] for row in input])\n",
    "        output = np.arange(0,outputSize[0]*outputSize[1]*outputSize[2],dtype=int).reshape(outputSize)\n",
    "        converter.conv2dToCRI(inputAxons,output,layer,layerIdx,axonsDict)\n",
    "        axonOffset += len(axonsDict)\n",
    "        print('constructing bias axons for input layer:',layer.bias.shape[0],'axons')\n",
    "        converter.convBiasAxons(layer,axonsDict,axonOffset,output)\n",
    "        axonOffset += layer.bias.shape[0]\n",
    "        currInput = output\n",
    "    elif layerIdx == len(net)-2 and isinstance(layer, torch.nn.Linear): #output layer\n",
    "        print('constructing output layer')\n",
    "        outputSize = layer.out_features\n",
    "        print(\"output layer shape(infeature, outfeature): \", currInput.flatten().shape[0],',',outputSize)\n",
    "        neuronOffset += currInput.shape[0]*currInput.shape[1]*currInput.shape[2]\n",
    "        output = np.arange(neuronOffset,neuronOffset+outputSize,dtype=int)\n",
    "        converter.linearToCRI(currInput,layer,neuronsDict,outputNeurons=outputNeurons)\n",
    "        print('constructing bias axons for output linearlayer:',layer.bias.shape[0],'axons')\n",
    "        print('Numer of neurons:',len(neuronsDict))\n",
    "        converter.linearBiasAxons(layer,axonsDict,axonOffset,output)\n",
    "        axonOffset += layer.bias.shape[0]\n",
    "    else: #hidden layer\n",
    "        if isinstance(layer,torch.nn.AvgPool2d):\n",
    "            print('constructing hidden avgpool layer')\n",
    "            outputSize = converter._avgPoolOutputSize(layer,currInput.shape)\n",
    "            print(\"Hidden layer shape(infeature, outfeature): \", currInput.shape,',',outputSize)\n",
    "            neuronOffset += currInput.shape[0]*currInput.shape[1]*currInput.shape[2]\n",
    "            output = np.arange(neuronOffset,neuronOffset+outputSize[0]*outputSize[1]*outputSize[2],dtype=int).reshape(outputSize)\n",
    "            converter.avgPoolToCRI(currInput,output,neuronsDict,layer)\n",
    "            currInput = output\n",
    "            print('Numer of neurons:',len(neuronsDict))\n",
    "        if isinstance(layer,torch.nn.Conv2d):\n",
    "            print('constructing hidden conv2d layer')\n",
    "            outputSize = converter._conv2dOutputSize(layer,currInput.shape)\n",
    "            print(\"Hidden layer shape(infeature, outfeature): \", currInput.shape,',',outputSize)\n",
    "            neuronOffset += currInput.shape[0]*currInput.shape[1]*currInput.shape[2]\n",
    "            output = np.arange(neuronOffset,neuronOffset+outputSize[0]*outputSize[1]*outputSize[2],dtype=int).reshape(outputSize)\n",
    "            converter.conv2dToCRI(currInput,output,layer,layerIdx,neuronsDict=neuronsDict)\n",
    "            print('constructing bias axons for hidden conv2d layer:',layer.bias.shape[0],'axons')\n",
    "            converter.convBiasAxons(layer,axonsDict,axonOffset,output)\n",
    "            axonOffset += layer.bias.shape[0]\n",
    "            currInput = output\n",
    "            print('Numer of neurons:',len(neuronsDict))\n",
    "    end_time = time.time()\n",
    "    \n",
    "total_time = end_time-start_time\n",
    "print(f'time taken: {total_time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_conv2dToCRI (__main__.TestLayerToCRIConverter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/vr/5qw6zp9500gd5_dc2ts4bk8r0000gn/T/ipykernel_31907/3221027896.py\", line 16, in test_conv2dToCRI\n",
      "    self.converter.conv2dToCRI(input_tensor, output_tensor, conv_layer, 0, neuronsDict=neuronsDict)\n",
      "  File \"/var/folders/vr/5qw6zp9500gd5_dc2ts4bk8r0000gn/T/ipykernel_31907/3156014874.py\", line 60, in conv2dToCRI\n",
      "    Hi, Wi = inputs.shape\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=1 failures=0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import unittest\n",
    "\n",
    "class TestLayerToCRIConverter(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Create an instance of the LayerToCRIConverter class for testing\n",
    "        self.converter = CRIConverter()\n",
    "\n",
    "    def test_conv2dToCRI(self):\n",
    "        # Test conv2dToCRI method with a simple convolutional layer\n",
    "        conv_layer = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "        input_tensor = torch.randn(1, 1, 28, 28)  # Batch size: 1, Channels: 1, Height: 5, Width: 5\n",
    "        output_tensor = conv_layer(input_tensor)\n",
    "        neuronsDict = defaultdict(list)\n",
    "        self.converter.conv2dToCRI(input_tensor, output_tensor, conv_layer, 0, neuronsDict=neuronsDict)\n",
    "\n",
    "        # Assert that neuronsDict contains expected keys and synapse information\n",
    "        self.assertIn('0', neuronsDict)  # Check if neuron ID '0' exists in neuronsDict\n",
    "        self.assertIn('1', neuronsDict)  # Check if neuron ID '1' exists in neuronsDict\n",
    "\n",
    "    # def test_maxPoolToCRI(self):\n",
    "    #     # Test maxPoolToCRI method with a simple max pooling layer\n",
    "    #     maxpool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     input_tensor = torch.tensor([[[[1.0, 2.0], [3.0, 4.0]]]])  # Batch size: 1, Channels: 1, Height: 2, Width: 2\n",
    "    #     output_tensor = maxpool_layer(input_tensor)\n",
    "    #     neuronsDict = {}\n",
    "    #     self.converter.maxPoolToCRI(input_tensor, output_tensor, maxpool_layer, neuronsDict)\n",
    "\n",
    "    #     # Assert that neuronsDict contains expected keys and pooling values\n",
    "    #     self.assertIn('2', neuronsDict)  # Check if neuron ID '2' exists in neuronsDict\n",
    "    #     self.assertEqual(neuronsDict['2'][0][1], 4.0)  # Check the pooling value\n",
    "\n",
    "    # def test_avgPoolToCRI(self):\n",
    "    #     # Test avgPoolToCRI method with a simple average pooling layer\n",
    "    #     avgpool_layer = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    #     input_tensor = torch.tensor([[[[1.0, 2.0], [3.0, 4.0]]]])  # Batch size: 1, Channels: 1, Height: 2, Width: 2\n",
    "    #     output_tensor = avgpool_layer(input_tensor)\n",
    "    #     neuronsDict = defaultdict(list)\n",
    "    #     self.converter.avgPoolToCRI(input_tensor, output_tensor, avgpool_layer, neuronsDict)\n",
    "\n",
    "    #     # Assert that neuronsDict contains expected keys and pooling values\n",
    "    #     self.assertIn('2', neuronsDict)  # Check if neuron ID '2' exists in neuronsDict\n",
    "    #     self.assertEqual(neuronsDict['2'][0][1], 2.5)  # Check the pooling value\n",
    "\n",
    "    # def test_linearToCRI(self):\n",
    "    #     # Test linearToCRI method with a simple linear layer\n",
    "    #     linear_layer = nn.Linear(in_features=4, out_features=2)\n",
    "    #     input_tensor = torch.randn(1, 4) # Batch size: 1, Input features: 4\n",
    "    #     output_tensor = linear_layer(input_tensor)\n",
    "    #     neuronsDict = defaultdict(list)\n",
    "    #     outputNeurons = []\n",
    "    #     self.converter.linearToCRI(input_tensor, output_tensor, linear_layer, 0, neuronsDict, outputNeurons)\n",
    "        \n",
    "    #     # Assert that neuronsDict contains expected keys and synapse information\n",
    "    #     self.assertIn('0', neuronsDict)  # Check if neuron ID '0' exists in neuronsDict\n",
    "    #     self.assertIn('1', neuronsDict)  # Check if neuron ID '1' exists in neuronsDict\n",
    "    #     self.assertIn('2', neuronsDict)  # Check if neuron ID '2' exists in neuronsDict\n",
    "    #     self.assertIn('3', neuronsDict)  # Check if neuron ID '3' exists in neuronsDict\n",
    "\n",
    "    #     # Assert that outputNeurons contains expected neuron IDs\n",
    "    #     self.assertIn('4', outputNeurons)  # Check if neuron ID '4' exists in outputNeurons\n",
    "    #     self.assertIn('5', outputNeurons)  # Check if neuron ID '5' exists in outputNeurons\n",
    "\n",
    "    # def test_convBiasAxons(self):\n",
    "    #     # Test convBiasAxons method with a simple convolutional layer\n",
    "    #     conv_layer = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "    #     input_tensor = torch.randn(1, 1, 5, 5)  # Batch size: 1, Channels: 1, Height: 5, Width: 5\n",
    "    #     output_tensor = conv_layer(input_tensor)\n",
    "    #     axonsDict = {}\n",
    "    #     self.converter.convBiasAxons(conv_layer, axonsDict, 0, output_tensor)\n",
    "\n",
    "    #     # Assert that axonsDict contains expected keys and bias values\n",
    "    #     self.assertIn('a0', axonsDict)  # Check if axon ID 'a0' exists in axonsDict\n",
    "    #     self.assertIn('a1', axonsDict)  # Check if axon ID 'a1' exists in axonsDict\n",
    "\n",
    "    # def test_linearBiasAxons(self):\n",
    "    #     # Test linearBiasAxons method with a simple linear layer\n",
    "    #     linear_layer = nn.Linear(in_features=4, out_features=2)\n",
    "    #     input_tensor = torch.randn(1, 4)  # Batch size: 1, Input features: 4\n",
    "    #     output_tensor = linear_layer(input_tensor)\n",
    "    #     axonsDict = {}\n",
    "    #     self.converter.linearBiasAxons(linear_layer, axonsDict, 0, output_tensor)\n",
    "\n",
    "    #     # Assert that axonsDict contains expected keys and bias values\n",
    "    #     self.assertIn('a0', axonsDict)  # Check if axon ID 'a0' exists in axonsDict\n",
    "    #     self.assertIn('a1', axonsDict)  # Check if axon ID 'a1' exists in axonsDict\n",
    "        \n",
    "# Create a test loader\n",
    "loader = unittest.TestLoader()\n",
    "\n",
    "# Load tests from the test class\n",
    "suite = loader.loadTestsFromTestCase(TestLayerToCRIConverter)\n",
    "\n",
    "# Use TextTestRunner to run the tests\n",
    "unittest.TextTestRunner().run(suite)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
