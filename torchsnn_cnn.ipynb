{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSGZ6cdmpknm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">](https://github.com/jeshraghian/snntorch/)\n",
    "\n",
    "# snnTorch - Surrogate Gradient Descent in a Convolutional Spiking Neural Network\n",
    "## Tutorial 6\n",
    "### By Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/tutorial_6_CNN.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rugeYYiqsrlc"
   },
   "source": [
    "The snnTorch tutorial series is based on the following paper. If you find these resources or code useful in your work, please consider citing the following source:\n",
    "\n",
    "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". arXiv preprint arXiv:2109.12894, September 2021.](https://arxiv.org/abs/2109.12894) </cite>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ymi3sqJg28OQ"
   },
   "source": [
    "# Introduction\n",
    "In this tutorial, you will:\n",
    "* Learn how to use surrogate gradient descent to overcome the dead neuron problem\n",
    "* Construct and train a convolutional spiking neural network\n",
    "* Use a sequential container, `nn.Sequential` to simplify model construction\n",
    "* Use the `snn.backprop` module to reduce the time it takes to design a neural network\n",
    "\n",
    "Part of this tutorial was inspired by Friedemann Zenke’s extensive\n",
    "work on SNNs. Check out his repo on surrogate gradients\n",
    "[here](https://github.com/fzenke/spytorch), and a favourite paper\n",
    "of mine: E. O. Neftci, H. Mostafa, F. Zenke, [Surrogate Gradient\n",
    "Learning in Spiking Neural Networks: Bringing the Power of\n",
    "Gradient-based optimization to spiking neural\n",
    "networks.](https://ieeexplore.ieee.org/document/8891809) IEEE\n",
    "Signal Processing Magazine 36, 51–63.\n",
    "\n",
    "At the end of the tutorial, we will train a convolutional spiking neural network (CSNN) using the MNIST dataset to perform image classification. The background theory follows on from [Tutorials 2, 4 and 5](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), so feel free to go back if you need to brush up.\n",
    "\n",
    "If running in Google Colab:\n",
    "* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`\n",
    "* Next, install the latest PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tn_wUlopkon",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXZ6Tuqc9Q-l"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aQvFG7ajpzU"
   },
   "source": [
    "### Define gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dCWD_qajyLw"
   },
   "outputs": [],
   "source": [
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffn7D6omkj5r"
   },
   "source": [
    "To explore the other surrogate gradient functions available, [take a look at the documentation here.](https://snntorch.readthedocs.io/en/latest/snntorch.surrogate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgzf83HE2BeB"
   },
   "source": [
    "## 2.1 DataLoaders\n",
    "Note that `utils.data_subset()` is called to reduce the size of the dataset by a factor of 10 to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxO32dntlOB2"
   },
   "outputs": [],
   "source": [
    "# dataloader arguments\n",
    "batch_size = 128\n",
    "data_path='~/justinData/mnist'\n",
    "subset=10\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE7eGTnulSBA"
   },
   "outputs": [],
   "source": [
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "# reduce datasets by 10x to speed up training\n",
    "utils.data_subset(mnist_train, subset)\n",
    "utils.data_subset(mnist_test, subset)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v8fBXrVlY3f"
   },
   "source": [
    "## 2.2 Define the Network\n",
    "\n",
    "The convolutional network architecture to be used is: 12C5-MP2-64C5-MP2-1024FC10\n",
    "\n",
    "- 12C5 is a 5$\\times$5 convolutional kernel with 12 filters\n",
    "- MP2 is a 2$\\times$2 max-pooling function\n",
    "- 1024FC10 is a fully-connected layer that maps 1,024 neurons to 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foos_NlopDrb"
   },
   "outputs": [],
   "source": [
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 1.0\n",
    "num_steps = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4sd8PDSlGZb"
   },
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.conv2 = nn.Conv2d(12, 64, 5)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.fc1 = nn.Linear(64*4*4, 10)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        cur1 = F.max_pool2d(self.conv1(x), 2)\n",
    "        spk1, mem1 = self.lif1(cur1, mem1)\n",
    "        \n",
    "        cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
    "        spk2, mem2 = self.lif2(cur2, mem2)\n",
    "    \n",
    "        cur3 = self.fc1(spk2.view(batch_size, -1))\n",
    "        spk3, mem3 = self.lif3(cur3, mem3)\n",
    "        return spk3, mem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVn3aYAUnWqH"
   },
   "source": [
    "In the previous tutorial, the network was wrapped inside of a class, as shown above. \n",
    "With increasing network complexity, this adds a lot of boilerplate code that we might wish to avoid. Alternatively, the `nn.Sequential` method can be used instead.\n",
    "\n",
    "> Note: the following code-block simulates over one single time-step, and requires a separate for-loop over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoYBY89angvp"
   },
   "outputs": [],
   "source": [
    "#  Initialize Network\n",
    "net = nn.Sequential(nn.Conv2d(1, 12, 5),\n",
    "                    nn.AvgPool2d(2, stride=2),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Conv2d(12, 64, 5),\n",
    "                    nn.AvgPool2d(2, stride=2),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(64*4*4, 10),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qgw1dRmpOlo"
   },
   "source": [
    "\n",
    "The `init_hidden` argument initializes the hidden states of the neuron (here, membrane potential). This takes place in the background as an instance variable. \n",
    "If `init_hidden` is activated, the membrane potential is not explicitly returned to the user, ensuring only the output spikes are sequentially passed through the layers wrapped in `nn.Sequential`. \n",
    "\n",
    "To train a model using the final layer's membrane potential, set the argument `output=True`. \n",
    "This enables the final layer to return both the spike and membrane potential response of the neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi-wfNda5QwW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-bCSQmBstvd"
   },
   "source": [
    "## 2.3 Forward-Pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3PxtCobuH_e"
   },
   "source": [
    "Wrap that in a function, recording the membrane potential and spike response over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykdnD3tRuHcs"
   },
   "outputs": [],
   "source": [
    "def forward_pass(net, num_steps, data):\n",
    "  mem_rec = []\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(num_steps):\n",
    "      spk_out, mem_out = net(data)\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "  \n",
    "  return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unJrx3pXcXii"
   },
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = forward_pass(net, num_steps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqJdfllYbc16"
   },
   "source": [
    "# 3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-kquOWLY1Jo"
   },
   "source": [
    "## 3.1 Loss Using snn.Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlA56BgOYq1D"
   },
   "source": [
    "In the previous tutorial, the Cross Entropy Loss between the membrane potential of the output neurons and the target was used to train the network. \n",
    "This time, the total number of spikes from each neuron will be used to calculate the Cross Entropy instead.\n",
    "\n",
    "A variety of loss functions are included in the `snn.functional` module, which is analogous to `torch.nn.functional` in PyTorch. \n",
    "These implement a mix of cross entropy and mean square error losses, are applied to spikes and/or membrane potential, to train a rate or latency-coded network. \n",
    "\n",
    "The approach below applies the cross entropy loss to the output spike count in order train a rate-coded network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ2BM6d6a11l"
   },
   "outputs": [],
   "source": [
    "# already imported snntorch.functional as SF \n",
    "loss_fn = SF.ce_rate_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q39HCIeOa4fC"
   },
   "source": [
    "The recordings of the spike are passed as the first argument to `loss_fn`, and the target neuron index as the second argument to generate a loss. [The documentation provides further information and exmaples.](https://snntorch.readthedocs.io/en/latest/snntorch.functional.html#snntorch.functional.ce_rate_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEVzMvujcjsE"
   },
   "outputs": [],
   "source": [
    "loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "print(f\"The loss from an untrained network is {loss_val.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS_zeb5mbqjw"
   },
   "source": [
    "## 3.2 Accuracy Using snn.Functional\n",
    "The `SF.accuracy_rate()` function works similarly, in that the predicted output spikes and actual targets are supplied as arguments. `accuracy_rate` assumes a rate code is used to interpret the output by checking if the index of the neuron with the highest spike count matches the target index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq7_rly0c9b4"
   },
   "outputs": [],
   "source": [
    "acc = SF.accuracy_rate(spk_rec, targets)\n",
    "\n",
    "print(f\"The accuracy of a single batch using an untrained network is {acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4Z6bnqCdL50"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "As the above function only returns the accuracy of a single batch of data, the following function returns the accuracy on the entire DataLoader object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqxDKFvrdXuF"
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "    \n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in train_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "\n",
    "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_u43hKAvefWM"
   },
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1pzWXlsYoIu"
   },
   "source": [
    "## 3.3 Training Automation Using snn.backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAUDYl3gf0G-"
   },
   "source": [
    "Training SNNs can become arduous even with simple networks, so the `snn.backprop` module is here to reduce some of this effort.\n",
    "\n",
    "The `backprop.BPTT` function automatically performs a single epoch of training, where you need only provide the training parameters, dataloader, and several other arguments. \n",
    "The average loss across iterations is returned. \n",
    "The argument `time_var` indicates whether the input data is time-varying. \n",
    "As we are using the MNIST dataset, we explicitly specify `time_var=False`. \n",
    "\n",
    "The following code block may take a while to run. If you are not connected to GPU, then consider reducing `num_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnS4wYyh0bdb"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "num_epochs = 20\n",
    "test_acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    avg_loss = backprop.BPTT(net, train_loader, optimizer=optimizer, criterion=loss_fn, \n",
    "                            num_steps=num_steps, time_var=False, device=device)\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Train Loss: {avg_loss.item():.2f}\")\n",
    "\n",
    "    # Test set accuracy\n",
    "    test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "    test_acc_hist.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}, Test Acc: {test_acc * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results\n",
    "## 4.1 Plot Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy\n",
    "fig = plt.figure(facecolor=\"w\")\n",
    "plt.plot(test_acc_hist)\n",
    "plt.title(\"Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYFamUJLkVY3"
   },
   "source": [
    "## 4.2 Spike Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjRPDFWxj2eS"
   },
   "source": [
    "Despite having selected some fairly generic values and architectures, the test set accuracy should be fairly competitive given the brief training run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HcwxfC6kfy0"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "idx = 0\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n",
    "labels=['0', '1', '2', '3', '4', '5', '6', '7', '8','9']\n",
    "print(f\"The target label is: {targets[idx]}\")\n",
    "\n",
    "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
    "\n",
    "#  Plot spike count histogram\n",
    "anim = splt.spike_count(spk_rec[:, idx].detach().cpu(), fig, ax, labels=labels, \n",
    "                        animate=True, interpolate=4)\n",
    "\n",
    "\n",
    "HTML(anim.to_html5_video())\n",
    "# anim.save(\"spike_bar.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_quantization(b):\n",
    "\n",
    "    def uniform_quant(x, b):\n",
    "        xdiv = x.mul((2 ** b - 1))\n",
    "        xhard = xdiv.round().div(2 ** b - 1)\n",
    "        #print('uniform quant bit: ', b)\n",
    "        return xhard\n",
    "\n",
    "    class _pq(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, alpha):\n",
    "            input.div_(alpha)                          # weights are first divided by alpha\n",
    "            input_c = input.clamp(min=-1, max=1)       # then clipped to [-1,1]\n",
    "            sign = input_c.sign()\n",
    "            input_abs = input_c.abs()\n",
    "            input_q = uniform_quant(input_abs, b).mul(sign)\n",
    "            ctx.save_for_backward(input, input_q)\n",
    "            input_q = input_q.mul(alpha)               # rescale to the original range\n",
    "            return input_q\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            grad_input = grad_output.clone()             # grad for weights will not be clipped\n",
    "            input, input_q = ctx.saved_tensors\n",
    "            i = (input.abs()>1.).float()     # >1 means clipped. # output matrix is a form of [True, False, True, ...]\n",
    "            sign = input.sign()              # output matrix is a form of [+1, -1, -1, +1, ...]\n",
    "            #grad_alpha = (grad_output*(sign*i + (input_q-input)*(1-i))).sum()\n",
    "            grad_alpha = (grad_output*(sign*i + (0.0)*(1-i))).sum()\n",
    "            # above line, if i = True,  and sign = +1, \"grad_alpha = grad_output * 1\"\n",
    "            #             if i = False, \"grad_alpha = grad_output * (input_q-input)\"\n",
    "            grad_input = grad_input*(1-i)\n",
    "            return grad_input, grad_alpha\n",
    "\n",
    "    return _pq().apply\n",
    "\n",
    "class weight_quantize_fn(nn.Module):\n",
    "    def __init__(self, w_bit, wgt_alpha):\n",
    "        super(weight_quantize_fn, self).__init__()\n",
    "        self.w_bit = w_bit-1\n",
    "        self.wgt_alpha = wgt_alpha\n",
    "        self.weight_q = weight_quantization(b=self.w_bit)\n",
    "        #self.register_parameter('wgt_alpha', Parameter(torch.tensor(3.0)))\n",
    "    def forward(self, weight):\n",
    "        #mean = weight.data.mean()\n",
    "        #std = weight.data.std()\n",
    "        #weight = weight.add(-mean).div(std)      # weights normalization\n",
    "        weight_q = self.weight_q(weight, self.wgt_alpha)\n",
    "\n",
    "        return weight_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_alpha=1\n",
    "w_bits=16\n",
    "weight_quant = weight_quantize_fn(w_bit= w_bits)  ## define quant function\n",
    "weight_quant.wgt_alpha = w_alpha\n",
    "conv1_quant      = weight_quant(net[0].weight)\n",
    "w_delta          = w_alpha/(2**(w_bits-1)-1)\n",
    "conv1_int        = conv1_quant/w_delta\n",
    "print(\"Conv1 Weights: \\n\",conv1_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in net:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in net:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "                layer.weight = Parameter(weight_quant(layer.weight))\n",
    "                w_delta = w_alpha/(2**(w_bits-1)-1)\n",
    "                layer.weight = Parameter(layer.weight/w_delta)\n",
    "                layer.bias = Parameter(layer.bias/w_delta)\n",
    "#                 print(layer.weight)\n",
    "#                 print(layer.bias)\n",
    "        if isinstance(layer, torch.nn.Conv2d):\n",
    "                layer.weight = Parameter(weight_quant(layer.weight))\n",
    "                w_delta = w_alpha/(2**(w_bits-1)-1)\n",
    "                layer.weight = Parameter(layer.weight/w_delta)\n",
    "                layer.bias = Parameter(layer.bias/w_delta)\n",
    "#                 print(layer.weight)\n",
    "#                 print(layer.bias)\n",
    "        if isinstance(layer, snn.Leaky):\n",
    "                layer.threshold = layer.threshold/w_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({'state_dict': net.state_dict(),}, 0, fdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_cnn_best.pth.tar'))\n",
    "    else:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_cnn_quan.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({'state_dict': net.state_dict(),}, 1, fdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = '/Volumes/export/isn/keli/Desktop/CRI/result/model_cnn_quan.pth.tar'\n",
    "checkpoint = torch.load(best_model_path)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0dAgWUt2o6E"
   },
   "source": [
    "# Conclusion\n",
    "You should now have a grasp of the basic features of snnTorch and be able to start running your own experiments. [In the next tutorial](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), we will train a network using a neuromorphic dataset.\n",
    "\n",
    "A special thanks to [Gianfresco Angelini](https://github.com/gianfa) for providing valuable feedback on the tutorial.\n",
    "\n",
    "If you like this project, please consider starring ⭐ the repo on GitHub as it is the easiest and best way to support it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSRE0ETf5Qwa"
   },
   "source": [
    "# Additional Resources\n",
    "* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping into CRI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [net.state_dict()['0.weight'].detach().cpu().numpy(),net.state_dict()['3.weight'].detach().cpu().numpy(),net.state_dict()['7.weight'].detach().cpu().numpy()]\n",
    "biases = [net.state_dict()['0.bias'].detach().cpu().numpy(),net.state_dict()['3.bias'].detach().cpu().numpy(),net.state_dict()['7.bias'].detach().cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(layers[1]))\n",
    "print(np.max(layers[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2dOutputSize(layer,inputSize):\n",
    "    H_out = (inputSize[0] + layer.padding[0]-layer.dilation[0]*(layer.kernel_size[0]-1)-1)/layer.stride[0] +1\n",
    "    W_out = (inputSize[1] + layer.padding[0]-layer.dilation[1]*(layer.kernel_size[1]-1)-1)/layer.stride[1] +1\n",
    "    return [layer.out_channels,int(H_out),int(W_out)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPoolOutputSize(layer,inputSize):\n",
    "    H_out = (inputSize[1] + layer.padding - layer.dilation*(layer.kernel_size-1)-1)/layer.stride +1\n",
    "    W_out = (inputSize[2] + layer.padding - layer.dilation*(layer.kernel_size-1)-1)/layer.stride +1\n",
    "    return [inputSize[0],int(H_out),int(W_out)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AvgPoolOutputSize(layer,inputSize):\n",
    "    H_out = (inputSize[1] + layer.padding*2 - (layer.kernel_size-1))/layer.stride +1\n",
    "    W_out = (inputSize[2] + layer.padding*2 - (layer.kernel_size-1))/layer.stride +1\n",
    "    return [inputSize[0],int(H_out),int(W_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2dToCRI(inputs,output,layer,layerIdx,axonsDict=None,neuronsDict=None):\n",
    "    Hk, Wk = layer.kernel_size\n",
    "    Ho, Wo = output.shape[1],output.shape[2]\n",
    "    pad_top,pad_left = Hk//2,Wk//2\n",
    "    filters = layer.weight.detach().cpu().numpy()\n",
    "    if layerIdx==0:\n",
    "        Hi, Wi = inputs.shape\n",
    "        for row in range(pad_top,Hi-pad_top):\n",
    "            for col in range(pad_left,Wi-pad_left):\n",
    "                patch = inputs[row-pad_top:row+pad_top+1,col-pad_left:col+pad_left+1]\n",
    "                for filIdx, fil in enumerate(filters):\n",
    "                    postSynapticID = str(output[filIdx,row-pad_top,col-pad_left])\n",
    "                    for i,axons in enumerate(patch):\n",
    "                        for j,axon in enumerate(axons):\n",
    "                            axonsDict[axon].append((postSynapticID,int(fil[0,i,j])))\n",
    "    else:\n",
    "        Hi, Wi = inputs.shape[1],inputs.shape[2]\n",
    "        for channel in range(inputs.shape[0]):\n",
    "            for row in range(pad_top,Hi-pad_top):\n",
    "                for col in range(pad_left,Wi-pad_left):\n",
    "                    patch = inputs[channel,row-pad_top:row+pad_top+1,col-pad_left:col+pad_left+1]\n",
    "                    for filIdx, fil in enumerate(filters):\n",
    "                        postSynapticID = str(output[filIdx,row-pad_top,col-pad_left])\n",
    "                        for i,neurons in enumerate(patch):\n",
    "                            for j,neuron in enumerate(neurons):\n",
    "                                neuronsDict[str(neuron)].append((postSynapticID,int(fil[channel,i,j])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPoolToCRI(inputs,output,layer,neuronsDict):\n",
    "    Hk, Wk = layer.kernel_size, layer.kernel_size\n",
    "    Hi, Wi = inputs.shape[1],inputs.shape[2]\n",
    "    Ho, Wo = output.shape[1],output.shape[2]\n",
    "    pad_top,pad_left = Hk//2,Wk//2\n",
    "    scaler = 1e6\n",
    "    for row in range(0,Hi,2):\n",
    "        for col in range(0,Wi,2):\n",
    "            for channel in range(inputs.shape[0]):\n",
    "                patch = inputs[channel,row:row+pad_top+1,col:col+pad_left+1]\n",
    "                postSynapticID = str(output[channel,row//2,col//2])\n",
    "                for i,preSynNeurons in enumerate(patch):\n",
    "                    for j,preSynNeuron in enumerate(preSynNeurons):\n",
    "                        neuronsDict[str(preSynNeuron)].append((postSynapticID,scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgPoolToCRI(inputs,output,layer,neuronsDict):\n",
    "    Hk, Wk = layer.kernel_size, layer.kernel_size\n",
    "    Hi, Wi = inputs.shape[1],inputs.shape[2]\n",
    "    Ho, Wo = output.shape[1],output.shape[2]\n",
    "    pad_top,pad_left = Hk//2,Wk//2\n",
    "    scaler = 1e6\n",
    "    for row in range(0,Hi,2):\n",
    "        for col in range(0,Wi,2):\n",
    "            for channel in range(inputs.shape[0]):\n",
    "                patch = inputs[channel,row:row+pad_top+1,col:col+pad_left+1]\n",
    "                postSynapticID = str(output[channel,row//2,col//2])\n",
    "                for i,preSynNeurons in enumerate(patch):\n",
    "                    for j,preSynNeuron in enumerate(preSynNeurons):\n",
    "                        neuronsDict[str(preSynNeuron)].append((postSynapticID,scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearToCRI(inputs,output,layer,layerIdx,neuronsDict,outputNeurons=None):\n",
    "    inputs = inputs.flatten()\n",
    "    weight = layer.weight.detach().cpu().numpy()\n",
    "    currLayerNeuronIdxOffset,nextLayerNeuronIdxOffset = inputs[0],inputs[-1]+1\n",
    "    for baseNeuronIdx, neuron in enumerate(weight.T):\n",
    "        neuronID = str(baseNeuronIdx+currLayerNeuronIdxOffset)\n",
    "        neuronEntry = [(str(basePostSynapticID+nextLayerNeuronIdxOffset), int(synapseWeight)) for basePostSynapticID, synapseWeight in enumerate(neuron) if synapseWeight != 0]\n",
    "        neuronsDict[neuronID] = neuronEntry\n",
    "    print('instantiate output neurons')\n",
    "    for baseNeuronIdx in range(layer.out_features):\n",
    "        neuronID = str(baseNeuronIdx+nextLayerNeuronIdxOffset)\n",
    "        neuronsDict[neuronID] = []\n",
    "        outputNeurons.append(neuronID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convBiasAxons(layer,axonsDict,axonOffset,outputs):\n",
    "    biases = layer.bias.detach().cpu().numpy()\n",
    "    for biasIdx, bias in enumerate(biases):\n",
    "        biasID = 'a'+str(biasIdx+axonOffset)\n",
    "        axonsDict[biasID] = [(str(neuronIdx),int(bias)) for neuronIdx in outputs[biasIdx].flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearBiasAXons(layer,axonsDict,axonOffset,outputs):\n",
    "    biases = layer.bias.detach().cpu().numpy()\n",
    "    for biasIdx, bias in enumerate(biases):\n",
    "        biasID = 'a'+str(biasIdx+axonOffset)\n",
    "        axonsDict[biasID] = [(str(outputs[biasIdx]),int(bias))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "axonsDict = defaultdict(list)\n",
    "neuronsDict = defaultdict(list)\n",
    "outputNeurons = []\n",
    "H_in, W_in = 28, 28\n",
    "inputSize = (H_in, W_in)\n",
    "axonOffset = 0\n",
    "neuronOffset = 0\n",
    "currInput = None\n",
    "\n",
    "for layerIdx, layer in enumerate(net):\n",
    "    if layerIdx == 0: #input layer\n",
    "        if isinstance(layer,torch.nn.Conv2d):\n",
    "            print('constructing Axons')\n",
    "            outputSize = conv2dOutputSize(layer,inputSize)\n",
    "            print(\"Input layer shape(infeature, outfeature): \", inputSize,',',outputSize)\n",
    "            input = np.arange(0,inputSize[0]*inputSize[1],dtype=int).reshape(inputSize)\n",
    "            inputAxons = np.array([['a'+str(i) for i in row] for row in input])\n",
    "            output = np.arange(0,outputSize[0]*outputSize[1]*outputSize[2],dtype=int).reshape(outputSize)\n",
    "            conv2dToCRI(inputAxons,output,layer,layerIdx,axonsDict)\n",
    "            axonOffset += len(axonsDict)\n",
    "            print('constructing bias axons for input layer:',layer.bias.shape[0],'axons')\n",
    "            convBiasAxons(layer,axonsDict,axonOffset,output)\n",
    "            axonOffset += layer.bias.shape[0]\n",
    "            currInput = output\n",
    "    elif layerIdx == len(net)-2: #output layer\n",
    "        if isinstance(layer,torch.nn.Linear):\n",
    "            print('constructing output layer')\n",
    "            outputSize = layer.out_features\n",
    "            print(\"output layer shape(infeature, outfeature): \", currInput.flatten().shape[0],',',outputSize)\n",
    "            neuronOffset += currInput.shape[0]*currInput.shape[1]*currInput.shape[2]\n",
    "            output = np.arange(neuronOffset,neuronOffset+outputSize,dtype=int)\n",
    "            linearToCRI(currInput,output,layer,layerIdx,neuronsDict=neuronsDict,outputNeurons=outputNeurons)\n",
    "            print('constructing bias axons for output linearlayer:',layer.bias.shape[0],'axons')\n",
    "            print('Numer of neurons:',len(neuronsDict))\n",
    "            linearBiasAXons(layer,axonsDict,axonOffset,output)\n",
    "            axonOffset += layer.bias.shape[0]\n",
    "    else: #hidden layer\n",
    "        if isinstance(layer,torch.nn.AvgPool2d):\n",
    "            print('constructing hidden avgpool layer')\n",
    "            outputSize = AvgPoolOutputSize(layer,currInput.shape)\n",
    "            print(\"Hidden layer shape(infeature, outfeature): \", currInput.shape,',',outputSize)\n",
    "            neuronOffset += currInput.shape[0]*currInput.shape[1]*currInput.shape[2]\n",
    "            output = np.arange(neuronOffset,neuronOffset+outputSize[0]*outputSize[1]*outputSize[2],dtype=int).reshape(outputSize)\n",
    "            avgPoolToCRI(currInput,output,layer,neuronsDict)\n",
    "            currInput = output\n",
    "            print('Numer of neurons:',len(neuronsDict))\n",
    "        if isinstance(layer,torch.nn.Conv2d):\n",
    "            print('constructing hidden conv2d layer')\n",
    "            outputSize = conv2dOutputSize(layer,currInput.shape)\n",
    "            print(\"Hidden layer shape(infeature, outfeature): \", currInput.shape,',',outputSize)\n",
    "            neuronOffset += currInput.shape[0]*currInput.shape[1]*currInput.shape[2]\n",
    "            output = np.arange(neuronOffset,neuronOffset+outputSize[0]*outputSize[1]*outputSize[2],dtype=int).reshape(outputSize)\n",
    "            conv2dToCRI(currInput,output,layer,layerIdx,neuronsDict=neuronsDict)\n",
    "            print('constructing bias axons for hidden conv2d layer:',layer.bias.shape[0],'axons')\n",
    "            convBiasAxons(layer,axonsDict,axonOffset,output)\n",
    "            axonOffset += layer.bias.shape[0]\n",
    "            currInput = output\n",
    "            print('Numer of neurons:',len(neuronsDict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of axons: \",len(axonsDict))\n",
    "totalAxonSyn = 0\n",
    "maxFan = 0\n",
    "for key in axonsDict.keys():\n",
    "    totalAxonSyn += len(axonsDict[key])\n",
    "    if len(axonsDict[key]) > maxFan:\n",
    "        maxFan = len(axonsDict[key])\n",
    "print(\"Total number of connections between axon and neuron: \", totalAxonSyn)\n",
    "print(\"Max fan out of axon: \", maxFan)\n",
    "print('---')\n",
    "print(\"Number of neurons: \", len(neuronsDict))\n",
    "totalSyn = 0\n",
    "maxFan = 0\n",
    "for key in neuronsDict.keys():\n",
    "    totalSyn += len(neuronsDict[key])\n",
    "    if len(neuronsDict[key]) > maxFan:\n",
    "        maxFan = len(neuronsDict[key])\n",
    "print(\"Total number of connections between hidden and output layers: \", totalSyn)\n",
    "print(\"Max fan out of neuron: \", maxFan)\n",
    "print(len(axonsDict))\n",
    "print(len(neuronsDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axonsDict, neuronsDict = dict(axonsDict), dict(neuronsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2s.api import CRI_network\n",
    "import cri_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['neuron_type'] = \"I&F\"\n",
    "config['global_neuron_params'] = {}\n",
    "config['global_neuron_params']['v_thr'] = 9*10**4\n",
    "#softwareNetwork = CRI_network(axons=axonsDict,connections=neuronsDict,config=config,target='simpleSim', outputs = outputNeurons)\n",
    "hardwareNetwork = CRI_network(axons=axonsDict,connections=neuronsDict,config=config,target='CRI', outputs = outputNeurons,simDump = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_CRI(currentInput):\n",
    "    num_steps = 10\n",
    "    currentInput = data.view(data.size(0), -1)\n",
    "    batch = []\n",
    "    n = 0\n",
    "    for element in currentInput:\n",
    "        timesteps = []\n",
    "        rateEnc = spikegen.rate(element,num_steps)\n",
    "        rateEnc = rateEnc.detach().cpu().numpy()\n",
    "        for element in rateEnc:\n",
    "            currInput = ['a'+str(idx) for idx,axon in enumerate(element) if axon != 0]\n",
    "            biasInput = ['a'+str(idx) for idx in range(784,len(axonsDict))]\n",
    "#             timesteps.append(currInput)\n",
    "#             timesteps.append(biasInput)\n",
    "            timesteps.append(currInput+biasInput)\n",
    "        batch.append(timesteps)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CRI(inputList):\n",
    "    firstOutput = 13760\n",
    "    predictions = []\n",
    "    total_time_cri = 0\n",
    "    #each image\n",
    "    for currInput in inputList:\n",
    "        #reset the membrane potential to zero\n",
    "        softwareNetwork.simpleSim.initialize_sim_vars(len(neuronsDict))\n",
    "        spikeRate = [0]*10\n",
    "        #each time step\n",
    "        for slice in currInput:\n",
    "            start_time = time.time()\n",
    "            swSpike = softwareNetwork.step(slice, membranePotential=False)\n",
    "            end_time = time.time()\n",
    "            total_time_cri = total_time_cri + end_time-start_time\n",
    "            for spike in swSpike:\n",
    "                spikeIdx = int(spike) - firstOutput \n",
    "                try: \n",
    "                    if spikeIdx >= 0: \n",
    "                        spikeRate[spikeIdx] += 1 \n",
    "                except:\n",
    "                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate )\n",
    "        predictions.append(spikeRate.index(max(spikeRate)))\n",
    "    print(f\"Total simulation execution time: {total_time_cri:.5f} s\")\n",
    "    cri_sw_runtime += total_time_cri\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CRI_hw(inputList):\n",
    "    firstOutput = 13760\n",
    "    predictions = []\n",
    "    #each image\n",
    "    total_time_cri = 0\n",
    "    for currInput in inputList:\n",
    "        #initiate the softwareNetwork for each image\n",
    "        cri_simulations.FPGA_Execution.fpga_controller.clear(len(neuronsDict), False, 0)  ##Num_neurons, simDump, coreOverride\n",
    "        spikeRate = [0]*10\n",
    "        #each time step\n",
    "        for slice in currInput:\n",
    "            hwSpike = hardwareNetwork.step(slice)\n",
    "            for spike in hwSpike:\n",
    "                spikeIdx = int(spike[0]) - firstOutput \n",
    "                if spikeIdx >= 0: \n",
    "                    spikeRate[spikeIdx] += 1 \n",
    "        predictions.append(spikeRate.index(max(spikeRate))) \n",
    "    # print(f\"Total execution time CRIFPGA: {total_time_cri:.5f} s\")\n",
    "    cri_hw_runtime += total_time_cri\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "cri_correct = 0\n",
    "cri_correct_hw = 0\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=True, drop_last=False)\n",
    "global snnTorch_runtime \n",
    "global cri_hw_runtime \n",
    "global cri_sw_runtime \n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        input = input_to_CRI(data)\n",
    "#         criPred = torch.tensor(run_CRI(input)).to(device)\n",
    "        criPred_hw = torch.tensor(run_CRI_hw(input)).to(device)\n",
    "        print(\"CRI Predicted: \",criPred)\n",
    "#         print(\"CRI Predicted HW: \",criPred_hw)\n",
    "        print(\"Target: \",targets)\n",
    "        snn_bTime = time.time()\n",
    "        test_spk, _ = forward_pass(net, num_steps, data)\n",
    "        snn_eTime = time.time()\n",
    "        snnTorch_runtime += snn_bTime-snn_eTime\n",
    "        # calculate total accuracy\n",
    "        _, predicted = test_spk.sum(dim=0).max(1)\n",
    "        print(\"Torchsnn Predicted: \",predicted)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "#         cri_correct += (criPred == targets).sum().item()\n",
    "        cri_correct_hw += (criPred_hw == targets).sum().item()\n",
    "        break #run for one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Totoal execution time: {end_time-start_time:.2f} s\")\n",
    "print(f\"Total correctly classified test set images for TorchSNN: {correct}/{total}\")\n",
    "print(f\"Total correctly classified test set images for CRI: {cri_correct}/{total}\")\n",
    "print(f\"Test Set Accuracy for TorchSNN: {100 * correct / total:.2f}%\")\n",
    "print(f\"Test Set Accuracy for CRI: {100 * cri_correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tutorial_6_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "782c4fc05a7b0c5006502edc276c124083adbfff5066531c0f613c007bf9a5ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
